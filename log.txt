converged SCF energy = -99.8206324520548  <S^2> = 8.8817842e-16  2S+1 = 1
Training epoch:   0%|          | 0/1000 [00:00<?, ?it/s]Iteration 0 Predicted energy: -89.27995480458739 Cost value: 111.10588526781898 Grad:  (Array(46.83362, dtype=float32), Array(-4.868678, dtype=float32))
Training epoch:   0%|          | 1/1000 [00:12<3:26:26, 12.40s/it]Iteration 1 Predicted energy: -89.61734432070381 Cost value: 104.10708869136793 Grad:  (Array(16.212242, dtype=float32), Array(-89.161995, dtype=float32))
Training epoch:   0%|          | 2/1000 [00:16<2:08:05,  7.70s/it]Iteration 2 Predicted energy: -90.316134866106 Cost value: 90.33547436130652 Grad:  (Array(130.2057, dtype=float32), Array(-7.3195863, dtype=float32))
Training epoch:   0%|          | 3/1000 [00:20<1:41:11,  6.09s/it]Iteration 3 Predicted energy: -90.99696841563703 Cost value: 77.85704702757229 Grad:  (Array(5.547296, dtype=float32), Array(-7.898156, dtype=float32))
Training epoch:   0%|          | 4/1000 [00:25<1:28:39,  5.34s/it]Iteration 4 Predicted energy: -90.91701627941723 Cost value: 79.27438094965328 Grad:  (Array(17.756815, dtype=float32), Array(-39.243774, dtype=float32))
Training epoch:   0%|          | 5/1000 [00:29<1:24:00,  5.07s/it]Iteration 5 Predicted energy: -90.95393868715843 Cost value: 78.61825832045213 Grad:  (Array(16.417433, dtype=float32), Array(-109.59186, dtype=float32))
Training epoch:   1%|          | 6/1000 [00:34<1:19:24,  4.79s/it]Iteration 6 Predicted energy: -91.49896952301043 Cost value: 69.25007390463124 Grad:  (Array(12.948746, dtype=float32), Array(-3.7493968, dtype=float32))
Training epoch:   1%|          | 7/1000 [00:38<1:15:54,  4.59s/it]Iteration 7 Predicted energy: -91.60645283149367 Cost value: 67.47274683884172 Grad:  (Array(57.43283, dtype=float32), Array(-1.2924125, dtype=float32))
Training epoch:   1%|          | 8/1000 [00:42<1:13:52,  4.47s/it]Iteration 8 Predicted energy: -91.50361330885639 Cost value: 69.17280742832878 Grad:  (Array(34.837883, dtype=float32), Array(-10.822966, dtype=float32))
Training epoch:   1%|          | 9/1000 [00:46<1:12:39,  4.40s/it]Iteration 9 Predicted energy: -91.3741979918005 Cost value: 71.34225509137127 Grad:  (Array(8.38048, dtype=float32), Array(-18.27849, dtype=float32))
Training epoch:   1%|          | 10/1000 [00:50<1:11:40,  4.34s/it]Iteration 10 Predicted energy: -91.71580933925024 Cost value: 65.68815768985088 Grad:  (Array(5.9953785, dtype=float32), Array(-10.606771, dtype=float32))
Training epoch:   1%|          | 11/1000 [00:55<1:10:50,  4.30s/it]Iteration 11 Predicted energy: -91.88659651264179 Cost value: 62.948926287897244 Grad:  (Array(41.659496, dtype=float32), Array(-4.1110997, dtype=float32))
Training epoch:   1%|          | 12/1000 [00:59<1:10:31,  4.28s/it]Iteration 12 Predicted energy: -91.77134905557647 Cost value: 64.79096319682172 Grad:  (Array(11.6349325, dtype=float32), Array(-36.66716, dtype=float32))
Training epoch:   1%|▏         | 13/1000 [01:03<1:09:57,  4.25s/it]Iteration 13 Predicted energy: -91.77059700648785 Cost value: 64.80307067488425 Grad:  (Array(10.843931, dtype=float32), Array(-53.1249, dtype=float32))
Training epoch:   1%|▏         | 14/1000 [01:07<1:09:24,  4.22s/it]Iteration 14 Predicted energy: -91.90250005574926 Cost value: 62.69682064542327 Grad:  (Array(79.23456, dtype=float32), Array(-3.2737098, dtype=float32))
Training epoch:   2%|▏         | 15/1000 [01:11<1:09:15,  4.22s/it]Iteration 15 Predicted energy: -92.00567400001565 Cost value: 61.07357560709815 Grad:  (Array(6.5532837, dtype=float32), Array(-29.157543, dtype=float32))
Training epoch:   2%|▏         | 16/1000 [01:16<1:09:00,  4.21s/it]Iteration 16 Predicted energy: -92.03633686296516 Cost value: 60.59525781832039 Grad:  (Array(4.7983055, dtype=float32), Array(-12.75978, dtype=float32))
Training epoch:   2%|▏         | 17/1000 [01:20<1:08:42,  4.19s/it]Iteration 17 Predicted energy: -92.10940731346359 Cost value: 59.46299313804092 Grad:  (Array(47.153652, dtype=float32), Array(-5.2901797, dtype=float32))
Training epoch:   2%|▏         | 18/1000 [01:24<1:08:51,  4.21s/it]Iteration 18 Predicted energy: -92.14890218613458 Cost value: 58.855445273036295 Grad:  (Array(7.3364153, dtype=float32), Array(-30.265707, dtype=float32))
Training epoch:   2%|▏         | 19/1000 [01:28<1:08:59,  4.22s/it]Iteration 19 Predicted energy: -92.08290681945068 Cost value: 59.87239796545868 Grad:  (Array(7.962473, dtype=float32), Array(-33.808807, dtype=float32))
Training epoch:   2%|▏         | 20/1000 [01:32<1:08:53,  4.22s/it]Iteration 20 Predicted energy: -92.0228187600978 Cost value: 60.80589837447189 Grad:  (Array(38.2412, dtype=float32), Array(-2.6941314, dtype=float32))
Training epoch:   2%|▏         | 21/1000 [01:37<1:08:46,  4.22s/it]Iteration 21 Predicted energy: -92.0787961459776 Cost value: 59.9360293900949 Grad:  (Array(10.170434, dtype=float32), Array(-12.440224, dtype=float32))
Training epoch:   2%|▏         | 22/1000 [01:41<1:08:53,  4.23s/it]Iteration 22 Predicted energy: -92.16563033019914 Cost value: 58.59905748561465 Grad:  (Array(5.520433, dtype=float32), Array(-25.055887, dtype=float32))
Training epoch:   2%|▏         | 23/1000 [01:45<1:08:55,  4.23s/it]Iteration 23 Predicted energy: -92.21242904181983 Cost value: 57.88475913151093 Grad:  (Array(38.589573, dtype=float32), Array(-4.049078, dtype=float32))
Training epoch:   2%|▏         | 24/1000 [01:49<1:08:43,  4.22s/it]Iteration 24 Predicted energy: -92.23015303974992 Cost value: 57.61537770862413 Grad:  (Array(1.647721, dtype=float32), Array(-22.227074, dtype=float32))
Training epoch:   2%|▎         | 25/1000 [01:53<1:08:16,  4.20s/it]Iteration 25 Predicted energy: -92.25344045738818 Cost value: 57.26239468414651 Grad:  (Array(2.438331, dtype=float32), Array(-17.426157, dtype=float32))
Training epoch:   3%|▎         | 26/1000 [01:58<1:08:32,  4.22s/it]Iteration 26 Predicted energy: -92.29032111023795 Cost value: 56.70558890469535 Grad:  (Array(36.299168, dtype=float32), Array(-3.4456584, dtype=float32))
Training epoch:   3%|▎         | 27/1000 [02:02<1:08:18,  4.21s/it]Iteration 27 Predicted energy: -92.32048445523654 Cost value: 56.2522199741769 Grad:  (Array(3.8395438, dtype=float32), Array(-26.112015, dtype=float32))
Training epoch:   3%|▎         | 28/1000 [02:06<1:07:51,  4.19s/it]Iteration 28 Predicted energy: -92.32538569358833 Cost value: 56.178723970302045 Grad:  (Array(6.6826477, dtype=float32), Array(-4.219675, dtype=float32))
Training epoch:   3%|▎         | 29/1000 [02:10<1:07:53,  4.19s/it]Iteration 29 Predicted energy: -92.3273871705943 Cost value: 56.14872484812988 Grad:  (Array(26.915506, dtype=float32), Array(-2.278492, dtype=float32))
Training epoch:   3%|▎         | 30/1000 [02:15<1:08:02,  4.21s/it]Iteration 30 Predicted energy: -92.35435010125919 Cost value: 55.74537214180201 Grad:  (Array(3.8217452, dtype=float32), Array(-15.414884, dtype=float32))
Training epoch:   3%|▎         | 31/1000 [02:19<1:08:09,  4.22s/it]Iteration 31 Predicted energy: -92.37506747880767 Cost value: 55.436437770844535 Grad:  (Array(3.1973042, dtype=float32), Array(-3.869502, dtype=float32))
Training epoch:   3%|▎         | 32/1000 [02:23<1:07:59,  4.21s/it]Iteration 32 Predicted energy: -92.38633786122283 Cost value: 55.26873606327346 Grad:  (Array(18.117405, dtype=float32), Array(-4.7752056, dtype=float32))
Training epoch:   3%|▎         | 33/1000 [02:27<1:07:47,  4.21s/it]Iteration 33 Predicted energy: -92.3934832283973 Cost value: 55.16254559047612 Grad:  (Array(2.5225136, dtype=float32), Array(-18.60847, dtype=float32))
Training epoch:   3%|▎         | 34/1000 [02:31<1:07:46,  4.21s/it]Iteration 34 Predicted energy: -92.38202440411534 Cost value: 55.33288969086961 Grad:  (Array(4.458226, dtype=float32), Array(-3.4129314, dtype=float32))
Training epoch:   4%|▎         | 35/1000 [02:36<1:08:14,  4.24s/it]Iteration 35 Predicted energy: -92.36017995421287 Cost value: 55.65835147255586 Grad:  (Array(12.618126, dtype=float32), Array(-3.6072874, dtype=float32))
Training epoch:   4%|▎         | 36/1000 [02:41<1:12:07,  4.49s/it]Iteration 36 Predicted energy: -92.35184135778609 Cost value: 55.78284040982759 Grad:  (Array(4.1793528, dtype=float32), Array(-18.240515, dtype=float32))
Training epoch:   4%|▎         | 37/1000 [02:45<1:10:19,  4.38s/it]Iteration 37 Predicted energy: -92.36938536272855 Cost value: 55.52108318619283 Grad:  (Array(4.8715, dtype=float32), Array(-2.1933677, dtype=float32))
Training epoch:   4%|▍         | 38/1000 [02:49<1:08:57,  4.30s/it]Iteration 38 Predicted energy: -92.3977904449394 Cost value: 55.098583462596864 Grad:  (Array(5.204343, dtype=float32), Array(-1.4599862, dtype=float32))
Training epoch:   4%|▍         | 39/1000 [02:53<1:08:31,  4.28s/it]Iteration 39 Predicted energy: -92.41153038572148 Cost value: 54.894793429344645 Grad:  (Array(2.463655, dtype=float32), Array(-14.358086, dtype=float32))
Training epoch:   4%|▍         | 40/1000 [02:57<1:08:09,  4.26s/it]Iteration 40 Predicted energy: -92.41695829232926 Cost value: 54.81439106338768 Grad:  (Array(15.846981, dtype=float32), Array(-2.7423823, dtype=float32))
Training epoch:   4%|▍         | 41/1000 [03:02<1:07:49,  4.24s/it]Iteration 41 Predicted energy: -92.42286747083632 Cost value: 54.726926717342344 Grad:  (Array(1.4102001, dtype=float32), Array(-3.1920288, dtype=float32))
Training epoch:   4%|▍         | 42/1000 [03:06<1:07:27,  4.23s/it]Iteration 42 Predicted energy: -92.42246194926116 Cost value: 54.73292678840579 Grad:  (Array(1.0383282, dtype=float32), Array(-6.7947264, dtype=float32))
Training epoch:   4%|▍         | 43/1000 [03:10<1:06:59,  4.20s/it]Iteration 43 Predicted energy: -92.41732667617852 Cost value: 54.808936411123035 Grad:  (Array(12.232825, dtype=float32), Array(-1.9605842, dtype=float32))
Training epoch:   4%|▍         | 44/1000 [03:14<1:07:05,  4.21s/it]Iteration 44 Predicted energy: -92.41749560143862 Cost value: 54.80643522895123 Grad:  (Array(1.8115264, dtype=float32), Array(-16.711784, dtype=float32))
Training epoch:   4%|▍         | 45/1000 [03:19<1:07:30,  4.24s/it]Iteration 45 Predicted energy: -92.41934806079323 Cost value: 54.77901064033214 Grad:  (Array(12.170181, dtype=float32), Array(-1.3865373, dtype=float32))
Training epoch:   5%|▍         | 46/1000 [03:23<1:07:34,  4.25s/it]Iteration 46 Predicted energy: -92.42077265075382 Cost value: 54.757925078910134 Grad:  (Array(1.338816, dtype=float32), Array(-4.133444, dtype=float32))
Training epoch:   5%|▍         | 47/1000 [03:27<1:07:26,  4.25s/it]Iteration 47 Predicted energy: -92.42624631861355 Cost value: 54.67694629042816 Grad:  (Array(1.3984327, dtype=float32), Array(-2.3922844, dtype=float32))
Training epoch:   5%|▍         | 48/1000 [03:31<1:07:20,  4.24s/it]Iteration 48 Predicted energy: -92.42991470329117 Cost value: 54.6227088418896 Grad:  (Array(5.712783, dtype=float32), Array(-1.3411212, dtype=float32))
Training epoch:   5%|▍         | 49/1000 [03:36<1:07:32,  4.26s/it]Iteration 49 Predicted energy: -92.4276739067919 Cost value: 54.65583605197573 Grad:  (Array(1.2689466, dtype=float32), Array(-12.691368, dtype=float32))
Training epoch:   5%|▌         | 50/1000 [03:40<1:07:40,  4.27s/it]Iteration 50 Predicted energy: -92.4294432051573 Cost value: 54.62967848345319 Grad:  (Array(11.2916765, dtype=float32), Array(-1.7451179, dtype=float32))
Training epoch:   5%|▌         | 51/1000 [03:44<1:07:32,  4.27s/it]Iteration 51 Predicted energy: -92.43522585582498 Cost value: 54.54423059163484 Grad:  (Array(1.3706862, dtype=float32), Array(-12.713086, dtype=float32))
Training epoch:   5%|▌         | 52/1000 [03:48<1:07:14,  4.26s/it]Iteration 52 Predicted energy: -92.43766280894353 Cost value: 54.508240751102505 Grad:  (Array(11.881465, dtype=float32), Array(-1.0721805, dtype=float32))
Training epoch:   5%|▌         | 53/1000 [03:53<1:07:03,  4.25s/it]Iteration 53 Predicted energy: -92.43989906998529 Cost value: 54.4752252571952 Grad:  (Array(1.0993079, dtype=float32), Array(-5.2364106, dtype=float32))
Training epoch:   5%|▌         | 54/1000 [03:57<1:06:46,  4.24s/it]Iteration 54 Predicted energy: -92.44075247901455 Cost value: 54.462628416480506 Grad:  (Array(2.1877813, dtype=float32), Array(-0.9614306, dtype=float32))
Training epoch:   6%|▌         | 55/1000 [04:01<1:06:36,  4.23s/it]Iteration 55 Predicted energy: -92.43932642371185 Cost value: 54.483678684051945 Grad:  (Array(1.776803, dtype=float32), Array(-1.2041072, dtype=float32))
Training epoch:   6%|▌         | 56/1000 [04:05<1:06:40,  4.24s/it]Iteration 56 Predicted energy: -92.4407175860158 Cost value: 54.463143429983454 Grad:  (Array(0.8263245, dtype=float32), Array(-6.776624, dtype=float32))
Training epoch:   6%|▌         | 57/1000 [04:09<1:06:35,  4.24s/it]Iteration 57 Predicted energy: -92.44217784777189 Cost value: 54.44159234746364 Grad:  (Array(10.142871, dtype=float32), Array(-0.61915547, dtype=float32))
Training epoch:   6%|▌         | 58/1000 [04:14<1:06:30,  4.24s/it]Iteration 58 Predicted energy: -92.44161200742326 Cost value: 54.44994272229019 Grad:  (Array(1.3812588, dtype=float32), Array(-11.837825, dtype=float32))
Training epoch:   6%|▌         | 59/1000 [04:18<1:06:16,  4.23s/it]Iteration 59 Predicted energy: -92.44099639871445 Cost value: 54.459028279760716 Grad:  (Array(16.936985, dtype=float32), Array(-0.7400223, dtype=float32))
Training epoch:   6%|▌         | 60/1000 [04:22<1:06:26,  4.24s/it]Iteration 60 Predicted energy: -92.43831447975958 Cost value: 54.49861864407289 Grad:  (Array(1.0376109, dtype=float32), Array(-24.980194, dtype=float32))
Training epoch:   6%|▌         | 61/1000 [04:26<1:06:09,  4.23s/it]Iteration 61 Predicted energy: -92.43041138647726 Cost value: 54.61536739810595 Grad:  (Array(32.93496, dtype=float32), Array(-1.8860344, dtype=float32))
Training epoch:   6%|▌         | 62/1000 [04:31<1:06:06,  4.23s/it]Iteration 62 Predicted energy: -92.41413737882819 Cost value: 54.856169269730024 Grad:  (Array(2.1249743, dtype=float32), Array(-50.562477, dtype=float32))
Training epoch:   6%|▋         | 63/1000 [04:35<1:05:41,  4.21s/it]Iteration 63 Predicted energy: -92.37368363549302 Cost value: 55.457046676490776 Grad:  (Array(69.71776, dtype=float32), Array(-2.8500311, dtype=float32))
Training epoch:   6%|▋         | 64/1000 [04:39<1:05:30,  4.20s/it]Iteration 64 Predicted energy: -92.34285329844244 Cost value: 55.91718107019958 Grad:  (Array(4.2276635, dtype=float32), Array(-86.95559, dtype=float32))
Training epoch:   6%|▋         | 65/1000 [04:43<1:05:45,  4.22s/it]Iteration 65 Predicted energy: -92.3047180917825 Cost value: 56.48896867094724 Grad:  (Array(94.64044, dtype=float32), Array(-4.157735, dtype=float32))
Training epoch:   7%|▋         | 66/1000 [04:47<1:05:46,  4.23s/it]Iteration 66 Predicted energy: -92.37927921492108 Cost value: 55.37373799980036 Grad:  (Array(2.816672, dtype=float32), Array(-72.45116, dtype=float32))
Training epoch:   7%|▋         | 67/1000 [04:52<1:05:17,  4.20s/it]Iteration 67 Predicted energy: -92.43603877785932 Cost value: 54.53222373296778 Grad:  (Array(29.757893, dtype=float32), Array(-1.5563173, dtype=float32))
Training epoch:   7%|▋         | 68/1000 [04:56<1:05:27,  4.21s/it]Iteration 68 Predicted energy: -92.44675768360645 Cost value: 54.374029100759145 Grad:  (Array(14.031021, dtype=float32), Array(-0.39281344, dtype=float32))
Training epoch:   7%|▋         | 69/1000 [05:00<1:05:27,  4.22s/it]Iteration 69 Predicted energy: -92.41115307176025 Cost value: 54.90038468700999 Grad:  (Array(2.8245203, dtype=float32), Array(-52.54084, dtype=float32))
Training epoch:   7%|▋         | 70/1000 [05:04<1:05:05,  4.20s/it]Iteration 70 Predicted energy: -92.3621111094651 Cost value: 55.62954061786593 Grad:  (Array(76.63372, dtype=float32), Array(-2.6995325, dtype=float32))
Training epoch:   7%|▋         | 71/1000 [05:08<1:05:04,  4.20s/it]Iteration 71 Predicted energy: -92.38124767627924 Cost value: 55.34444584204105 Grad:  (Array(2.971434, dtype=float32), Array(-71.629776, dtype=float32))
Training epoch:   7%|▋         | 72/1000 [05:13<1:05:08,  4.21s/it]Iteration 72 Predicted energy: -92.42039107859183 Cost value: 54.76357238551297 Grad:  (Array(43.032166, dtype=float32), Array(-2.3507845, dtype=float32))
Training epoch:   7%|▋         | 73/1000 [05:17<1:05:15,  4.22s/it]Iteration 73 Predicted energy: -92.44844761766889 Cost value: 54.349109232349534 Grad:  (Array(0.5596943, dtype=float32), Array(-3.7182293, dtype=float32))
Training epoch:   7%|▋         | 74/1000 [05:21<1:05:03,  4.22s/it]Iteration 74 Predicted energy: -92.43108539461419 Cost value: 54.60540571412916 Grad:  (Array(1.6839961, dtype=float32), Array(-36.89571, dtype=float32))
Training epoch:   8%|▊         | 75/1000 [05:25<1:05:30,  4.25s/it]Iteration 75 Predicted energy: -92.3976412176881 Cost value: 55.100798865484734 Grad:  (Array(59.893894, dtype=float32), Array(-2.0638242, dtype=float32))
Training epoch:   8%|▊         | 76/1000 [05:30<1:05:29,  4.25s/it]Iteration 76 Predicted energy: -92.40885548147943 Cost value: 54.93443786155127 Grad:  (Array(2.8684165, dtype=float32), Array(-54.73151, dtype=float32))
Training epoch:   8%|▊         | 77/1000 [05:34<1:05:08,  4.23s/it]Iteration 77 Predicted energy: -92.43497310547936 Cost value: 54.54796398365711 Grad:  (Array(31.854889, dtype=float32), Array(-1.4771262, dtype=float32))
Training epoch:   8%|▊         | 78/1000 [05:38<1:04:43,  4.21s/it]Iteration 78 Predicted energy: -92.44974215392406 Cost value: 54.33002378707775 Grad:  (Array(0.62187773, dtype=float32), Array(-0.5174176, dtype=float32))
Training epoch:   8%|▊         | 79/1000 [05:42<1:04:46,  4.22s/it]Iteration 79 Predicted energy: -92.43728567944852 Cost value: 54.51380956455547 Grad:  (Array(1.2209535, dtype=float32), Array(-30.813017, dtype=float32))
Training epoch:   8%|▊         | 80/1000 [05:47<1:04:37,  4.21s/it]Iteration 80 Predicted energy: -92.41643164791732 Cost value: 54.82218954799002 Grad:  (Array(48.1989, dtype=float32), Array(-2.151934, dtype=float32))
Training epoch:   8%|▊         | 81/1000 [05:51<1:04:10,  4.19s/it]Iteration 81 Predicted energy: -92.4200684899591 Cost value: 54.76834695706943 Grad:  (Array(2.4055846, dtype=float32), Array(-46.388622, dtype=float32))
Training epoch:   8%|▊         | 82/1000 [05:55<1:04:12,  4.20s/it]Iteration 82 Predicted energy: -92.43597180686153 Cost value: 54.5332128446662 Grad:  (Array(31.267067, dtype=float32), Array(-1.434546, dtype=float32))
Training epoch:   8%|▊         | 83/1000 [05:59<1:04:31,  4.22s/it]Iteration 83 Predicted energy: -92.44946901209296 Cost value: 54.33405045862997 Grad:  (Array(0.25287396, dtype=float32), Array(-7.984199, dtype=float32))
Training epoch:   8%|▊         | 84/1000 [06:03<1:04:27,  4.22s/it]Iteration 84 Predicted energy: -92.44610370683378 Cost value: 54.383674214091016 Grad:  (Array(0.63637996, dtype=float32), Array(-17.993725, dtype=float32))
Training epoch:   8%|▊         | 85/1000 [06:08<1:04:57,  4.26s/it]Iteration 85 Predicted energy: -92.43353312087575 Cost value: 54.569236528705886 Grad:  (Array(33.981834, dtype=float32), Array(-1.4925827, dtype=float32))
Training epoch:   9%|▊         | 86/1000 [06:12<1:04:42,  4.25s/it]Iteration 86 Predicted energy: -92.42970588644287 Cost value: 54.62579549826801 Grad:  (Array(1.9324452, dtype=float32), Array(-38.261185, dtype=float32))
Training epoch:   9%|▊         | 87/1000 [06:16<1:05:01,  4.27s/it]Iteration 87 Predicted energy: -92.4351686639295 Cost value: 54.54507536571 Grad:  (Array(32.55791, dtype=float32), Array(-1.3777461, dtype=float32))
Training epoch:   9%|▉         | 88/1000 [06:20<1:04:46,  4.26s/it]Iteration 88 Predicted energy: -92.44625897783935 Cost value: 54.381384137212386 Grad:  (Array(0.6205391, dtype=float32), Array(-16.553679, dtype=float32))
Training epoch:   9%|▉         | 89/1000 [06:25<1:04:30,  4.25s/it]Iteration 89 Predicted energy: -92.44999282302052 Cost value: 54.326328541090476 Grad:  (Array(0.42014745, dtype=float32), Array(-2.5272522, dtype=float32))
Training epoch:   9%|▉         | 90/1000 [06:29<1:04:14,  4.24s/it]Iteration 90 Predicted energy: -92.44548156819303 Cost value: 54.39285055972696 Grad:  (Array(18.41246, dtype=float32), Array(-0.9822718, dtype=float32))
Training epoch:   9%|▉         | 91/1000 [06:33<1:04:16,  4.24s/it]Iteration 91 Predicted energy: -92.4387850830683 Cost value: 54.49167057901289 Grad:  (Array(1.3991083, dtype=float32), Array(-29.147108, dtype=float32))
Training epoch:   9%|▉         | 92/1000 [06:38<1:04:37,  4.27s/it]Iteration 92 Predicted energy: -92.43445456463427 Cost value: 54.55562378462 Grad:  (Array(33.61837, dtype=float32), Array(-1.3872234, dtype=float32))
Training epoch:   9%|▉         | 93/1000 [06:42<1:04:13,  4.25s/it]Iteration 93 Predicted energy: -92.43784054501758 Cost value: 54.50561634261422 Grad:  (Array(1.4296529, dtype=float32), Array(-30.535639, dtype=float32))
Training epoch:   9%|▉         | 94/1000 [06:46<1:03:57,  4.24s/it]Iteration 94 Predicted energy: -92.44323217930051 Cost value: 54.42603478443502 Grad:  (Array(22.210854, dtype=float32), Array(-1.1307495, dtype=float32))
Training epoch:  10%|▉         | 95/1000 [06:50<1:03:43,  4.23s/it]Iteration 95 Predicted energy: -92.4486399598429 Cost value: 54.34627330522865 Grad:  (Array(0.4320157, dtype=float32), Array(-12.002044, dtype=float32))
Training epoch:  10%|▉         | 96/1000 [06:54<1:03:33,  4.22s/it]Iteration 96 Predicted energy: -92.45055966980092 Cost value: 54.317972815719315 Grad:  (Array(0.1014979, dtype=float32), Array(-0.12355828, dtype=float32))
Training epoch:  10%|▉         | 97/1000 [06:59<1:03:26,  4.22s/it]Iteration 97 Predicted energy: -92.44900766757587 Cost value: 54.34085196314396 Grad:  (Array(10.623533, dtype=float32), Array(-0.38981405, dtype=float32))
Training epoch:  10%|▉         | 98/1000 [07:03<1:03:13,  4.21s/it]Iteration 98 Predicted energy: -92.44570163791508 Cost value: 54.3896045133475 Grad:  (Array(0.8920648, dtype=float32), Array(-18.681963, dtype=float32))
Training epoch:  10%|▉         | 99/1000 [07:07<1:03:10,  4.21s/it]Iteration 99 Predicted energy: -92.441789364388 Cost value: 54.44732531240803 Grad:  (Array(24.85566, dtype=float32), Array(-1.1939595, dtype=float32))
Training epoch:  10%|█         | 100/1000 [07:11<1:03:10,  4.21s/it]Iteration 100 Predicted energy: -92.43956277505049 Cost value: 54.48018957679244 Grad:  (Array(1.1972666, dtype=float32), Array(-28.742668, dtype=float32))
Training epoch:  10%|█         | 101/1000 [07:15<1:03:04,  4.21s/it]Iteration 101 Predicted energy: -92.43777610476492 Cost value: 54.506567844718376 Grad:  (Array(30.03024, dtype=float32), Array(-1.3422325, dtype=float32))
Training epoch:  10%|█         | 102/1000 [07:20<1:02:55,  4.20s/it]Iteration 102 Predicted energy: -92.43878414656014 Cost value: 54.49168440533434 Grad:  (Array(1.4323277, dtype=float32), Array(-29.42709, dtype=float32))
Training epoch:  10%|█         | 103/1000 [07:24<1:02:47,  4.20s/it]Iteration 103 Predicted energy: -92.43964643679034 Cost value: 54.478954557529455 Grad:  (Array(27.889835, dtype=float32), Array(-1.132217, dtype=float32))
Training epoch:  10%|█         | 104/1000 [07:28<1:02:51,  4.21s/it]Iteration 104 Predicted energy: -92.44215398845893 Cost value: 54.44194443774805 Grad:  (Array(1.1152521, dtype=float32), Array(-24.999512, dtype=float32))
Training epoch:  10%|█         | 105/1000 [07:32<1:03:01,  4.23s/it]Iteration 105 Predicted energy: -92.4439636403231 Cost value: 54.41524275797503 Grad:  (Array(21.515959, dtype=float32), Array(-1.0433383, dtype=float32))
Training epoch:  11%|█         | 106/1000 [07:36<1:03:02,  4.23s/it]Iteration 106 Predicted energy: -92.4459890230127 Cost value: 54.38536570551375 Grad:  (Array(0.7783847, dtype=float32), Array(-18.623543, dtype=float32))
Training epoch:  11%|█         | 107/1000 [07:41<1:03:04,  4.24s/it]Iteration 107 Predicted energy: -92.44718351455242 Cost value: 54.36774923395489 Grad:  (Array(15.901559, dtype=float32), Array(-0.6692443, dtype=float32))
Training epoch:  11%|█         | 108/1000 [07:45<1:02:55,  4.23s/it]Iteration 108 Predicted energy: -92.4480822091213 Cost value: 54.3544970845788 Grad:  (Array(0.68931395, dtype=float32), Array(-13.465711, dtype=float32))
Training epoch:  11%|█         | 109/1000 [07:49<1:02:36,  4.22s/it]Iteration 109 Predicted energy: -92.44851782697143 Cost value: 54.348074045368115 Grad:  (Array(12.449921, dtype=float32), Array(-0.52929455, dtype=float32))
Training epoch:  11%|█         | 110/1000 [07:53<1:02:26,  4.21s/it]Iteration 110 Predicted energy: -92.44871496693544 Cost value: 54.34516740740847 Grad:  (Array(0.4940425, dtype=float32), Array(-12.07221, dtype=float32))
Training epoch:  11%|█         | 111/1000 [07:58<1:02:24,  4.21s/it]Iteration 111 Predicted energy: -92.44849397859696 Cost value: 54.34842567183726 Grad:  (Array(12.340736, dtype=float32), Array(-0.6149058, dtype=float32))
Training epoch:  11%|█         | 112/1000 [08:02<1:02:15,  4.21s/it]Iteration 112 Predicted energy: -92.44793738487279 Cost value: 54.35663255364991 Grad:  (Array(0.6426599, dtype=float32), Array(-14.15345, dtype=float32))
Training epoch:  11%|█▏        | 113/1000 [08:06<1:02:26,  4.22s/it]Iteration 113 Predicted energy: -92.44655879566785 Cost value: 54.37696228981986 Grad:  (Array(17.181772, dtype=float32), Array(-0.720605, dtype=float32))
Training epoch:  11%|█▏        | 114/1000 [08:10<1:02:12,  4.21s/it]Iteration 114 Predicted energy: -92.44415924592612 Cost value: 54.412356960734314 Grad:  (Array(1.0304145, dtype=float32), Array(-21.872887, dtype=float32))
Training epoch:  12%|█▏        | 115/1000 [08:14<1:01:52,  4.20s/it]Iteration 115 Predicted energy: -92.43874858355296 Cost value: 54.492209448047554 Grad:  (Array(28.896065, dtype=float32), Array(-1.311955, dtype=float32))
Training epoch:  12%|█▏        | 116/1000 [08:19<1:01:49,  4.20s/it]Iteration 116 Predicted energy: -92.42980395959235 Cost value: 54.624345804994725 Grad:  (Array(1.7655747, dtype=float32), Array(-39.465584, dtype=float32))
Training epoch:  12%|█▏        | 117/1000 [08:23<1:01:37,  4.19s/it]Iteration 117 Predicted energy: -92.40943496302154 Cost value: 54.92584822145284 Grad:  (Array(52.967457, dtype=float32), Array(-2.373396, dtype=float32))
Training epoch:  12%|█▏        | 118/1000 [08:27<1:01:37,  4.19s/it]Iteration 118 Predicted energy: -92.38514538406352 Cost value: 55.28646793826549 Grad:  (Array(3.2459793, dtype=float32), Array(-69.92949, dtype=float32))
Training epoch:  12%|█▏        | 119/1000 [08:31<1:01:07,  4.16s/it]Iteration 119 Predicted energy: -92.33570423915371 Cost value: 56.02415035228258 Grad:  (Array(85.591934, dtype=float32), Array(-3.8769922, dtype=float32))
Training epoch:  12%|█▏        | 120/1000 [08:35<1:01:00,  4.16s/it]Iteration 120 Predicted energy: -92.33942076763324 Cost value: 55.96852826712556 Grad:  (Array(4.213187, dtype=float32), Array(-90.90268, dtype=float32))
Training epoch:  12%|█▏        | 121/1000 [08:39<1:01:16,  4.18s/it]Iteration 121 Predicted energy: -92.34324603352971 Cost value: 55.91130765194341 Grad:  (Array(81.989204, dtype=float32), Array(-3.8648286, dtype=float32))
Training epoch:  12%|█▏        | 122/1000 [08:44<1:01:16,  4.19s/it]Iteration 122 Predicted energy: -92.41058220702335 Cost value: 54.90884463389054 Grad:  (Array(2.5030637, dtype=float32), Array(-53.523052, dtype=float32))
Training epoch:  12%|█▏        | 123/1000 [08:48<1:01:29,  4.21s/it]Iteration 123 Predicted energy: -92.44669993483821 Cost value: 54.37488076846416 Grad:  (Array(15.104276, dtype=float32), Array(-0.6050066, dtype=float32))
Training epoch:  12%|█▏        | 124/1000 [08:52<1:01:21,  4.20s/it]Iteration 124 Predicted energy: -92.44362468079368 Cost value: 54.42024365724695 Grad:  (Array(21.31551, dtype=float32), Array(-0.8565499, dtype=float32))
Training epoch:  12%|█▎        | 125/1000 [08:56<1:01:25,  4.21s/it]Iteration 125 Predicted energy: -92.41364642911981 Cost value: 54.86344194395426 Grad:  (Array(2.5507715, dtype=float32), Array(-51.896755, dtype=float32))
Training epoch:  13%|█▎        | 126/1000 [09:00<1:01:09,  4.20s/it]Iteration 126 Predicted energy: -92.3749872619405 Cost value: 55.43763229707208 Grad:  (Array(69.57621, dtype=float32), Array(-3.4387412, dtype=float32))
Training epoch:  13%|█▎        | 127/1000 [09:05<1:00:57,  4.19s/it]Iteration 127 Predicted energy: -92.38438242985539 Cost value: 55.29781439266061 Grad:  (Array(3.2811244, dtype=float32), Array(-69.870605, dtype=float32))
Training epoch:  13%|█▎        | 128/1000 [09:09<1:01:01,  4.20s/it]Iteration 128 Predicted energy: -92.40679528012707 Cost value: 54.96498161185728 Grad:  (Array(53.330193, dtype=float32), Array(-2.6961336, dtype=float32))
Training epoch:  13%|█▎        | 129/1000 [09:13<1:00:50,  4.19s/it]Iteration 129 Predicted energy: -92.44132052414767 Cost value: 54.454244529352366 Grad:  (Array(1.1850678, dtype=float32), Array(-24.598152, dtype=float32))
Training epoch:  13%|█▎        | 130/1000 [09:17<1:00:53,  4.20s/it]Iteration 130 Predicted energy: -92.44895175418436 Cost value: 54.341676311355485 Grad:  (Array(0.46999437, dtype=float32), Array(-8.18938, dtype=float32))
Training epoch:  13%|█▎        | 131/1000 [09:21<1:01:03,  4.22s/it]Iteration 131 Predicted energy: -92.43167611104572 Cost value: 54.59667580933825 Grad:  (Array(35.398224, dtype=float32), Array(-1.6409837, dtype=float32))
Training epoch:  13%|█▎        | 132/1000 [09:26<1:00:43,  4.20s/it]Iteration 132 Predicted energy: -92.41233389635421 Cost value: 54.88288749039534 Grad:  (Array(2.5156257, dtype=float32), Array(-52.931206, dtype=float32))
Training epoch:  13%|█▎        | 133/1000 [09:30<1:00:31,  4.19s/it]Iteration 133 Predicted energy: -92.40015602660952 Cost value: 55.06347038058905 Grad:  (Array(57.50992, dtype=float32), Array(-2.8570426, dtype=float32))
Training epoch:  13%|█▎        | 134/1000 [09:34<1:00:31,  4.19s/it]Iteration 134 Predicted energy: -92.41889278240753 Cost value: 54.78575013723008 Grad:  (Array(2.196204, dtype=float32), Array(-47.9481, dtype=float32))
Training epoch:  14%|█▎        | 135/1000 [09:38<1:00:20,  4.19s/it]Iteration 135 Predicted energy: -92.43833367366072 Cost value: 54.49833525347863 Grad:  (Array(28.73664, dtype=float32), Array(-1.4289838, dtype=float32))
Training epoch:  14%|█▎        | 136/1000 [09:42<1:00:35,  4.21s/it]Iteration 136 Predicted energy: -92.44996099871753 Cost value: 54.326797673040886 Grad:  (Array(0.21748772, dtype=float32), Array(-5.341924, dtype=float32))
Training epoch:  14%|█▎        | 137/1000 [09:47<1:01:04,  4.25s/it]Iteration 137 Predicted energy: -92.44623144724808 Cost value: 54.38179017969427 Grad:  (Array(0.8074913, dtype=float32), Array(-17.530216, dtype=float32))
Training epoch:  14%|█▍        | 138/1000 [09:51<1:00:49,  4.23s/it]Iteration 138 Predicted energy: -92.43302182791346 Cost value: 54.57679073392587 Grad:  (Array(34.47292, dtype=float32), Array(-1.6042205, dtype=float32))
Training epoch:  14%|█▍        | 139/1000 [09:55<1:00:37,  4.22s/it]Iteration 139 Predicted energy: -92.42402505083656 Cost value: 54.70980104775634 Grad:  (Array(2.0987005, dtype=float32), Array(-44.07301, dtype=float32))
Training epoch:  14%|█▍        | 140/1000 [09:59<1:00:16,  4.20s/it]Iteration 140 Predicted energy: -92.42016529208121 Cost value: 54.76691418584753 Grad:  (Array(45.537178, dtype=float32), Array(-2.1183386, dtype=float32))
Training epoch:  14%|█▍        | 141/1000 [10:03<59:36,  4.16s/it]  Iteration 141 Predicted energy: -92.43074709770468 Cost value: 54.6104055504383 Grad:  (Array(1.7526466, dtype=float32), Array(-37.91175, dtype=float32))
Training epoch:  14%|█▍        | 142/1000 [10:08<59:39,  4.17s/it]Iteration 142 Predicted energy: -92.44143251676046 Cost value: 54.452591685047956 Grad:  (Array(25.173893, dtype=float32), Array(-1.2493967, dtype=float32))
Training epoch:  14%|█▍        | 143/1000 [10:12<59:31,  4.17s/it]Iteration 143 Predicted energy: -92.44928270298362 Cost value: 54.336797123131625 Grad:  (Array(0.37565753, dtype=float32), Array(-9.757103, dtype=float32))
Training epoch:  14%|█▍        | 144/1000 [10:16<59:05,  4.14s/it]Iteration 144 Predicted energy: -92.45014199565905 Cost value: 54.32412956782073 Grad:  (Array(0.26099932, dtype=float32), Array(-6.124193, dtype=float32))
Training epoch:  14%|█▍        | 145/1000 [10:20<59:23,  4.17s/it]Iteration 145 Predicted energy: -92.44536777869915 Cost value: 54.39452900204774 Grad:  (Array(19.241198, dtype=float32), Array(-0.851453, dtype=float32))
Training epoch:  15%|█▍        | 146/1000 [10:24<59:19,  4.17s/it]Iteration 146 Predicted energy: -92.43886262276484 Cost value: 54.49052581261539 Grad:  (Array(1.4305546, dtype=float32), Array(-29.263128, dtype=float32))
Training epoch:  15%|█▍        | 147/1000 [10:28<59:17,  4.17s/it]Iteration 147 Predicted energy: -92.43242548081986 Cost value: 54.58560224980451 Grad:  (Array(35.501778, dtype=float32), Array(-1.6252526, dtype=float32))
Training epoch:  15%|█▍        | 148/1000 [10:33<59:35,  4.20s/it]Iteration 148 Predicted energy: -92.43189459815862 Cost value: 54.59344707359824 Grad:  (Array(1.7038765, dtype=float32), Array(-37.155853, dtype=float32))
Training epoch:  15%|█▍        | 149/1000 [10:37<59:44,  4.21s/it]Iteration 149 Predicted energy: -92.43302274722518 Cost value: 54.5767771508927 Grad:  (Array(34.76314, dtype=float32), Array(-1.6483871, dtype=float32))
Training epoch:  15%|█▌        | 150/1000 [10:41<59:39,  4.21s/it]Iteration 150 Predicted energy: -92.43919301238043 Cost value: 54.485648201580226 Grad:  (Array(1.3308374, dtype=float32), Array(-28.89288, dtype=float32))
Training epoch:  15%|█▌        | 151/1000 [10:45<59:32,  4.21s/it]Iteration 151 Predicted energy: -92.44446666112707 Cost value: 54.407821775252486 Grad:  (Array(20.891245, dtype=float32), Array(-0.93700725, dtype=float32))
Training epoch:  15%|█▌        | 152/1000 [10:50<59:26,  4.21s/it]Iteration 152 Predicted energy: -92.44866235719282 Cost value: 54.34594307953933 Grad:  (Array(0.5982321, dtype=float32), Array(-11.836966, dtype=float32))
Training epoch:  15%|█▌        | 153/1000 [10:54<59:55,  4.24s/it]Iteration 153 Predicted energy: -92.45048157056728 Cost value: 54.31912401589124 Grad:  (Array(3.0212069, dtype=float32), Array(-0.10185809, dtype=float32))
Training epoch:  15%|█▌        | 154/1000 [10:58<59:32,  4.22s/it]Iteration 154 Predicted energy: -92.45029776050083 Cost value: 54.321833465523866 Grad:  (Array(5.028041, dtype=float32), Array(-0.21307561, dtype=float32))
Training epoch:  16%|█▌        | 155/1000 [11:02<59:17,  4.21s/it]Iteration 155 Predicted energy: -92.44858260901881 Cost value: 54.347118888206836 Grad:  (Array(0.58304125, dtype=float32), Array(-12.383925, dtype=float32))
Training epoch:  16%|█▌        | 156/1000 [11:06<59:15,  4.21s/it]Iteration 156 Predicted energy: -92.44579025840504 Cost value: 54.38829738123673 Grad:  (Array(18.444923, dtype=float32), Array(-0.85802984, dtype=float32))
Training epoch:  16%|█▌        | 157/1000 [11:11<59:14,  4.22s/it]Iteration 157 Predicted energy: -92.44285086234645 Cost value: 54.431661185439445 Grad:  (Array(1.104458, dtype=float32), Array(-23.937233, dtype=float32))
Training epoch:  16%|█▌        | 158/1000 [11:15<58:59,  4.20s/it]Iteration 158 Predicted energy: -92.43894628620157 Cost value: 54.48929065114888 Grad:  (Array(28.616554, dtype=float32), Array(-1.3380727, dtype=float32))
Training epoch:  16%|█▌        | 159/1000 [11:19<59:05,  4.22s/it]Iteration 159 Predicted energy: -92.43599100255108 Cost value: 54.532929337728376 Grad:  (Array(1.537992, dtype=float32), Array(-32.77673, dtype=float32))
Training epoch:  16%|█▌        | 160/1000 [11:23<59:03,  4.22s/it]Iteration 160 Predicted energy: -92.43121559956431 Cost value: 54.60348141987038 Grad:  (Array(36.71119, dtype=float32), Array(-1.6758653, dtype=float32))
Training epoch:  16%|█▌        | 161/1000 [11:28<58:59,  4.22s/it]Iteration 161 Predicted energy: -92.42898887204498 Cost value: 54.63639481390028 Grad:  (Array(1.8826714, dtype=float32), Array(-39.92806, dtype=float32))
Training epoch:  16%|█▌        | 162/1000 [11:32<58:54,  4.22s/it]Iteration 162 Predicted energy: -92.42399316729855 Cost value: 54.71027270879941 Grad:  (Array(42.705963, dtype=float32), Array(-1.9817152, dtype=float32))
Training epoch:  16%|█▋        | 163/1000 [11:36<58:53,  4.22s/it]Iteration 163 Predicted energy: -92.4239451737127 Cost value: 54.71098269358786 Grad:  (Array(2.0475602, dtype=float32), Array(-44.384098, dtype=float32))
Training epoch:  16%|█▋        | 164/1000 [11:40<58:32,  4.20s/it]Iteration 164 Predicted energy: -92.42102203298307 Cost value: 54.754234354034764 Grad:  (Array(44.845303, dtype=float32), Array(-2.1198685, dtype=float32))
Training epoch:  16%|█▋        | 165/1000 [11:44<58:18,  4.19s/it]Iteration 165 Predicted energy: -92.42457107126043 Cost value: 54.70172394847784 Grad:  (Array(2.0600164, dtype=float32), Array(-43.735252, dtype=float32))
Training epoch:  17%|█▋        | 166/1000 [11:48<58:13,  4.19s/it]Iteration 166 Predicted energy: -92.42553249224117 Cost value: 54.68750341563541 Grad:  (Array(41.377274, dtype=float32), Array(-1.9186465, dtype=float32))
Training epoch:  17%|█▋        | 167/1000 [11:53<58:00,  4.18s/it]Iteration 167 Predicted energy: -92.43131055512546 Cost value: 54.60207809643929 Grad:  (Array(1.8077413, dtype=float32), Array(-37.6017, dtype=float32))
Training epoch:  17%|█▋        | 168/1000 [11:57<57:59,  4.18s/it]Iteration 168 Predicted energy: -92.43476617890457 Cost value: 54.55102060485804 Grad:  (Array(32.975452, dtype=float32), Array(-1.5466985, dtype=float32))
Training epoch:  17%|█▋        | 169/1000 [12:01<57:53,  4.18s/it]Iteration 169 Predicted energy: -92.439880581333 Cost value: 54.47549817716328 Grad:  (Array(1.3222356, dtype=float32), Array(-27.969698, dtype=float32))
Training epoch:  17%|█▋        | 170/1000 [12:05<58:04,  4.20s/it]Iteration 170 Predicted energy: -92.44312945713172 Cost value: 54.42755044009897 Grad:  (Array(22.805504, dtype=float32), Array(-1.1027961, dtype=float32))
Training epoch:  17%|█▋        | 171/1000 [12:09<58:00,  4.20s/it]Iteration 171 Predicted energy: -92.44610811517205 Cost value: 54.38360919527586 Grad:  (Array(0.84303564, dtype=float32), Array(-18.053406, dtype=float32))
Training epoch:  17%|█▋        | 172/1000 [12:14<57:47,  4.19s/it]Iteration 172 Predicted energy: -92.44790560128958 Cost value: 54.35710121599441 Grad:  (Array(13.813605, dtype=float32), Array(-0.6735369, dtype=float32))
Training epoch:  17%|█▋        | 173/1000 [12:18<57:32,  4.17s/it]Iteration 173 Predicted energy: -92.4491427075673 Cost value: 54.33886105308425 Grad:  (Array(0.48327586, dtype=float32), Array(-10.457927, dtype=float32))
Training epoch:  17%|█▋        | 174/1000 [12:22<57:24,  4.17s/it]Iteration 174 Predicted energy: -92.44983067205118 Cost value: 54.328718880104496 Grad:  (Array(7.5403137, dtype=float32), Array(-0.3685937, dtype=float32))
Training epoch:  18%|█▊        | 175/1000 [12:26<57:26,  4.18s/it]Iteration 175 Predicted energy: -92.45024279886158 Cost value: 54.32264363989759 Grad:  (Array(0.24936631, dtype=float32), Array(-5.563262, dtype=float32))
Training epoch:  18%|█▊        | 176/1000 [12:30<57:20,  4.17s/it]Iteration 176 Predicted energy: -92.45045554047876 Cost value: 54.319507707928516 Grad:  (Array(3.997284, dtype=float32), Array(-0.20986935, dtype=float32))
Training epoch:  18%|█▊        | 177/1000 [12:34<57:22,  4.18s/it]Iteration 177 Predicted energy: -92.45056488399322 Cost value: 54.31789595779301 Grad:  (Array(0.10516924, dtype=float32), Array(-2.892655, dtype=float32))
Training epoch:  18%|█▊        | 178/1000 [12:39<57:34,  4.20s/it]Iteration 178 Predicted energy: -92.45061968148538 Cost value: 54.3170882383563 Grad:  (Array(2.2398567, dtype=float32), Array(-0.13393791, dtype=float32))
Training epoch:  18%|█▊        | 179/1000 [12:43<57:35,  4.21s/it]Iteration 179 Predicted energy: -92.45064275041585 Cost value: 54.31674820226407 Grad:  (Array(0.0748542, dtype=float32), Array(-1.810749, dtype=float32))
Training epoch:  18%|█▊        | 180/1000 [12:47<57:42,  4.22s/it]Iteration 180 Predicted energy: -92.45064797391329 Cost value: 54.31667120804669 Grad:  (Array(1.7060947, dtype=float32), Array(-0.07864839, dtype=float32))
Training epoch:  18%|█▊        | 181/1000 [12:51<57:46,  4.23s/it]Iteration 181 Predicted energy: -92.45064439907435 Cost value: 54.3167239010745 Grad:  (Array(0.08681064, dtype=float32), Array(-1.7729521, dtype=float32))
Training epoch:  18%|█▊        | 182/1000 [12:56<57:45,  4.24s/it]Iteration 182 Predicted energy: -92.45062736226294 Cost value: 54.31697502355792 Grad:  (Array(2.1641808, dtype=float32), Array(-0.10449201, dtype=float32))
Training epoch:  18%|█▊        | 183/1000 [13:00<57:43,  4.24s/it]Iteration 183 Predicted energy: -92.45058296907594 Cost value: 54.31762938155691 Grad:  (Array(0.11866129, dtype=float32), Array(-2.817212, dtype=float32))
Training epoch:  18%|█▊        | 184/1000 [13:04<57:39,  4.24s/it]Iteration 184 Predicted energy: -92.45048171279052 Cost value: 54.319121919477745 Grad:  (Array(3.909359, dtype=float32), Array(-0.18991312, dtype=float32))
Training epoch:  18%|█▊        | 185/1000 [13:08<57:19,  4.22s/it]Iteration 185 Predicted energy: -92.4502597538142 Cost value: 54.32239371097044 Grad:  (Array(0.26487675, dtype=float32), Array(-5.6126413, dtype=float32))
Training epoch:  19%|█▊        | 186/1000 [13:13<57:20,  4.23s/it]Iteration 186 Predicted energy: -92.44974160245914 Cost value: 54.330031916652935 Grad:  (Array(8.273662, dtype=float32), Array(-0.3702893, dtype=float32))
Training epoch:  19%|█▊        | 187/1000 [13:17<57:02,  4.21s/it]Iteration 187 Predicted energy: -92.44858238400482 Cost value: 54.3471222058356 Grad:  (Array(0.5887916, dtype=float32), Array(-12.374456, dtype=float32))
Training epoch:  19%|█▉        | 188/1000 [13:21<56:53,  4.20s/it]Iteration 188 Predicted energy: -92.44573621545396 Cost value: 54.38909450062913 Grad:  (Array(18.718224, dtype=float32), Array(-0.8614115, dtype=float32))
Training epoch:  19%|█▉        | 189/1000 [13:25<56:59,  4.22s/it]Iteration 189 Predicted energy: -92.43946089847512 Cost value: 54.48169350337381 Grad:  (Array(1.3423436, dtype=float32), Array(-28.683983, dtype=float32))
Training epoch:  19%|█▉        | 190/1000 [13:29<56:41,  4.20s/it]Iteration 190 Predicted energy: -92.42315787504646 Cost value: 54.7226301174847 Grad:  (Array(43.406784, dtype=float32), Array(-2.010356, dtype=float32))
Training epoch:  19%|█▉        | 191/1000 [13:34<56:48,  4.21s/it]Iteration 191 Predicted energy: -92.39268171464742 Cost value: 55.174452157350714 Grad:  (Array(3.1075518, dtype=float32), Array(-65.676765, dtype=float32))
Training epoch:  19%|█▉        | 192/1000 [13:38<57:07,  4.24s/it]Iteration 192 Predicted energy: -92.316188320576 Cost value: 56.31668172248648 Grad:  (Array(91.66013, dtype=float32), Array(-4.2929435, dtype=float32))
Training epoch:  19%|█▉        | 193/1000 [13:42<56:47,  4.22s/it]Iteration 193 Predicted energy: -92.27051981678854 Cost value: 57.00420080520722 Grad:  (Array(5.609737, dtype=float32), Array(-115.484634, dtype=float32))
Training epoch:  19%|█▉        | 194/1000 [13:46<56:34,  4.21s/it]Iteration 194 Predicted energy: -92.19101150819603 Cost value: 58.21111574696836 Grad:  (Array(120.11974, dtype=float32), Array(-5.854837, dtype=float32))
Training epoch:  20%|█▉        | 195/1000 [13:50<56:24,  4.20s/it]Iteration 195 Predicted energy: -92.35561497498352 Cost value: 55.72648593297952 Grad:  (Array(4.013573, dtype=float32), Array(-81.57234, dtype=float32))
Training epoch:  20%|█▉        | 196/1000 [13:55<56:30,  4.22s/it]Iteration 196 Predicted energy: -92.43993981274276 Cost value: 54.47462383599479 Grad:  (Array(21.903236, dtype=float32), Array(-0.89020354, dtype=float32))
Training epoch:  20%|█▉        | 197/1000 [13:59<56:27,  4.22s/it]Iteration 197 Predicted energy: -92.43152311280276 Cost value: 54.598936827421575 Grad:  (Array(33.637596, dtype=float32), Array(-1.378108, dtype=float32))
Training epoch:  20%|█▉        | 198/1000 [14:03<56:16,  4.21s/it]Iteration 198 Predicted energy: -92.3618791103445 Cost value: 55.63300141247444 Grad:  (Array(4.20551, dtype=float32), Array(-79.786224, dtype=float32))
Training epoch:  20%|█▉        | 199/1000 [14:07<56:10,  4.21s/it]Iteration 199 Predicted energy: -92.27469729918698 Cost value: 56.94113733128618 Grad:  (Array(101.14356, dtype=float32), Array(-5.3595195, dtype=float32))
Training epoch:  20%|██        | 200/1000 [14:12<56:05,  4.21s/it]Iteration 200 Predicted energy: -92.34944894251134 Cost value: 55.818583033273995 Grad:  (Array(4.24833, dtype=float32), Array(-85.446434, dtype=float32))
Training epoch:  20%|██        | 201/1000 [14:16<56:21,  4.23s/it]Iteration 201 Predicted energy: -92.41925155429489 Cost value: 54.78043919372524 Grad:  (Array(42.830437, dtype=float32), Array(-2.3274248, dtype=float32))
Training epoch:  20%|██        | 202/1000 [14:20<56:25,  4.24s/it]Iteration 202 Predicted energy: -92.44710318564843 Cost value: 54.368933842551186 Grad:  (Array(6.668065, dtype=float32), Array(-0.6641435, dtype=float32))
Training epoch:  20%|██        | 203/1000 [14:24<56:08,  4.23s/it]Iteration 203 Predicted energy: -92.40969856802187 Cost value: 54.92194103350739 Grad:  (Array(2.8744738, dtype=float32), Array(-52.649704, dtype=float32))
Training epoch:  20%|██        | 204/1000 [14:29<56:19,  4.25s/it]Iteration 204 Predicted energy: -92.34966734054598 Cost value: 55.815319697381966 Grad:  (Array(78.706696, dtype=float32), Array(-3.965812, dtype=float32))
Training epoch:  20%|██        | 205/1000 [14:33<56:19,  4.25s/it]Iteration 205 Predicted energy: -92.37336803160474 Cost value: 55.46174734810128 Grad:  (Array(3.6642988, dtype=float32), Array(-74.50399, dtype=float32))
Training epoch:  21%|██        | 206/1000 [14:37<56:08,  4.24s/it]Iteration 206 Predicted energy: -92.41370695070738 Cost value: 54.862545382510675 Grad:  (Array(48.38507, dtype=float32), Array(-2.683237, dtype=float32))
Training epoch:  21%|██        | 207/1000 [14:41<55:55,  4.23s/it]Iteration 207 Predicted energy: -92.44768405314923 Cost value: 54.36036809292412 Grad:  (Array(0.4015305, dtype=float32), Array(-11.079113, dtype=float32))
Training epoch:  21%|██        | 208/1000 [14:45<55:38,  4.22s/it]Iteration 208 Predicted energy: -92.43834573175344 Cost value: 54.49815722073769 Grad:  (Array(1.368936, dtype=float32), Array(-28.236162, dtype=float32))
Training epoch:  21%|██        | 209/1000 [14:50<55:57,  4.25s/it]Iteration 209 Predicted energy: -92.40437584743731 Cost value: 55.000862025532506 Grad:  (Array(54.661133, dtype=float32), Array(-2.6273258, dtype=float32))
Training epoch:  21%|██        | 210/1000 [14:54<55:53,  4.25s/it]Iteration 210 Predicted energy: -92.3971475640054 Cost value: 55.10812788309783 Grad:  (Array(3.0295434, dtype=float32), Array(-61.94423, dtype=float32))
Training epoch:  21%|██        | 211/1000 [14:58<55:54,  4.25s/it]Iteration 211 Predicted energy: -92.40926207156723 Cost value: 54.92841091676844 Grad:  (Array(51.619698, dtype=float32), Array(-2.584559, dtype=float32))
Training epoch:  21%|██        | 212/1000 [15:02<55:36,  4.23s/it]Iteration 212 Predicted energy: -92.44007721453275 Cost value: 54.4725956141141 Grad:  (Array(1.2712687, dtype=float32), Array(-26.638496, dtype=float32))
Training epoch:  21%|██▏       | 213/1000 [15:07<55:29,  4.23s/it]Iteration 213 Predicted energy: -92.44993641110705 Cost value: 54.32716012804282 Grad:  (Array(0.2812681, dtype=float32), Array(-3.243598, dtype=float32))
Training epoch:  21%|██▏       | 214/1000 [15:11<55:09,  4.21s/it]Iteration 214 Predicted energy: -92.43752795862495 Cost value: 54.5102319609039 Grad:  (Array(29.347387, dtype=float32), Array(-1.4676532, dtype=float32))
Training epoch:  22%|██▏       | 215/1000 [15:15<55:01,  4.21s/it]Iteration 215 Predicted energy: -92.4216054598806 Cost value: 54.74560043092239 Grad:  (Array(2.0735793, dtype=float32), Array(-46.280727, dtype=float32))
Training epoch:  22%|██▏       | 216/1000 [15:19<55:04,  4.22s/it]Iteration 216 Predicted energy: -92.41261082916665 Cost value: 54.87878436517827 Grad:  (Array(50.04151, dtype=float32), Array(-2.575381, dtype=float32))
Training epoch:  22%|██▏       | 217/1000 [15:24<55:10,  4.23s/it]Iteration 217 Predicted energy: -92.42702675852631 Cost value: 54.66540515137683 Grad:  (Array(2.009172, dtype=float32), Array(-41.062447, dtype=float32))
Training epoch:  22%|██▏       | 218/1000 [15:28<55:05,  4.23s/it]Iteration 218 Predicted energy: -92.44257127197687 Cost value: 54.435786776972805 Grad:  (Array(23.663765, dtype=float32), Array(-0.9875522, dtype=float32))
Training epoch:  22%|██▏       | 219/1000 [15:32<55:02,  4.23s/it]Iteration 219 Predicted energy: -92.45041499726615 Cost value: 54.3201053308712 Grad:  (Array(0.20608215, dtype=float32), Array(-2.0751152, dtype=float32))
Training epoch:  22%|██▏       | 220/1000 [15:36<54:50,  4.22s/it]Iteration 220 Predicted energy: -92.44590736533546 Cost value: 54.386570104687536 Grad:  (Array(0.8117137, dtype=float32), Array(-18.385574, dtype=float32))
Training epoch:  22%|██▏       | 221/1000 [15:40<54:34,  4.20s/it]Iteration 221 Predicted energy: -92.43540614360468 Cost value: 54.54156762702371 Grad:  (Array(32.063156, dtype=float32), Array(-1.6444688, dtype=float32))
Training epoch:  22%|██▏       | 222/1000 [15:45<54:37,  4.21s/it]Iteration 222 Predicted energy: -92.43073910111846 Cost value: 54.610523738213026 Grad:  (Array(1.7699623, dtype=float32), Array(-37.8083, dtype=float32))
Training epoch:  22%|██▏       | 223/1000 [15:49<54:29,  4.21s/it]Iteration 223 Predicted energy: -92.43203532656065 Cost value: 54.59136748286033 Grad:  (Array(35.800194, dtype=float32), Array(-1.6311078, dtype=float32))
Training epoch:  22%|██▏       | 224/1000 [15:53<54:27,  4.21s/it]Iteration 224 Predicted energy: -92.44141007939102 Cost value: 54.452922825221606 Grad:  (Array(1.3160683, dtype=float32), Array(-25.85619, dtype=float32))
Training epoch:  22%|██▎       | 225/1000 [15:57<54:53,  4.25s/it]Iteration 225 Predicted energy: -92.44846191693246 Cost value: 54.348898398925954 Grad:  (Array(11.737203, dtype=float32), Array(-0.50556666, dtype=float32))
Training epoch:  23%|██▎       | 226/1000 [16:01<54:23,  4.22s/it]Iteration 226 Predicted energy: -92.45044867048809 Cost value: 54.319608974068956 Grad:  (Array(2.3284044, dtype=float32), Array(-0.1753143, dtype=float32))
Training epoch:  23%|██▎       | 227/1000 [16:06<54:19,  4.22s/it]Iteration 227 Predicted energy: -92.44732411928247 Cost value: 54.365675770129805 Grad:  (Array(0.74903154, dtype=float32), Array(-15.416884, dtype=float32))
Training epoch:  23%|██▎       | 228/1000 [16:10<54:04,  4.20s/it]Iteration 228 Predicted energy: -92.44193543519671 Cost value: 54.44516966659038 Grad:  (Array(24.755054, dtype=float32), Array(-1.1411499, dtype=float32))
Training epoch:  23%|██▎       | 229/1000 [16:14<54:02,  4.21s/it]Iteration 229 Predicted energy: -92.4390438923212 Cost value: 54.48784966518997 Grad:  (Array(1.3969424, dtype=float32), Array(-28.99121, dtype=float32))
Training epoch:  23%|██▎       | 230/1000 [16:18<54:12,  4.22s/it]Iteration 230 Predicted energy: -92.43844087141022 Cost value: 54.49675253333962 Grad:  (Array(29.02101, dtype=float32), Array(-1.3577257, dtype=float32))
Training epoch:  23%|██▎       | 231/1000 [16:22<53:52,  4.20s/it]Iteration 231 Predicted energy: -92.44211562611508 Cost value: 54.44251055067545 Grad:  (Array(1.1855584, dtype=float32), Array(-25.023455, dtype=float32))
Training epoch:  23%|██▎       | 232/1000 [16:27<53:43,  4.20s/it]Iteration 232 Predicted energy: -92.44605279034538 Cost value: 54.384425186898206 Grad:  (Array(17.983423, dtype=float32), Array(-0.82576793, dtype=float32))
Training epoch:  23%|██▎       | 233/1000 [16:31<53:32,  4.19s/it]Iteration 233 Predicted energy: -92.44941059404984 Cost value: 54.334911679930066 Grad:  (Array(0.43836445, dtype=float32), Array(-9.224433, dtype=float32))
Training epoch:  23%|██▎       | 234/1000 [16:35<53:11,  4.17s/it]Iteration 234 Predicted energy: -92.45065897164677 Cost value: 54.31650910191752 Grad:  (Array(0.40690517, dtype=float32), Array(-0.08947941, dtype=float32))
Training epoch:  24%|██▎       | 235/1000 [16:39<53:24,  4.19s/it]Iteration 235 Predicted energy: -92.4498423349765 Cost value: 54.328546950019145 Grad:  (Array(7.645294, dtype=float32), Array(-0.3447941, dtype=float32))
Training epoch:  24%|██▎       | 236/1000 [16:43<53:14,  4.18s/it]Iteration 236 Predicted energy: -92.44783241054593 Cost value: 54.35818045207316 Grad:  (Array(0.69430894, dtype=float32), Array(-14.275221, dtype=float32))
Training epoch:  24%|██▎       | 237/1000 [16:48<53:20,  4.20s/it]Iteration 237 Predicted energy: -92.44554847528336 Cost value: 54.39186366443077 Grad:  (Array(18.958447, dtype=float32), Array(-0.89837605, dtype=float32))
Training epoch:  24%|██▍       | 238/1000 [16:52<53:05,  4.18s/it]Iteration 238 Predicted energy: -92.44431173645303 Cost value: 54.41010729941572 Grad:  (Array(0.970118, dtype=float32), Array(-21.454523, dtype=float32))
Training epoch:  24%|██▍       | 239/1000 [16:56<53:05,  4.19s/it]Iteration 239 Predicted energy: -92.44371168088621 Cost value: 54.41896006409851 Grad:  (Array(21.970345, dtype=float32), Array(-1.0897648, dtype=float32))
Training epoch:  24%|██▍       | 240/1000 [17:00<53:00,  4.19s/it]Iteration 240 Predicted energy: -92.44480633875885 Cost value: 54.402810853578345 Grad:  (Array(0.9874441, dtype=float32), Array(-20.544085, dtype=float32))
Training epoch:  24%|██▍       | 241/1000 [17:04<53:03,  4.19s/it]Iteration 241 Predicted energy: -92.44616886391013 Cost value: 54.38271321287147 Grad:  (Array(17.769573, dtype=float32), Array(-0.7884761, dtype=float32))
Training epoch:  24%|██▍       | 242/1000 [17:09<52:57,  4.19s/it]Iteration 242 Predicted energy: -92.44798203916955 Cost value: 54.35597411061704 Grad:  (Array(0.70372266, dtype=float32), Array(-13.91163, dtype=float32))
Training epoch:  24%|██▍       | 243/1000 [17:13<52:53,  4.19s/it]Iteration 243 Predicted energy: -92.44934851901239 Cost value: 54.335826821529125 Grad:  (Array(9.611859, dtype=float32), Array(-0.4873085, dtype=float32))
Training epoch:  24%|██▍       | 244/1000 [17:17<53:05,  4.21s/it]Iteration 244 Predicted energy: -92.45025613415507 Cost value: 54.32244706745713 Grad:  (Array(0.19821464, dtype=float32), Array(-5.5140657, dtype=float32))
Training epoch:  24%|██▍       | 245/1000 [17:21<53:01,  4.21s/it]Iteration 245 Predicted energy: -92.45065078534832 Cost value: 54.31662976758962 Grad:  (Array(1.2613478, dtype=float32), Array(-0.09484825, dtype=float32))
Training epoch:  25%|██▍       | 246/1000 [17:25<52:54,  4.21s/it]Iteration 246 Predicted energy: -92.45060520378462 Cost value: 54.317301640244864 Grad:  (Array(2.4606638, dtype=float32), Array(-0.09815403, dtype=float32))
Training epoch:  25%|██▍       | 247/1000 [17:30<52:58,  4.22s/it]Iteration 247 Predicted energy: -92.4502237963723 Cost value: 54.32292375175946 Grad:  (Array(0.30262724, dtype=float32), Array(-5.6943426, dtype=float32))
Training epoch:  25%|██▍       | 248/1000 [17:34<53:02,  4.23s/it]Iteration 248 Predicted energy: -92.4496271253073 Cost value: 54.33171952693992 Grad:  (Array(8.606742, dtype=float32), Array(-0.40908632, dtype=float32))
Training epoch:  25%|██▍       | 249/1000 [17:38<52:45,  4.22s/it]Iteration 249 Predicted energy: -92.44894602780984 Cost value: 54.34176073739739 Grad:  (Array(0.5071383, dtype=float32), Array(-11.217827, dtype=float32))
Training epoch:  25%|██▌       | 250/1000 [17:42<52:35,  4.21s/it]Iteration 250 Predicted energy: -92.44809908688543 Cost value: 54.35424822053545 Grad:  (Array(13.520643, dtype=float32), Array(-0.6589001, dtype=float32))
Training epoch:  25%|██▌       | 251/1000 [17:46<52:34,  4.21s/it]Iteration 251 Predicted energy: -92.44724670607891 Cost value: 54.3668173589603 Grad:  (Array(0.7428535, dtype=float32), Array(-15.720753, dtype=float32))
Training epoch:  25%|██▌       | 252/1000 [17:51<52:35,  4.22s/it]Iteration 252 Predicted energy: -92.44601372634231 Cost value: 54.385001349629164 Grad:  (Array(18.095255, dtype=float32), Array(-0.86806107, dtype=float32))
Training epoch:  25%|██▌       | 253/1000 [17:55<52:27,  4.21s/it]Iteration 253 Predicted energy: -92.44478865750298 Cost value: 54.40307168162848 Grad:  (Array(0.9581344, dtype=float32), Array(-20.730354, dtype=float32))
Training epoch:  25%|██▌       | 254/1000 [17:59<52:19,  4.21s/it]Iteration 254 Predicted energy: -92.44266176634109 Cost value: 54.43445143925077 Grad:  (Array(23.614388, dtype=float32), Array(-1.131126, dtype=float32))
Training epoch:  26%|██▌       | 255/1000 [18:03<52:25,  4.22s/it]Iteration 255 Predicted energy: -92.44057278355271 Cost value: 54.4652807106511 Grad:  (Array(1.3016454, dtype=float32), Array(-27.052013, dtype=float32))
Training epoch:  26%|██▌       | 256/1000 [18:08<52:23,  4.22s/it]Iteration 256 Predicted energy: -92.43664418721936 Cost value: 54.52328269522746 Grad:  (Array(31.172432, dtype=float32), Array(-1.4424405, dtype=float32))
Training epoch:  26%|██▌       | 257/1000 [18:12<52:21,  4.23s/it]Iteration 257 Predicted energy: -92.43317509453956 Cost value: 54.57452620910592 Grad:  (Array(1.7123528, dtype=float32), Array(-35.72905, dtype=float32))
Training epoch:  26%|██▌       | 258/1000 [18:16<52:08,  4.22s/it]Iteration 258 Predicted energy: -92.42608888162435 Cost value: 54.679274614994206 Grad:  (Array(40.860794, dtype=float32), Array(-1.9561076, dtype=float32))
Training epoch:  26%|██▌       | 259/1000 [18:20<52:04,  4.22s/it]Iteration 259 Predicted energy: -92.42130642354041 Cost value: 54.750025676250395 Grad:  (Array(2.2011137, dtype=float32), Array(-46.409603, dtype=float32))
Training epoch:  26%|██▌       | 260/1000 [18:24<51:55,  4.21s/it]Iteration 260 Predicted energy: -92.41062145782847 Cost value: 54.908262934555026 Grad:  (Array(51.732975, dtype=float32), Array(-2.4621277, dtype=float32))
Training epoch:  26%|██▌       | 261/1000 [18:29<51:52,  4.21s/it]Iteration 261 Predicted energy: -92.40791418710548 Cost value: 54.94839207551325 Grad:  (Array(2.7220137, dtype=float32), Array(-55.956535, dtype=float32))
Training epoch:  26%|██▌       | 262/1000 [18:33<51:58,  4.23s/it]Iteration 262 Predicted energy: -92.398581421387 Cost value: 55.086841501836986 Grad:  (Array(58.478893, dtype=float32), Array(-2.785697, dtype=float32))
Training epoch:  26%|██▋       | 263/1000 [18:37<51:44,  4.21s/it]Iteration 263 Predicted energy: -92.40505993050881 Cost value: 54.99071582230784 Grad:  (Array(2.815311, dtype=float32), Array(-57.70471, dtype=float32))
Training epoch:  26%|██▋       | 264/1000 [18:41<51:28,  4.20s/it]Iteration 264 Predicted energy: -92.40642177672505 Cost value: 54.970519938173496 Grad:  (Array(53.89993, dtype=float32), Array(-2.6039395, dtype=float32))
Training epoch:  26%|██▋       | 265/1000 [18:45<51:30,  4.20s/it]Iteration 265 Predicted energy: -92.42041015848307 Cost value: 54.763289994276036 Grad:  (Array(2.3011446, dtype=float32), Array(-46.743732, dtype=float32))
Training epoch:  27%|██▋       | 266/1000 [18:50<51:39,  4.22s/it]Iteration 266 Predicted energy: -92.42951151138955 Cost value: 54.62866875954031 Grad:  (Array(37.585526, dtype=float32), Array(-1.8138789, dtype=float32))
Training epoch:  27%|██▋       | 267/1000 [18:54<51:28,  4.21s/it]Iteration 267 Predicted energy: -92.43992687418309 Cost value: 54.47481482722655 Grad:  (Array(1.370032, dtype=float32), Array(-27.664661, dtype=float32))
Training epoch:  27%|██▋       | 268/1000 [18:58<51:24,  4.21s/it]Iteration 268 Predicted energy: -92.44610731757895 Cost value: 54.38362095901599 Grad:  (Array(17.378735, dtype=float32), Array(-0.8512633, dtype=float32))
Training epoch:  27%|██▋       | 269/1000 [19:02<51:01,  4.19s/it]Iteration 269 Predicted energy: -92.44962020130922 Cost value: 54.33182160064141 Grad:  (Array(0.388413, dtype=float32), Array(-8.320796, dtype=float32))
Training epoch:  27%|██▋       | 270/1000 [19:06<50:57,  4.19s/it]Iteration 270 Predicted energy: -92.45060376970532 Cost value: 54.317322778653875 Grad:  (Array(0.02564324, dtype=float32), Array(-0.3664465, dtype=float32))
Training epoch:  27%|██▋       | 271/1000 [19:11<51:11,  4.21s/it]Iteration 271 Predicted energy: -92.44974046425789 Cost value: 54.330048695768674 Grad:  (Array(7.8547277, dtype=float32), Array(-0.4101507, dtype=float32))
Training epoch:  27%|██▋       | 272/1000 [19:15<51:15,  4.22s/it]Iteration 272 Predicted energy: -92.44748659119719 Cost value: 54.36327988548163 Grad:  (Array(0.69782835, dtype=float32), Array(-15.054325, dtype=float32))
Training epoch:  27%|██▋       | 273/1000 [19:19<51:48,  4.28s/it]Iteration 273 Predicted energy: -92.44370045102306 Cost value: 54.419125747846046 Grad:  (Array(21.984615, dtype=float32), Array(-1.0813793, dtype=float32))
Training epoch:  27%|██▋       | 274/1000 [19:24<51:34,  4.26s/it]Iteration 274 Predicted energy: -92.43890169784963 Cost value: 54.489948927578354 Grad:  (Array(1.3550519, dtype=float32), Array(-29.13499, dtype=float32))
Training epoch:  28%|██▊       | 275/1000 [19:28<51:35,  4.27s/it]Iteration 275 Predicted energy: -92.4307594779388 Cost value: 54.610222573569885 Grad:  (Array(36.89747, dtype=float32), Array(-1.7886328, dtype=float32))
Training epoch:  28%|██▊       | 276/1000 [19:32<51:15,  4.25s/it]Iteration 276 Predicted energy: -92.42272763762233 Cost value: 54.728995643403046 Grad:  (Array(2.113009, dtype=float32), Array(-45.124832, dtype=float32))
Training epoch:  28%|██▊       | 277/1000 [19:36<50:45,  4.21s/it]Iteration 277 Predicted energy: -92.40754043022547 Cost value: 54.95393332410964 Grad:  (Array(53.610905, dtype=float32), Array(-2.5545044, dtype=float32))
Training epoch:  28%|██▊       | 278/1000 [19:40<50:46,  4.22s/it]Iteration 278 Predicted energy: -92.39978788099079 Cost value: 55.068934147890175 Grad:  (Array(2.9183695, dtype=float32), Array(-61.0557, dtype=float32))
Training epoch:  28%|██▊       | 279/1000 [19:45<50:46,  4.23s/it]Iteration 279 Predicted energy: -92.38269748907436 Cost value: 55.322876513526765 Grad:  (Array(66.42638, dtype=float32), Array(-3.1653552, dtype=float32))
Training epoch:  28%|██▊       | 280/1000 [19:49<50:42,  4.23s/it]Iteration 280 Predicted energy: -92.38968650104842 Cost value: 55.21895772677809 Grad:  (Array(3.2451105, dtype=float32), Array(-66.742905, dtype=float32))
Training epoch:  28%|██▊       | 281/1000 [19:53<50:33,  4.22s/it]Iteration 281 Predicted energy: -92.39025659756159 Cost value: 55.21048533903565 Grad:  (Array(62.514374, dtype=float32), Array(-3.0073493, dtype=float32))
Training epoch:  28%|██▊       | 282/1000 [19:57<50:25,  4.21s/it]Iteration 282 Predicted energy: -92.41269907423549 Cost value: 54.87747693020933 Grad:  (Array(2.60829, dtype=float32), Array(-52.341694, dtype=float32))
Training epoch:  28%|██▊       | 283/1000 [20:02<50:43,  4.25s/it]Iteration 283 Predicted energy: -92.42792945643126 Cost value: 54.652057581501225 Grad:  (Array(38.771225, dtype=float32), Array(-1.8576574, dtype=float32))
Training epoch:  28%|██▊       | 284/1000 [20:06<50:33,  4.24s/it]Iteration 284 Predicted energy: -92.44239691444395 Cost value: 54.438359648463646 Grad:  (Array(1.2187247, dtype=float32), Array(-23.980766, dtype=float32))
Training epoch:  28%|██▊       | 285/1000 [20:10<50:17,  4.22s/it]Iteration 285 Predicted energy: -92.44923982912525 Cost value: 54.33742920138016 Grad:  (Array(8.646682, dtype=float32), Array(-0.4247452, dtype=float32))
Training epoch:  29%|██▊       | 286/1000 [20:14<50:10,  4.22s/it]Iteration 286 Predicted energy: -92.45005893747158 Cost value: 54.32535393387555 Grad:  (Array(4.621501, dtype=float32), Array(-0.24876231, dtype=float32))
Training epoch:  29%|██▊       | 287/1000 [20:18<50:07,  4.22s/it]Iteration 287 Predicted energy: -92.44627681238426 Cost value: 54.3811211003407 Grad:  (Array(0.8320686, dtype=float32), Array(-17.40754, dtype=float32))
Training epoch:  29%|██▉       | 288/1000 [20:23<49:46,  4.19s/it]Iteration 288 Predicted energy: -92.43895066200403 Cost value: 54.48922604956704 Grad:  (Array(28.059458, dtype=float32), Array(-1.3982115, dtype=float32))
Training epoch:  29%|██▉       | 289/1000 [20:27<49:45,  4.20s/it]Iteration 289 Predicted energy: -92.430893909859 Cost value: 54.608235722014115 Grad:  (Array(1.8094983, dtype=float32), Array(-37.74872, dtype=float32))
Training epoch:  29%|██▉       | 290/1000 [20:31<49:32,  4.19s/it]Iteration 290 Predicted energy: -92.41923118079458 Cost value: 54.78074077821229 Grad:  (Array(45.89721, dtype=float32), Array(-2.2423337, dtype=float32))
Training epoch:  29%|██▉       | 291/1000 [20:35<49:29,  4.19s/it]Iteration 291 Predicted energy: -92.41353201776083 Cost value: 54.865136843717856 Grad:  (Array(2.4748857, dtype=float32), Array(-51.993874, dtype=float32))
Training epoch:  29%|██▉       | 292/1000 [20:39<49:29,  4.19s/it]Iteration 292 Predicted energy: -92.4030538040025 Cost value: 55.02047300004137 Grad:  (Array(56.14071, dtype=float32), Array(-2.6979513, dtype=float32))
Training epoch:  29%|██▉       | 293/1000 [20:44<49:24,  4.19s/it]Iteration 293 Predicted energy: -92.40673279017373 Cost value: 54.96590819644011 Grad:  (Array(2.7046483, dtype=float32), Array(-56.584682, dtype=float32))
Training epoch:  29%|██▉       | 294/1000 [20:48<49:23,  4.20s/it]Iteration 294 Predicted energy: -92.40612241770182 Cost value: 54.97495904952091 Grad:  (Array(54.204308, dtype=float32), Array(-2.5895364, dtype=float32))
Training epoch:  30%|██▉       | 295/1000 [20:52<49:21,  4.20s/it]Iteration 295 Predicted energy: -92.41880094068962 Cost value: 54.787109722638455 Grad:  (Array(2.3204718, dtype=float32), Array(-48.029686, dtype=float32))
Training epoch:  30%|██▉       | 296/1000 [20:56<49:14,  4.20s/it]Iteration 296 Predicted energy: -92.42725823810126 Cost value: 54.66198226755306 Grad:  (Array(39.605473, dtype=float32), Array(-1.8771847, dtype=float32))
Training epoch:  30%|██▉       | 297/1000 [21:00<49:18,  4.21s/it]Iteration 297 Predicted energy: -92.43830555177136 Cost value: 54.49875046264837 Grad:  (Array(1.4781368, dtype=float32), Array(-29.738167, dtype=float32))
Training epoch:  30%|██▉       | 298/1000 [21:05<49:34,  4.24s/it]Iteration 298 Predicted energy: -92.44511141101201 Cost value: 54.39831062686489 Grad:  (Array(19.503597, dtype=float32), Array(-0.9236994, dtype=float32))
Training epoch:  30%|██▉       | 299/1000 [21:09<49:30,  4.24s/it]Iteration 299 Predicted energy: -92.44926573136426 Cost value: 54.33704733090388 Grad:  (Array(0.47806954, dtype=float32), Array(-9.961694, dtype=float32))
Training epoch:  30%|███       | 300/1000 [21:13<49:21,  4.23s/it]Iteration 300 Predicted energy: -92.4506056508549 Cost value: 54.31729505040481 Grad:  (Array(0.8695097, dtype=float32), Array(-0.09158725, dtype=float32))
Training epoch:  30%|███       | 301/1000 [21:17<49:14,  4.23s/it]Iteration 301 Predicted energy: -92.44989422145306 Cost value: 54.327782064053935 Grad:  (Array(6.9334764, dtype=float32), Array(-0.37518582, dtype=float32))
Training epoch:  30%|███       | 302/1000 [21:22<49:05,  4.22s/it]Iteration 302 Predicted energy: -92.44771320206848 Cost value: 54.359938266818695 Grad:  (Array(0.6681765, dtype=float32), Array(-14.383089, dtype=float32))
Training epoch:  30%|███       | 303/1000 [21:26<48:59,  4.22s/it]Iteration 303 Predicted energy: -92.44417353233885 Cost value: 54.412146194256906 Grad:  (Array(21.112476, dtype=float32), Array(-1.0375016, dtype=float32))
Training epoch:  30%|███       | 304/1000 [21:30<49:05,  4.23s/it]Iteration 304 Predicted energy: -92.44004111102369 Cost value: 54.473128543303346 Grad:  (Array(1.3095485, dtype=float32), Array(-27.668571, dtype=float32))
Training epoch:  30%|███       | 305/1000 [21:34<49:00,  4.23s/it]Iteration 305 Predicted energy: -92.43370417909507 Cost value: 54.566709309851696 Grad:  (Array(34.052814, dtype=float32), Array(-1.6491964, dtype=float32))
Training epoch:  31%|███       | 306/1000 [21:38<48:47,  4.22s/it]Iteration 306 Predicted energy: -92.42845556180458 Cost value: 54.6442791767493 Grad:  (Array(1.900991, dtype=float32), Array(-40.172466, dtype=float32))
Training epoch:  31%|███       | 307/1000 [21:43<48:47,  4.22s/it]Iteration 307 Predicted energy: -92.41926541583892 Cost value: 54.78023400478294 Grad:  (Array(45.92261, dtype=float32), Array(-2.1942625, dtype=float32))
Training epoch:  31%|███       | 308/1000 [21:47<48:26,  4.20s/it]Iteration 308 Predicted energy: -92.41560896300523 Cost value: 54.83437287337585 Grad:  (Array(2.4377723, dtype=float32), Array(-50.5519, dtype=float32))
Training epoch:  31%|███       | 309/1000 [21:51<48:21,  4.20s/it]Iteration 309 Predicted energy: -92.40682256147547 Cost value: 54.9645770936519 Grad:  (Array(53.864937, dtype=float32), Array(-2.5526476, dtype=float32))
Training epoch:  31%|███       | 310/1000 [21:55<48:33,  4.22s/it]Iteration 310 Predicted energy: -92.40967070271 Cost value: 54.922354050251634 Grad:  (Array(2.6806426, dtype=float32), Array(-54.66848, dtype=float32))
Training epoch:  31%|███       | 311/1000 [21:59<48:16,  4.20s/it]Iteration 311 Predicted energy: -92.40760881311988 Cost value: 54.95291947140787 Grad:  (Array(53.31191, dtype=float32), Array(-2.5460198, dtype=float32))
Training epoch:  31%|███       | 312/1000 [22:04<48:13,  4.21s/it]Iteration 312 Predicted energy: -92.41746018428555 Cost value: 54.8069596262677 Grad:  (Array(2.4217, dtype=float32), Array(-49.13608, dtype=float32))
Training epoch:  31%|███▏      | 313/1000 [22:08<48:11,  4.21s/it]Iteration 313 Predicted energy: -92.42284982333152 Cost value: 54.727187821839884 Grad:  (Array(43.095097, dtype=float32), Array(-2.0838547, dtype=float32))
Training epoch:  31%|███▏      | 314/1000 [22:12<47:58,  4.20s/it]Iteration 314 Predicted energy: -92.43290223136118 Cost value: 54.57855781374969 Grad:  (Array(1.763472, dtype=float32), Array(-35.81468, dtype=float32))
Training epoch:  32%|███▏      | 315/1000 [22:16<47:52,  4.19s/it]Iteration 315 Predicted energy: -92.43917596259692 Cost value: 54.48589990575978 Grad:  (Array(27.879158, dtype=float32), Array(-1.3616937, dtype=float32))
Training epoch:  32%|███▏      | 316/1000 [22:20<47:54,  4.20s/it]Iteration 316 Predicted energy: -92.44481788320391 Cost value: 54.40264055407296 Grad:  (Array(0.98853683, dtype=float32), Array(-20.407812, dtype=float32))
Training epoch:  32%|███▏      | 317/1000 [22:25<47:56,  4.21s/it]Iteration 317 Predicted energy: -92.44808978329687 Cost value: 54.354385402656305 Grad:  (Array(13.136508, dtype=float32), Array(-0.65628296, dtype=float32))
Training epoch:  32%|███▏      | 318/1000 [22:29<47:57,  4.22s/it]Iteration 318 Predicted energy: -92.44995170806973 Cost value: 54.32693462975219 Grad:  (Array(0.31344607, dtype=float32), Array(-6.9355245, dtype=float32))
Training epoch:  32%|███▏      | 319/1000 [22:33<47:33,  4.19s/it]Iteration 319 Predicted energy: -92.4506235783867 Cost value: 54.31703079794651 Grad:  (Array(1.1663418, dtype=float32), Array(-0.08241091, dtype=float32))
Training epoch:  32%|███▏      | 320/1000 [22:37<47:31,  4.19s/it]Iteration 320 Predicted energy: -92.45045863492459 Cost value: 54.31946209471167 Grad:  (Array(3.8567028, dtype=float32), Array(-0.21294706, dtype=float32))
Training epoch:  32%|███▏      | 321/1000 [22:41<47:25,  4.19s/it]Iteration 321 Predicted energy: -92.44964896118931 Cost value: 54.33139762261152 Grad:  (Array(0.3882222, dtype=float32), Array(-8.591676, dtype=float32))
Training epoch:  32%|███▏      | 322/1000 [22:46<47:21,  4.19s/it]Iteration 322 Predicted energy: -92.44818848114392 Cost value: 54.35293010422018 Grad:  (Array(13.2477, dtype=float32), Array(-0.65048724, dtype=float32))
Training epoch:  32%|███▏      | 323/1000 [22:50<47:28,  4.21s/it]Iteration 323 Predicted energy: -92.4461168020375 Cost value: 54.383481072350094 Grad:  (Array(0.8527317, dtype=float32), Array(-18.094627, dtype=float32))
Training epoch:  32%|███▏      | 324/1000 [22:54<47:34,  4.22s/it]Iteration 324 Predicted energy: -92.44269372166676 Cost value: 54.43397990935986 Grad:  (Array(23.53022, dtype=float32), Array(-1.1265391, dtype=float32))
Training epoch:  32%|███▎      | 325/1000 [22:58<47:31,  4.23s/it]Iteration 325 Predicted energy: -92.43840328004477 Cost value: 54.49730754807587 Grad:  (Array(1.4136939, dtype=float32), Array(-29.787258, dtype=float32))
Training epoch:  33%|███▎      | 326/1000 [23:03<47:19,  4.21s/it]Iteration 326 Predicted energy: -92.43048500075244 Cost value: 54.61427935199068 Grad:  (Array(37.119587, dtype=float32), Array(-1.766755, dtype=float32))
Training epoch:  33%|███▎      | 327/1000 [23:07<47:24,  4.23s/it]Iteration 327 Predicted energy: -92.42221168633088 Cost value: 54.7366298266948 Grad:  (Array(2.179435, dtype=float32), Array(-45.55807, dtype=float32))
Training epoch:  33%|███▎      | 328/1000 [23:11<47:21,  4.23s/it]Iteration 328 Predicted energy: -92.40559166381405 Cost value: 54.98282989127393 Grad:  (Array(54.746567, dtype=float32), Array(-2.6100583, dtype=float32))
Training epoch:  33%|███▎      | 329/1000 [23:15<47:33,  4.25s/it]Iteration 329 Predicted energy: -92.395726545732 Cost value: 55.12922771774708 Grad:  (Array(3.0633183, dtype=float32), Array(-63.442684, dtype=float32))
Training epoch:  33%|███▎      | 330/1000 [23:20<47:42,  4.27s/it]Iteration 330 Predicted energy: -92.37390480829926 Cost value: 55.45375260027289 Grad:  (Array(70.204445, dtype=float32), Array(-3.3897226, dtype=float32))
Training epoch:  33%|███▎      | 331/1000 [23:24<47:40,  4.28s/it]Iteration 331 Predicted energy: -92.38038462027936 Cost value: 55.35728779823909 Grad:  (Array(3.5139177, dtype=float32), Array(-71.592606, dtype=float32))
Training epoch:  33%|███▎      | 332/1000 [23:28<47:33,  4.27s/it]Iteration 332 Predicted energy: -92.37864248144683 Cost value: 55.38321472262952 Grad:  (Array(67.673, dtype=float32), Array(-3.2941244, dtype=float32))
Training epoch:  33%|███▎      | 333/1000 [23:32<47:22,  4.26s/it]Iteration 333 Predicted energy: -92.40598374695644 Cost value: 54.977015420016755 Grad:  (Array(2.857138, dtype=float32), Array(-56.621185, dtype=float32))
Training epoch:  33%|███▎      | 334/1000 [23:37<47:17,  4.26s/it]Iteration 334 Predicted energy: -92.42427191100177 Cost value: 54.70614925324624 Grad:  (Array(41.388638, dtype=float32), Array(-2.0016627, dtype=float32))
Training epoch:  34%|███▎      | 335/1000 [23:41<46:59,  4.24s/it]Iteration 335 Predicted energy: -92.44162330613185 Cost value: 54.44977597561454 Grad:  (Array(1.2810711, dtype=float32), Array(-24.771461, dtype=float32))
Training epoch:  34%|███▎      | 336/1000 [23:45<46:54,  4.24s/it]Iteration 336 Predicted energy: -92.44935632790677 Cost value: 54.33571169843473 Grad:  (Array(7.4605045, dtype=float32), Array(-0.36818582, dtype=float32))
Training epoch:  34%|███▎      | 337/1000 [23:49<46:46,  4.23s/it]Iteration 337 Predicted energy: -92.44948812365111 Cost value: 54.33376871015785 Grad:  (Array(7.375455, dtype=float32), Array(-0.3964289, dtype=float32))
Training epoch:  34%|███▍      | 338/1000 [23:54<46:46,  4.24s/it]Iteration 338 Predicted energy: -92.44391963821845 Cost value: 54.415891937817385 Grad:  (Array(1.045967, dtype=float32), Array(-21.731663, dtype=float32))
Training epoch:  34%|███▍      | 339/1000 [23:58<46:38,  4.23s/it]Iteration 339 Predicted energy: -92.43375937864572 Cost value: 54.56589380265607 Grad:  (Array(33.593987, dtype=float32), Array(-1.6875125, dtype=float32))
Training epoch:  34%|███▍      | 340/1000 [24:02<46:36,  4.24s/it]Iteration 340 Predicted energy: -92.42346102006822 Cost value: 54.718145194198364 Grad:  (Array(2.1430697, dtype=float32), Array(-44.258774, dtype=float32))
Training epoch:  34%|███▍      | 341/1000 [24:06<46:29,  4.23s/it]Iteration 341 Predicted energy: -92.40809306155595 Cost value: 54.945740215697064 Grad:  (Array(53.07879, dtype=float32), Array(-2.6039414, dtype=float32))
Training epoch:  34%|███▍      | 342/1000 [24:11<46:26,  4.23s/it]Iteration 342 Predicted energy: -92.40297039815353 Cost value: 55.02171034588677 Grad:  (Array(2.8032262, dtype=float32), Array(-58.846283, dtype=float32))
Training epoch:  34%|███▍      | 343/1000 [24:15<46:12,  4.22s/it]Iteration 343 Predicted energy: -92.39190098564026 Cost value: 55.18605120009742 Grad:  (Array(61.922295, dtype=float32), Array(-3.0089438, dtype=float32))
Training epoch:  34%|███▍      | 344/1000 [24:19<46:04,  4.21s/it]Iteration 344 Predicted energy: -92.40134038126891 Cost value: 55.04589483162632 Grad:  (Array(2.8509161, dtype=float32), Array(-59.792538, dtype=float32))
Training epoch:  34%|███▍      | 345/1000 [24:23<46:00,  4.22s/it]Iteration 345 Predicted energy: -92.4059594776165 Cost value: 54.97737531786555 Grad:  (Array(54.08883, dtype=float32), Array(-2.597656, dtype=float32))
Training epoch:  35%|███▍      | 346/1000 [24:27<45:46,  4.20s/it]Iteration 346 Predicted energy: -92.42337967025385 Cost value: 54.719348717861806 Grad:  (Array(2.1620176, dtype=float32), Array(-44.178608, dtype=float32))
Training epoch:  35%|███▍      | 347/1000 [24:32<45:43,  4.20s/it]Iteration 347 Predicted energy: -92.4351025528969 Cost value: 54.546051891355326 Grad:  (Array(32.2317, dtype=float32), Array(-1.5272207, dtype=float32))
Training epoch:  35%|███▍      | 348/1000 [24:36<45:55,  4.23s/it]Iteration 348 Predicted energy: -92.44509719115045 Cost value: 54.398520384843295 Grad:  (Array(0.9982945, dtype=float32), Array(-19.759861, dtype=float32))
Training epoch:  35%|███▍      | 349/1000 [24:40<45:46,  4.22s/it]Iteration 349 Predicted energy: -92.44980399968398 Cost value: 54.32911207427916 Grad:  (Array(7.3295383, dtype=float32), Array(-0.35798097, dtype=float32))
Training epoch:  35%|███▌      | 350/1000 [24:44<45:44,  4.22s/it]Iteration 350 Predicted energy: -92.45038258866487 Cost value: 54.32058304879928 Grad:  (Array(3.5579662, dtype=float32), Array(-0.20360495, dtype=float32))
Training epoch:  35%|███▌      | 351/1000 [24:48<45:28,  4.20s/it]Iteration 351 Predicted energy: -92.44785020521556 Cost value: 54.35791805930781 Grad:  (Array(0.64218974, dtype=float32), Array(-13.910487, dtype=float32))
Training epoch:  35%|███▌      | 352/1000 [24:53<45:30,  4.21s/it]Iteration 352 Predicted energy: -92.44297651185612 Cost value: 54.42980717194885 Grad:  (Array(22.716232, dtype=float32), Array(-1.147406, dtype=float32))
Training epoch:  35%|███▌      | 353/1000 [24:57<45:34,  4.23s/it]Iteration 353 Predicted energy: -92.43730271012363 Cost value: 54.5135580780853 Grad:  (Array(1.484673, dtype=float32), Array(-30.893408, dtype=float32))
Training epoch:  35%|███▌      | 354/1000 [25:01<45:15,  4.20s/it]Iteration 354 Predicted energy: -92.429186036064 Cost value: 54.63348012046323 Grad:  (Array(38.08854, dtype=float32), Array(-1.8592558, dtype=float32))
Training epoch:  36%|███▌      | 355/1000 [25:05<45:19,  4.22s/it]Iteration 355 Predicted energy: -92.42386580697918 Cost value: 54.71215680170318 Grad:  (Array(2.1048882, dtype=float32), Array(-44.084473, dtype=float32))
Training epoch:  36%|███▌      | 356/1000 [25:09<45:01,  4.20s/it]Iteration 356 Predicted energy: -92.41500946545551 Cost value: 54.84325181964769 Grad:  (Array(48.721302, dtype=float32), Array(-2.3576188, dtype=float32))
Training epoch:  36%|███▌      | 357/1000 [25:14<45:02,  4.20s/it]Iteration 357 Predicted energy: -92.41490148902943 Cost value: 54.84485109671257 Grad:  (Array(2.4404833, dtype=float32), Array(-50.95083, dtype=float32))
Training epoch:  36%|███▌      | 358/1000 [25:18<45:02,  4.21s/it]Iteration 358 Predicted energy: -92.41132911909047 Cost value: 54.89777587987629 Grad:  (Array(50.96681, dtype=float32), Array(-2.4268348, dtype=float32))
Training epoch:  36%|███▌      | 359/1000 [25:22<44:53,  4.20s/it]Iteration 359 Predicted energy: -92.41887116009373 Cost value: 54.78607022317314 Grad:  (Array(2.3635468, dtype=float32), Array(-47.91352, dtype=float32))
Training epoch:  36%|███▌      | 360/1000 [25:26<44:51,  4.21s/it]Iteration 360 Predicted energy: -92.42302510292123 Cost value: 54.72459449195494 Grad:  (Array(42.932884, dtype=float32), Array(-2.0224156, dtype=float32))
Training epoch:  36%|███▌      | 361/1000 [25:30<44:36,  4.19s/it]Iteration 361 Predicted energy: -92.43242098394191 Cost value: 54.58566869755476 Grad:  (Array(1.8102158, dtype=float32), Array(-36.270355, dtype=float32))
Training epoch:  36%|███▌      | 362/1000 [25:35<44:33,  4.19s/it]Iteration 362 Predicted energy: -92.43838790619623 Cost value: 54.49753453485859 Grad:  (Array(28.853857, dtype=float32), Array(-1.3891762, dtype=float32))
Training epoch:  36%|███▋      | 363/1000 [25:39<44:36,  4.20s/it]Iteration 363 Predicted energy: -92.44408748929267 Cost value: 54.41341558765128 Grad:  (Array(1.058157, dtype=float32), Array(-21.761513, dtype=float32))
Training epoch:  36%|███▋      | 364/1000 [25:43<44:34,  4.20s/it]Iteration 364 Predicted energy: -92.44744545029376 Cost value: 54.36388656293794 Grad:  (Array(14.812398, dtype=float32), Array(-0.73763824, dtype=float32))
Training epoch:  36%|███▋      | 365/1000 [25:47<44:29,  4.20s/it]Iteration 365 Predicted energy: -92.449524011906 Cost value: 54.3332396364327 Grad:  (Array(0.41514426, dtype=float32), Array(-8.909297, dtype=float32))
Training epoch:  37%|███▋      | 366/1000 [25:51<44:23,  4.20s/it]Iteration 366 Predicted energy: -92.45046027635303 Cost value: 54.319437899488534 Grad:  (Array(3.507906, dtype=float32), Array(-0.18695948, dtype=float32))
Training epoch:  37%|███▋      | 367/1000 [25:56<44:27,  4.21s/it]Iteration 367 Predicted energy: -92.45063358311862 Cost value: 54.316883328120554 Grad:  (Array(1.1874781, dtype=float32), Array(-0.08594525, dtype=float32))
Training epoch:  37%|███▋      | 368/1000 [26:00<44:24,  4.22s/it]Iteration 368 Predicted energy: -92.45024543724264 Cost value: 54.322604748111594 Grad:  (Array(0.23402438, dtype=float32), Array(-5.471754, dtype=float32))
Training epoch:  37%|███▋      | 369/1000 [26:04<44:18,  4.21s/it]Iteration 369 Predicted energy: -92.44937697561117 Cost value: 54.33540729900009 Grad:  (Array(9.568016, dtype=float32), Array(-0.48502386, dtype=float32))
Training epoch:  37%|███▋      | 370/1000 [26:08<44:15,  4.21s/it]Iteration 370 Predicted energy: -92.44807862853321 Cost value: 54.35454988072274 Grad:  (Array(0.6273809, dtype=float32), Array(-13.614099, dtype=float32))
Training epoch:  37%|███▋      | 371/1000 [26:13<44:23,  4.23s/it]Iteration 371 Predicted energy: -92.44605696571145 Cost value: 54.3843636037762 Grad:  (Array(17.943935, dtype=float32), Array(-0.86037385, dtype=float32))
Training epoch:  37%|███▋      | 372/1000 [26:17<44:17,  4.23s/it]Iteration 372 Predicted energy: -92.44351539904046 Cost value: 54.421856013874844 Grad:  (Array(1.0896447, dtype=float32), Array(-22.679718, dtype=float32))
Training epoch:  37%|███▋      | 373/1000 [26:21<44:14,  4.23s/it]Iteration 373 Predicted energy: -92.439182597792 Cost value: 54.48580195099627 Grad:  (Array(28.122078, dtype=float32), Array(-1.3273197, dtype=float32))
Training epoch:  37%|███▋      | 374/1000 [26:25<44:29,  4.27s/it]Iteration 374 Predicted energy: -92.4343389841482 Cost value: 54.55733119403967 Grad:  (Array(1.6658598, dtype=float32), Array(-34.39439, dtype=float32))
Training epoch:  38%|███▊      | 375/1000 [26:30<44:23,  4.26s/it]Iteration 375 Predicted energy: -92.42513561873824 Cost value: 54.69337341159522 Grad:  (Array(41.54811, dtype=float32), Array(-1.9841063, dtype=float32))
Training epoch:  38%|███▊      | 376/1000 [26:34<44:15,  4.26s/it]Iteration 376 Predicted energy: -92.41715980064126 Cost value: 54.81140730022819 Grad:  (Array(2.3942628, dtype=float32), Array(-49.444633, dtype=float32))
Training epoch:  38%|███▊      | 377/1000 [26:38<44:08,  4.25s/it]Iteration 377 Predicted energy: -92.40058343055723 Cost value: 55.057127481426924 Grad:  (Array(57.42081, dtype=float32), Array(-2.7738895, dtype=float32))
Training epoch:  38%|███▊      | 378/1000 [26:42<44:02,  4.25s/it]Iteration 378 Predicted energy: -92.394407244699 Cost value: 55.148820830366674 Grad:  (Array(3.1267622, dtype=float32), Array(-64.10304, dtype=float32))
Training epoch:  38%|███▊      | 379/1000 [26:47<43:54,  4.24s/it]Iteration 379 Predicted energy: -92.37788408934728 Cost value: 55.39450319058545 Grad:  (Array(68.25667, dtype=float32), Array(-3.323276, dtype=float32))
Training epoch:  38%|███▊      | 380/1000 [26:51<43:39,  4.23s/it]Iteration 380 Predicted energy: -92.38869408984078 Cost value: 55.2337078197483 Grad:  (Array(3.3184235, dtype=float32), Array(-67.01154, dtype=float32))
Training epoch:  38%|███▊      | 381/1000 [26:55<43:37,  4.23s/it]Iteration 381 Predicted energy: -92.39211892037089 Cost value: 55.18281329041088 Grad:  (Array(61.16713, dtype=float32), Array(-2.989476, dtype=float32))
Training epoch:  38%|███▊      | 382/1000 [26:59<43:20,  4.21s/it]Iteration 382 Predicted energy: -92.41544316086097 Cost value: 54.836828438411644 Grad:  (Array(2.5353017, dtype=float32), Array(-50.095264, dtype=float32))
Training epoch:  38%|███▊      | 383/1000 [27:03<43:12,  4.20s/it]Iteration 383 Predicted energy: -92.43057961946684 Cost value: 54.61288086844125 Grad:  (Array(36.10279, dtype=float32), Array(-1.7624148, dtype=float32))
Training epoch:  38%|███▊      | 384/1000 [27:08<42:57,  4.18s/it]Iteration 384 Predicted energy: -92.44362953480626 Cost value: 54.42017204109336 Grad:  (Array(1.1135852, dtype=float32), Array(-21.856049, dtype=float32))
Training epoch:  38%|███▊      | 385/1000 [27:12<42:53,  4.19s/it]Iteration 385 Predicted energy: -92.44955297980304 Cost value: 54.332812586251144 Grad:  (Array(7.258381, dtype=float32), Array(-0.37251502, dtype=float32))
Training epoch:  39%|███▊      | 386/1000 [27:16<43:01,  4.20s/it]Iteration 386 Predicted energy: -92.45005751504287 Cost value: 54.32537490210832 Grad:  (Array(5.0923424, dtype=float32), Array(-0.28388226, dtype=float32))
Training epoch:  39%|███▊      | 387/1000 [27:20<42:57,  4.20s/it]Iteration 387 Predicted energy: -92.446447371365 Cost value: 54.37860560426801 Grad:  (Array(0.8179516, dtype=float32), Array(-17.12521, dtype=float32))
Training epoch:  39%|███▉      | 388/1000 [27:24<43:00,  4.22s/it]Iteration 388 Predicted energy: -92.4393999445915 Cost value: 54.482593329232884 Grad:  (Array(27.575592, dtype=float32), Array(-1.3808135, dtype=float32))
Training epoch:  39%|███▉      | 389/1000 [27:29<42:52,  4.21s/it]Iteration 389 Predicted energy: -92.43100620038429 Cost value: 54.6065761393779 Grad:  (Array(1.7929202, dtype=float32), Array(-37.5364, dtype=float32))
Training epoch:  39%|███▉      | 390/1000 [27:33<42:43,  4.20s/it]Iteration 390 Predicted energy: -92.41763886092771 Cost value: 54.8043141102687 Grad:  (Array(47.010616, dtype=float32), Array(-2.3070621, dtype=float32))
Training epoch:  39%|███▉      | 391/1000 [27:37<42:44,  4.21s/it]Iteration 391 Predicted energy: -92.40867567712105 Cost value: 54.9371032334862 Grad:  (Array(2.5995, dtype=float32), Array(-55.172913, dtype=float32))
Training epoch:  39%|███▉      | 392/1000 [27:41<42:51,  4.23s/it]Iteration 392 Predicted energy: -92.3919006492802 Cost value: 55.18605619755465 Grad:  (Array(61.904186, dtype=float32), Array(-2.9966884, dtype=float32))
Training epoch:  39%|███▉      | 393/1000 [27:46<42:49,  4.23s/it]Iteration 393 Predicted energy: -92.39333605367118 Cost value: 55.16473178944226 Grad:  (Array(3.0735114, dtype=float32), Array(-64.47097, dtype=float32))
Training epoch:  39%|███▉      | 394/1000 [27:50<42:38,  4.22s/it]Iteration 394 Predicted energy: -92.3884153438308 Cost value: 55.23785114377744 Grad:  (Array(63.323273, dtype=float32), Array(-3.0407038, dtype=float32))
Training epoch:  40%|███▉      | 395/1000 [27:54<42:37,  4.23s/it]Iteration 395 Predicted energy: -92.40675844930222 Cost value: 54.96552772869054 Grad:  (Array(2.7717385, dtype=float32), Array(-56.167824, dtype=float32))
Training epoch:  40%|███▉      | 396/1000 [27:58<42:38,  4.24s/it]Iteration 396 Predicted energy: -92.41902055489103 Cost value: 54.78385867623613 Grad:  (Array(45.572716, dtype=float32), Array(-2.179616, dtype=float32))
Training epoch:  40%|███▉      | 397/1000 [28:03<42:38,  4.24s/it]Iteration 397 Predicted energy: -92.43570641920518 Cost value: 54.53713251066003 Grad:  (Array(1.6593417, dtype=float32), Array(-32.55174, dtype=float32))
Training epoch:  40%|███▉      | 398/1000 [28:07<42:21,  4.22s/it]Iteration 398 Predicted energy: -92.4453743170314 Cost value: 54.39443255822886 Grad:  (Array(18.50987, dtype=float32), Array(-0.90915823, dtype=float32))
Training epoch:  40%|███▉      | 399/1000 [28:11<42:10,  4.21s/it]Iteration 399 Predicted energy: -92.44997564703972 Cost value: 54.32658173731501 Grad:  (Array(0.2729863, dtype=float32), Array(-5.881145, dtype=float32))
Training epoch:  40%|████      | 400/1000 [28:15<42:12,  4.22s/it]Iteration 400 Predicted energy: -92.44982995961105 Cost value: 54.32872938261491 Grad:  (Array(0.29573932, dtype=float32), Array(-6.582481, dtype=float32))
Training epoch:  40%|████      | 401/1000 [28:19<42:02,  4.21s/it]Iteration 401 Predicted energy: -92.44620350443145 Cost value: 54.38220230354513 Grad:  (Array(16.941685, dtype=float32), Array(-0.8641281, dtype=float32))
Training epoch:  40%|████      | 402/1000 [28:24<41:55,  4.21s/it]Iteration 402 Predicted energy: -92.44053833894372 Cost value: 54.46578911837668 Grad:  (Array(1.2971491, dtype=float32), Array(-26.697834, dtype=float32))
Training epoch:  40%|████      | 403/1000 [28:28<41:58,  4.22s/it]Iteration 403 Predicted energy: -92.43229890052055 Cost value: 54.58747266872663 Grad:  (Array(35.18016, dtype=float32), Array(-1.7338618, dtype=float32))
Training epoch:  40%|████      | 404/1000 [28:32<42:03,  4.23s/it]Iteration 404 Predicted energy: -92.42567470382603 Cost value: 54.68540009808861 Grad:  (Array(2.018413, dtype=float32), Array(-42.47458, dtype=float32))
Training epoch:  40%|████      | 405/1000 [28:36<41:59,  4.23s/it]Iteration 405 Predicted energy: -92.41526184672068 Cost value: 54.83951380234653 Grad:  (Array(48.5409, dtype=float32), Array(-2.3629508, dtype=float32))
Training epoch:  41%|████      | 406/1000 [28:41<41:54,  4.23s/it]Iteration 406 Predicted energy: -92.41288343623201 Cost value: 54.874745481423474 Grad:  (Array(2.4970417, dtype=float32), Array(-52.346153, dtype=float32))
Training epoch:  41%|████      | 407/1000 [28:45<41:28,  4.20s/it]Iteration 407 Predicted energy: -92.40621123119048 Cost value: 54.97364204040304 Grad:  (Array(54.07328, dtype=float32), Array(-2.5743227, dtype=float32))
Training epoch:  41%|████      | 408/1000 [28:49<41:12,  4.18s/it]Iteration 408 Predicted energy: -92.41267230059505 Cost value: 54.87787360561552 Grad:  (Array(2.5636904, dtype=float32), Array(-52.384678, dtype=float32))
Training epoch:  41%|████      | 409/1000 [28:53<41:08,  4.18s/it]Iteration 409 Predicted energy: -92.415129959356 Cost value: 54.84146716936816 Grad:  (Array(48.477734, dtype=float32), Array(-2.29477, dtype=float32))
Training epoch:  41%|████      | 410/1000 [28:57<41:08,  4.18s/it]Iteration 410 Predicted energy: -92.42612796349263 Cost value: 54.67869663136597 Grad:  (Array(2.0881627, dtype=float32), Array(-42.053326, dtype=float32))
Training epoch:  41%|████      | 411/1000 [29:01<41:14,  4.20s/it]Iteration 411 Predicted energy: -92.43301110844682 Cost value: 54.576949116532106 Grad:  (Array(34.478607, dtype=float32), Array(-1.6589648, dtype=float32))
Training epoch:  41%|████      | 412/1000 [29:06<41:15,  4.21s/it]Iteration 412 Predicted energy: -92.44080027239869 Cost value: 54.46192299988778 Grad:  (Array(1.3088069, dtype=float32), Array(-26.634882, dtype=float32))
Training epoch:  41%|████▏     | 413/1000 [29:10<41:17,  4.22s/it]Iteration 413 Predicted energy: -92.44549749119268 Cost value: 54.3926156909306 Grad:  (Array(18.718594, dtype=float32), Array(-0.93057275, dtype=float32))
Training epoch:  41%|████▏     | 414/1000 [29:14<41:08,  4.21s/it]Iteration 414 Predicted energy: -92.4486729779759 Cost value: 54.34578648746154 Grad:  (Array(0.5570063, dtype=float32), Array(-11.796703, dtype=float32))
Training epoch:  42%|████▏     | 415/1000 [29:18<41:16,  4.23s/it]Iteration 415 Predicted energy: -92.45019811718981 Cost value: 54.323302284556604 Grad:  (Array(5.237136, dtype=float32), Array(-0.27493256, dtype=float32))
Training epoch:  42%|████▏     | 416/1000 [29:23<41:07,  4.23s/it]Iteration 416 Predicted energy: -92.45061120118724 Cost value: 54.31721323823932 Grad:  (Array(0.38907337, dtype=float32), Array(-0.08551604, dtype=float32))
Training epoch:  42%|████▏     | 417/1000 [29:27<40:51,  4.20s/it]Iteration 417 Predicted energy: -92.45019865977315 Cost value: 54.32329428640719 Grad:  (Array(0.24128284, dtype=float32), Array(-5.5883856, dtype=float32))
Training epoch:  42%|████▏     | 418/1000 [29:31<40:52,  4.21s/it]Iteration 418 Predicted energy: -92.44912501624123 Cost value: 54.339121876254744 Grad:  (Array(10.367178, dtype=float32), Array(-0.5305806, dtype=float32))
Training epoch:  42%|████▏     | 419/1000 [29:35<40:48,  4.21s/it]Iteration 419 Predicted energy: -92.44753070067975 Cost value: 54.362629436129765 Grad:  (Array(0.6944899, dtype=float32), Array(-14.996513, dtype=float32))
Training epoch:  42%|████▏     | 420/1000 [29:39<40:40,  4.21s/it]Iteration 420 Predicted energy: -92.44511403335596 Cost value: 54.398271944565714 Grad:  (Array(19.635338, dtype=float32), Array(-0.94628876, dtype=float32))
Training epoch:  42%|████▏     | 421/1000 [29:44<40:49,  4.23s/it]Iteration 421 Predicted energy: -92.44230620524795 Cost value: 54.43969820431886 Grad:  (Array(1.1855403, dtype=float32), Array(-24.51292, dtype=float32))
Training epoch:  42%|████▏     | 422/1000 [29:48<40:53,  4.24s/it]Iteration 422 Predicted energy: -92.437696952256 Cost value: 54.50773659418922 Grad:  (Array(29.809206, dtype=float32), Array(-1.4075038, dtype=float32))
Training epoch:  42%|████▏     | 423/1000 [29:52<40:36,  4.22s/it]Iteration 423 Predicted energy: -92.43313613835248 Cost value: 54.575101784965284 Grad:  (Array(1.7256228, dtype=float32), Array(-35.598083, dtype=float32))
Training epoch:  42%|████▏     | 424/1000 [29:56<40:26,  4.21s/it]Iteration 424 Predicted energy: -92.42456618672813 Cost value: 54.70179620110315 Grad:  (Array(41.96212, dtype=float32), Array(-2.0048535, dtype=float32))
Training epoch:  42%|████▎     | 425/1000 [30:00<40:13,  4.20s/it]Iteration 425 Predicted energy: -92.41824061048953 Cost value: 54.79540497607194 Grad:  (Array(2.3457072, dtype=float32), Array(-48.568413, dtype=float32))
Training epoch:  43%|████▎     | 426/1000 [30:05<40:03,  4.19s/it]Iteration 426 Predicted energy: -92.40473023406929 Cost value: 54.99560570672232 Grad:  (Array(55.068222, dtype=float32), Array(-2.654434, dtype=float32))
Training epoch:  43%|████▎     | 427/1000 [30:09<40:07,  4.20s/it]Iteration 427 Predicted energy: -92.40109022792328 Cost value: 55.04960681567048 Grad:  (Array(2.924084, dtype=float32), Array(-60.079777, dtype=float32))
Training epoch:  43%|████▎     | 428/1000 [30:13<40:08,  4.21s/it]Iteration 428 Predicted energy: -92.38909967724658 Cost value: 55.22767938304874 Grad:  (Array(63.05294, dtype=float32), Array(-3.0650942, dtype=float32))
Training epoch:  43%|████▎     | 429/1000 [30:17<40:01,  4.21s/it]Iteration 429 Predicted energy: -92.39786327244153 Cost value: 55.09750229381664 Grad:  (Array(3.053754, dtype=float32), Array(-61.814484, dtype=float32))
Training epoch:  43%|████▎     | 430/1000 [30:21<39:49,  4.19s/it]Iteration 430 Predicted energy: -92.40011214693254 Cost value: 55.064121598731646 Grad:  (Array(57.064053, dtype=float32), Array(-2.7944617, dtype=float32))
Training epoch:  43%|████▎     | 431/1000 [30:26<39:48,  4.20s/it]Iteration 431 Predicted energy: -92.41789817056352 Cost value: 54.80047484236618 Grad:  (Array(2.4379227, dtype=float32), Array(-48.370525, dtype=float32))
Training epoch:  43%|████▎     | 432/1000 [30:30<39:48,  4.20s/it]Iteration 432 Predicted energy: -92.42936785817255 Cost value: 54.63079229677721 Grad:  (Array(37.253376, dtype=float32), Array(-1.8292305, dtype=float32))
Training epoch:  43%|████▎     | 433/1000 [30:34<39:44,  4.21s/it]Iteration 433 Predicted energy: -92.44114325732299 Cost value: 54.45686077516344 Grad:  (Array(1.3045024, dtype=float32), Array(-25.722445, dtype=float32))
Training epoch:  43%|████▎     | 434/1000 [30:38<39:45,  4.21s/it]Iteration 434 Predicted energy: -92.4476169095489 Cost value: 54.36135819003352 Grad:  (Array(13.686377, dtype=float32), Array(-0.6841039, dtype=float32))
Training epoch:  44%|████▎     | 435/1000 [30:43<39:43,  4.22s/it]Iteration 435 Predicted energy: -92.45034991066859 Cost value: 54.321064739862265 Grad:  (Array(0.15414132, dtype=float32), Array(-3.3991523, dtype=float32))
Training epoch:  44%|████▎     | 436/1000 [30:47<39:39,  4.22s/it]Iteration 436 Predicted energy: -92.4499572256646 Cost value: 54.32685329292209 Grad:  (Array(0.30961058, dtype=float32), Array(-6.6491165, dtype=float32))
Training epoch:  44%|████▎     | 437/1000 [30:51<39:41,  4.23s/it]Iteration 437 Predicted energy: -92.4471960491551 Cost value: 54.36756438760646 Grad:  (Array(15.328497, dtype=float32), Array(-0.7764566, dtype=float32))
Training epoch:  44%|████▍     | 438/1000 [30:55<39:40,  4.24s/it]Iteration 438 Predicted energy: -92.44272007559914 Cost value: 54.433591034657525 Grad:  (Array(1.1175941, dtype=float32), Array(-23.765574, dtype=float32))
Training epoch:  44%|████▍     | 439/1000 [30:59<39:40,  4.24s/it]Iteration 439 Predicted energy: -92.43554478632343 Cost value: 54.5395198305375 Grad:  (Array(32.12714, dtype=float32), Array(-1.5831805, dtype=float32))
Training epoch:  44%|████▍     | 440/1000 [31:04<39:31,  4.23s/it]Iteration 440 Predicted energy: -92.42795714245595 Cost value: 54.65164823315235 Grad:  (Array(1.8848237, dtype=float32), Array(-40.40521, dtype=float32))
Training epoch:  44%|████▍     | 441/1000 [31:08<39:17,  4.22s/it]Iteration 441 Predicted energy: -92.41470399255655 Cost value: 54.84777634720599 Grad:  (Array(48.98395, dtype=float32), Array(-2.3601213, dtype=float32))
Training epoch:  44%|████▍     | 442/1000 [31:12<39:15,  4.22s/it]Iteration 442 Predicted energy: -92.40660020258137 Cost value: 54.96787419623193 Grad:  (Array(2.6668777, dtype=float32), Array(-56.49817, dtype=float32))
Training epoch:  44%|████▍     | 443/1000 [31:16<39:18,  4.23s/it]Iteration 443 Predicted energy: -92.39015815599107 Cost value: 55.21194826446366 Grad:  (Array(62.683434, dtype=float32), Array(-3.005588, dtype=float32))
Training epoch:  44%|████▍     | 444/1000 [31:21<39:16,  4.24s/it]Iteration 444 Predicted energy: -92.39285769609556 Cost value: 55.171837825265264 Grad:  (Array(3.147151, dtype=float32), Array(-64.72942, dtype=float32))
Training epoch:  44%|████▍     | 445/1000 [31:25<39:00,  4.22s/it]Iteration 445 Predicted energy: -92.38858699065611 Cost value: 55.23529974029682 Grad:  (Array(63.161255, dtype=float32), Array(-3.05083, dtype=float32))
Training epoch:  45%|████▍     | 446/1000 [31:29<38:50,  4.21s/it]Iteration 446 Predicted energy: -92.40709327410588 Cost value: 54.960563142983546 Grad:  (Array(2.8203268, dtype=float32), Array(-55.987495, dtype=float32))
Training epoch:  45%|████▍     | 447/1000 [31:33<38:43,  4.20s/it]Iteration 447 Predicted energy: -92.41901684103098 Cost value: 54.78391365335143 Grad:  (Array(45.39856, dtype=float32), Array(-2.2159877, dtype=float32))
Training epoch:  45%|████▍     | 448/1000 [31:37<38:45,  4.21s/it]Iteration 448 Predicted energy: -92.43532737953028 Cost value: 54.54273101425636 Grad:  (Array(1.6843421, dtype=float32), Array(-32.875023, dtype=float32))
Training epoch:  45%|████▍     | 449/1000 [31:42<38:38,  4.21s/it]Iteration 449 Predicted energy: -92.44483717057778 Cost value: 54.40235603425854 Grad:  (Array(19.110165, dtype=float32), Array(-0.95278424, dtype=float32))
Training epoch:  45%|████▌     | 450/1000 [31:46<38:23,  4.19s/it]Iteration 450 Predicted energy: -92.44967585306756 Cost value: 54.33100118415346 Grad:  (Array(0.33386585, dtype=float32), Array(-6.920307, dtype=float32))
Training epoch:  45%|████▌     | 451/1000 [31:50<38:24,  4.20s/it]Iteration 451 Predicted energy: -92.45001342269285 Cost value: 54.32602487599245 Grad:  (Array(0.23706019, dtype=float32), Array(-5.2099266, dtype=float32))
Training epoch:  45%|████▌     | 452/1000 [31:54<38:33,  4.22s/it]Iteration 452 Predicted energy: -92.44700225614659 Cost value: 54.370422266009285 Grad:  (Array(15.3316145, dtype=float32), Array(-0.78667504, dtype=float32))
Training epoch:  45%|████▌     | 453/1000 [31:59<38:38,  4.24s/it]Iteration 453 Predicted energy: -92.44185436353258 Cost value: 54.44636607965548 Grad:  (Array(1.1917948, dtype=float32), Array(-24.942402, dtype=float32))
Training epoch:  45%|████▌     | 454/1000 [32:03<38:53,  4.27s/it]Iteration 454 Predicted energy: -92.43405488633617 Cost value: 54.56152813437768 Grad:  (Array(33.539185, dtype=float32), Array(-1.6548574, dtype=float32))
Training epoch:  46%|████▌     | 455/1000 [32:07<38:43,  4.26s/it]Iteration 455 Predicted energy: -92.42698343680686 Cost value: 54.666045760676695 Grad:  (Array(1.9600636, dtype=float32), Array(-41.319912, dtype=float32))
Training epoch:  46%|████▌     | 456/1000 [32:11<38:37,  4.26s/it]Iteration 456 Predicted energy: -92.41541026735256 Cost value: 54.83731560480621 Grad:  (Array(48.485386, dtype=float32), Array(-2.338053, dtype=float32))
Training epoch:  46%|████▌     | 457/1000 [32:16<38:19,  4.23s/it]Iteration 457 Predicted energy: -92.41052836045255 Cost value: 54.909642648380405 Grad:  (Array(2.5690217, dtype=float32), Array(-53.925632, dtype=float32))
Training epoch:  46%|████▌     | 458/1000 [32:20<38:02,  4.21s/it]Iteration 458 Predicted energy: -92.39967176353807 Cost value: 55.07065754051069 Grad:  (Array(57.77869, dtype=float32), Array(-2.7553713, dtype=float32))
Training epoch:  46%|████▌     | 459/1000 [32:24<37:51,  4.20s/it]Iteration 459 Predicted energy: -92.40401936189191 Cost value: 55.00614972917543 Grad:  (Array(2.8200629, dtype=float32), Array(-58.09622, dtype=float32))
Training epoch:  46%|████▌     | 460/1000 [32:28<37:52,  4.21s/it]Iteration 460 Predicted energy: -92.40289921147382 Cost value: 55.02276642841989 Grad:  (Array(55.885063, dtype=float32), Array(-2.6654334, dtype=float32))
Training epoch:  46%|████▌     | 461/1000 [32:32<37:58,  4.23s/it]Iteration 461 Predicted energy: -92.41608891996712 Cost value: 54.82726491858138 Grad:  (Array(2.4792664, dtype=float32), Array(-49.9172, dtype=float32))
Training epoch:  46%|████▌     | 462/1000 [32:37<37:53,  4.23s/it]Iteration 462 Predicted energy: -92.42408954620635 Cost value: 54.708846958057016 Grad:  (Array(41.976486, dtype=float32), Array(-2.0333216, dtype=float32))
Training epoch:  46%|████▋     | 463/1000 [32:41<37:56,  4.24s/it]Iteration 463 Predicted energy: -92.43568354341295 Cost value: 54.53747038325039 Grad:  (Array(1.6262537, dtype=float32), Array(-32.749073, dtype=float32))
Training epoch:  46%|████▋     | 464/1000 [32:45<37:52,  4.24s/it]Iteration 464 Predicted energy: -92.44284410270775 Cost value: 54.43176092776096 Grad:  (Array(22.758001, dtype=float32), Array(-1.1375728, dtype=float32))
Training epoch:  46%|████▋     | 465/1000 [32:49<37:40,  4.23s/it]Iteration 465 Predicted energy: -92.44789001158873 Cost value: 54.357331093449574 Grad:  (Array(0.6611736, dtype=float32), Array(-13.705688, dtype=float32))
Training epoch:  47%|████▋     | 466/1000 [32:54<37:42,  4.24s/it]Iteration 466 Predicted energy: -92.45015071637756 Cost value: 54.324001015951644 Grad:  (Array(4.7458296, dtype=float32), Array(-0.25376213, dtype=float32))
Training epoch:  47%|████▋     | 467/1000 [32:58<37:36,  4.23s/it]Iteration 467 Predicted energy: -92.4503963528205 Cost value: 54.32038015845629 Grad:  (Array(2.8940096, dtype=float32), Array(-0.18255955, dtype=float32))
Training epoch:  47%|████▋     | 468/1000 [33:02<37:55,  4.28s/it]Iteration 468 Predicted energy: -92.44914381964216 Cost value: 54.338844657788705 Grad:  (Array(0.46725887, dtype=float32), Array(-10.137323, dtype=float32))
Training epoch:  47%|████▋     | 469/1000 [33:06<37:45,  4.27s/it]Iteration 469 Predicted energy: -92.4466640267257 Cost value: 54.375410337750466 Grad:  (Array(16.562828, dtype=float32), Array(-0.83336985, dtype=float32))
Training epoch:  47%|████▋     | 470/1000 [33:11<37:52,  4.29s/it]Iteration 470 Predicted energy: -92.44344594196275 Cost value: 54.42288080468405 Grad:  (Array(1.0798831, dtype=float32), Array(-22.76912, dtype=float32))
Training epoch:  47%|████▋     | 471/1000 [33:15<37:49,  4.29s/it]Iteration 471 Predicted energy: -92.43860045351494 Cost value: 54.49439642746638 Grad:  (Array(28.733643, dtype=float32), Array(-1.3867443, dtype=float32))
Training epoch:  47%|████▋     | 472/1000 [33:19<37:45,  4.29s/it]Iteration 472 Predicted energy: -92.43399247386331 Cost value: 54.562450167416664 Grad:  (Array(1.6642755, dtype=float32), Array(-34.642063, dtype=float32))
Training epoch:  47%|████▋     | 473/1000 [33:24<37:33,  4.28s/it]Iteration 473 Predicted energy: -92.42616421383109 Cost value: 54.67816052609924 Grad:  (Array(40.639618, dtype=float32), Array(-1.9316379, dtype=float32))
Training epoch:  47%|████▋     | 474/1000 [33:28<37:19,  4.26s/it]Iteration 474 Predicted energy: -92.42112045345232 Cost value: 54.75277781746203 Grad:  (Array(2.2206368, dtype=float32), Array(-46.216442, dtype=float32))
Training epoch:  48%|████▊     | 475/1000 [33:32<37:28,  4.28s/it]Iteration 475 Predicted energy: -92.41064264672437 Cost value: 54.90794891510084 Grad:  (Array(51.53093, dtype=float32), Array(-2.4578016, dtype=float32))
Training epoch:  48%|████▊     | 476/1000 [33:36<37:22,  4.28s/it]Iteration 476 Predicted energy: -92.40865315686399 Cost value: 54.93743707233717 Grad:  (Array(2.671096, dtype=float32), Array(-55.21708, dtype=float32))
Training epoch:  48%|████▊     | 477/1000 [33:41<37:23,  4.29s/it]Iteration 477 Predicted energy: -92.40013078665022 Cost value: 55.06384496627203 Grad:  (Array(57.488472, dtype=float32), Array(-2.7744553, dtype=float32))
Training epoch:  48%|████▊     | 478/1000 [33:45<37:11,  4.28s/it]Iteration 478 Predicted energy: -92.40637271580069 Cost value: 54.97124743663886 Grad:  (Array(2.778663, dtype=float32), Array(-56.640366, dtype=float32))
Training epoch:  48%|████▊     | 479/1000 [33:49<36:55,  4.25s/it]Iteration 479 Predicted energy: -92.4069656192352 Cost value: 54.962455908049414 Grad:  (Array(53.35502, dtype=float32), Array(-2.608598, dtype=float32))
Training epoch:  48%|████▊     | 480/1000 [33:53<36:44,  4.24s/it]Iteration 480 Predicted energy: -92.41970907865687 Cost value: 54.773666778907796 Grad:  (Array(2.3531399, dtype=float32), Array(-47.121788, dtype=float32))
Training epoch:  48%|████▊     | 481/1000 [33:58<36:34,  4.23s/it]Iteration 481 Predicted energy: -92.42760639943926 Cost value: 54.6568342146521 Grad:  (Array(38.884056, dtype=float32), Array(-1.9144859, dtype=float32))
Training epoch:  48%|████▊     | 482/1000 [34:02<36:28,  4.22s/it]Iteration 482 Predicted energy: -92.43796710699706 Cost value: 54.50374759711639 Grad:  (Array(1.5021902, dtype=float32), Array(-29.88462, dtype=float32))
Training epoch:  48%|████▊     | 483/1000 [34:06<36:23,  4.22s/it]Iteration 483 Predicted energy: -92.44437553775033 Cost value: 54.409166065824394 Grad:  (Array(20.151247, dtype=float32), Array(-1.0035548, dtype=float32))
Training epoch:  48%|████▊     | 484/1000 [34:10<36:31,  4.25s/it]Iteration 484 Predicted energy: -92.44864063457491 Cost value: 54.34626335699031 Grad:  (Array(0.56634665, dtype=float32), Array(-11.5543585, dtype=float32))
Training epoch:  48%|████▊     | 485/1000 [34:14<36:17,  4.23s/it]Iteration 485 Predicted energy: -92.4504215106404 Cost value: 54.32000932094452 Grad:  (Array(3.0204382, dtype=float32), Array(-0.16962695, dtype=float32))
Training epoch:  49%|████▊     | 486/1000 [34:19<36:14,  4.23s/it]Iteration 486 Predicted energy: -92.45037509485648 Cost value: 54.320693511335854 Grad:  (Array(4.1498938, dtype=float32), Array(-0.21629392, dtype=float32))
Training epoch:  49%|████▊     | 487/1000 [34:23<36:10,  4.23s/it]Iteration 487 Predicted energy: -92.44895342912524 Cost value: 54.34165161709964 Grad:  (Array(0.5200332, dtype=float32), Array(-11.0407715, dtype=float32))
Training epoch:  49%|████▉     | 488/1000 [34:27<36:03,  4.23s/it]Iteration 488 Predicted energy: -92.44627872866263 Cost value: 54.38109283770783 Grad:  (Array(17.469593, dtype=float32), Array(-0.8652731, dtype=float32))
Training epoch:  49%|████▉     | 489/1000 [34:31<36:01,  4.23s/it]Iteration 489 Predicted energy: -92.44268523632091 Cost value: 54.43410511815536 Grad:  (Array(1.1102588, dtype=float32), Array(-23.840721, dtype=float32))
Training epoch:  49%|████▉     | 490/1000 [34:36<35:55,  4.23s/it]Iteration 490 Predicted energy: -92.4368847280079 Cost value: 54.51973045236775 Grad:  (Array(30.71325, dtype=float32), Array(-1.4834762, dtype=float32))
Training epoch:  49%|████▉     | 491/1000 [34:40<36:00,  4.25s/it]Iteration 491 Predicted energy: -92.4307578906212 Cost value: 54.610246033723456 Grad:  (Array(1.7678745, dtype=float32), Array(-37.797337, dtype=float32))
Training epoch:  49%|████▉     | 492/1000 [34:44<36:01,  4.26s/it]Iteration 492 Predicted energy: -92.41968226908418 Cost value: 54.774063610812824 Grad:  (Array(45.583485, dtype=float32), Array(-2.1725588, dtype=float32))
Training epoch:  49%|████▉     | 493/1000 [34:48<35:46,  4.23s/it]Iteration 493 Predicted energy: -92.41195784780162 Cost value: 54.88845939170599 Grad:  (Array(2.5194774, dtype=float32), Array(-52.945232, dtype=float32))
Training epoch:  49%|████▉     | 494/1000 [34:53<35:37,  4.22s/it]Iteration 494 Predicted energy: -92.39609733600199 Cost value: 55.123721689501295 Grad:  (Array(59.6968, dtype=float32), Array(-2.8635142, dtype=float32))
Training epoch:  50%|████▉     | 495/1000 [34:57<35:24,  4.21s/it]Iteration 495 Predicted energy: -92.39515033005001 Cost value: 55.13778474421262 Grad:  (Array(3.1023054, dtype=float32), Array(-63.462406, dtype=float32))
Training epoch:  50%|████▉     | 496/1000 [35:01<35:27,  4.22s/it]Iteration 496 Predicted energy: -92.38643862671688 Cost value: 55.267237832692366 Grad:  (Array(64.12723, dtype=float32), Array(-3.1261468, dtype=float32))
Training epoch:  50%|████▉     | 497/1000 [35:05<35:19,  4.21s/it]Iteration 497 Predicted energy: -92.40155011545389 Cost value: 55.0427827172636 Grad:  (Array(2.9969327, dtype=float32), Array(-59.448647, dtype=float32))
Training epoch:  50%|████▉     | 498/1000 [35:09<35:23,  4.23s/it]Iteration 498 Predicted energy: -92.41033083736474 Cost value: 54.91257002067805 Grad:  (Array(50.935867, dtype=float32), Array(-2.5053895, dtype=float32))
Training epoch:  50%|████▉     | 499/1000 [35:14<35:21,  4.23s/it]Iteration 499 Predicted energy: -92.42848619879392 Cost value: 54.6438262295988 Grad:  (Array(2.0376828, dtype=float32), Array(-39.532875, dtype=float32))
Training epoch:  50%|█████     | 500/1000 [35:18<35:09,  4.22s/it]Iteration 500 Predicted energy: -92.43983616315168 Cost value: 54.47615385828597 Grad:  (Array(26.228117, dtype=float32), Array(-1.3008429, dtype=float32))
Training epoch:  50%|█████     | 501/1000 [35:22<34:58,  4.21s/it]Iteration 501 Predicted energy: -92.44757692668807 Cost value: 54.36194778014077 Grad:  (Array(0.6967994, dtype=float32), Array(-13.963526, dtype=float32))
Training epoch:  50%|█████     | 502/1000 [35:26<34:46,  4.19s/it]Iteration 502 Predicted energy: -92.45033020997573 Cost value: 54.32135513959567 Grad:  (Array(1.4679422, dtype=float32), Array(-0.1532039, dtype=float32))
Training epoch:  50%|█████     | 503/1000 [35:30<34:43,  4.19s/it]Iteration 503 Predicted energy: -92.44930138979318 Cost value: 54.336521629462986 Grad:  (Array(8.928696, dtype=float32), Array(-0.47029087, dtype=float32))
Training epoch:  50%|█████     | 504/1000 [35:35<34:36,  4.19s/it]Iteration 504 Predicted energy: -92.44552695403549 Cost value: 54.39218110691464 Grad:  (Array(0.909571, dtype=float32), Array(-18.970652, dtype=float32))
Training epoch:  50%|█████     | 505/1000 [35:39<34:31,  4.18s/it]Iteration 505 Predicted energy: -92.4391099334049 Cost value: 54.486874693335594 Grad:  (Array(28.05972, dtype=float32), Array(-1.3853513, dtype=float32))
Training epoch:  51%|█████     | 506/1000 [35:43<34:34,  4.20s/it]Iteration 506 Predicted energy: -92.43189431501186 Cost value: 54.59345125779271 Grad:  (Array(1.7290016, dtype=float32), Array(-36.681812, dtype=float32))
Training epoch:  51%|█████     | 507/1000 [35:47<34:30,  4.20s/it]Iteration 507 Predicted energy: -92.42010425116194 Cost value: 54.76781765221037 Grad:  (Array(45.245888, dtype=float32), Array(-2.1924186, dtype=float32))
Training epoch:  51%|█████     | 508/1000 [35:51<34:26,  4.20s/it]Iteration 508 Predicted energy: -92.41201369820287 Cost value: 54.887631839926456 Grad:  (Array(2.483386, dtype=float32), Array(-52.837723, dtype=float32))
Training epoch:  51%|█████     | 509/1000 [35:56<34:22,  4.20s/it]Iteration 509 Predicted energy: -92.39649499611362 Cost value: 55.11781696470875 Grad:  (Array(59.492424, dtype=float32), Array(-2.8400834, dtype=float32))
Training epoch:  51%|█████     | 510/1000 [36:00<34:16,  4.20s/it]Iteration 510 Predicted energy: -92.39624606396244 Cost value: 55.1215132396911 Grad:  (Array(3.0153267, dtype=float32), Array(-62.716957, dtype=float32))
Training epoch:  51%|█████     | 511/1000 [36:04<34:10,  4.19s/it]Iteration 511 Predicted energy: -92.38895812101408 Cost value: 55.22978336264939 Grad:  (Array(63.06252, dtype=float32), Array(-3.0178204, dtype=float32))
Training epoch:  51%|█████     | 512/1000 [36:08<34:19,  4.22s/it]Iteration 512 Predicted energy: -92.40392552462389 Cost value: 55.00754164740163 Grad:  (Array(2.8808854, dtype=float32), Array(-57.98849, dtype=float32))
Training epoch:  51%|█████▏    | 513/1000 [36:12<34:12,  4.21s/it]Iteration 513 Predicted energy: -92.41276657460665 Cost value: 54.87647685826058 Grad:  (Array(49.656586, dtype=float32), Array(-2.411718, dtype=float32))
Training epoch:  51%|█████▏    | 514/1000 [36:17<34:04,  4.21s/it]Iteration 514 Predicted energy: -92.42979102056601 Cost value: 54.624537065411126 Grad:  (Array(1.9522709, dtype=float32), Array(-38.536552, dtype=float32))
Training epoch:  52%|█████▏    | 515/1000 [36:21<33:56,  4.20s/it]Iteration 515 Predicted energy: -92.44039607386047 Cost value: 54.4678889980229 Grad:  (Array(25.788322, dtype=float32), Array(-1.2868699, dtype=float32))
Training epoch:  52%|█████▏    | 516/1000 [36:25<33:43,  4.18s/it]Iteration 516 Predicted energy: -92.44764374013539 Cost value: 54.36096254609096 Grad:  (Array(0.69064975, dtype=float32), Array(-13.975128, dtype=float32))
Training epoch:  52%|█████▏    | 517/1000 [36:29<33:30,  4.16s/it]Iteration 517 Predicted energy: -92.45027099203428 Cost value: 54.322228051355786 Grad:  (Array(2.0021505, dtype=float32), Array(-0.19965518, dtype=float32))
Training epoch:  52%|█████▏    | 518/1000 [36:33<33:32,  4.17s/it]Iteration 518 Predicted energy: -92.44943014681655 Cost value: 54.33462342474957 Grad:  (Array(8.028254, dtype=float32), Array(-0.42529917, dtype=float32))
Training epoch:  52%|█████▏    | 519/1000 [36:37<33:25,  4.17s/it]Iteration 519 Predicted energy: -92.44613119920908 Cost value: 54.383268728223065 Grad:  (Array(0.8432033, dtype=float32), Array(-17.62622, dtype=float32))
Training epoch:  52%|█████▏    | 520/1000 [36:42<33:19,  4.16s/it]Iteration 520 Predicted energy: -92.44068355332155 Cost value: 54.46364574791406 Grad:  (Array(25.95979, dtype=float32), Array(-1.2994624, dtype=float32))
Training epoch:  52%|█████▏    | 521/1000 [36:46<33:11,  4.16s/it]Iteration 521 Predicted energy: -92.43485398108263 Cost value: 54.549723622276005 Grad:  (Array(1.6016437, dtype=float32), Array(-33.679657, dtype=float32))
Training epoch:  52%|█████▏    | 522/1000 [36:50<33:13,  4.17s/it]Iteration 522 Predicted energy: -92.42596597785395 Cost value: 54.68109226466998 Grad:  (Array(40.729576, dtype=float32), Array(-1.975482, dtype=float32))
Training epoch:  52%|█████▏    | 523/1000 [36:54<33:20,  4.19s/it]Iteration 523 Predicted energy: -92.42038682860019 Cost value: 54.76363528745909 Grad:  (Array(2.231549, dtype=float32), Array(-46.713615, dtype=float32))
Training epoch:  52%|█████▏    | 524/1000 [36:58<33:10,  4.18s/it]Iteration 524 Predicted energy: -92.41005526167949 Cost value: 54.91665429451077 Grad:  (Array(51.787407, dtype=float32), Array(-2.4630744, dtype=float32))
Training epoch:  52%|█████▎    | 525/1000 [37:03<33:16,  4.20s/it]Iteration 525 Predicted energy: -92.40952791480129 Cost value: 54.92447046209952 Grad:  (Array(2.624678, dtype=float32), Array(-54.48226, dtype=float32))
Training epoch:  53%|█████▎    | 526/1000 [37:07<33:10,  4.20s/it]Iteration 526 Predicted energy: -92.40365624301478 Cost value: 55.0115360854656 Grad:  (Array(55.49235, dtype=float32), Array(-2.6441662, dtype=float32))
Training epoch:  53%|█████▎    | 527/1000 [37:11<33:13,  4.21s/it]Iteration 527 Predicted energy: -92.41140280895296 Cost value: 54.896683904218996 Grad:  (Array(2.6088793, dtype=float32), Array(-53.226437, dtype=float32))
Training epoch:  53%|█████▎    | 528/1000 [37:15<33:07,  4.21s/it]Iteration 528 Predicted energy: -92.41409958368769 Cost value: 54.856729130202304 Grad:  (Array(49.06279, dtype=float32), Array(-2.3701754, dtype=float32))
Training epoch:  53%|█████▎    | 529/1000 [37:19<33:04,  4.21s/it]Iteration 529 Predicted energy: -92.42535522532259 Cost value: 54.690125260223965 Grad:  (Array(2.1112688, dtype=float32), Array(-42.661472, dtype=float32))
Training epoch:  53%|█████▎    | 530/1000 [37:24<32:58,  4.21s/it]Iteration 530 Predicted energy: -92.43223660530293 Cost value: 54.588393188300174 Grad:  (Array(34.955605, dtype=float32), Array(-1.7254472, dtype=float32))
Training epoch:  53%|█████▎    | 531/1000 [37:28<32:53,  4.21s/it]Iteration 531 Predicted energy: -92.44031021210539 Cost value: 54.46915636549184 Grad:  (Array(1.3373572, dtype=float32), Array(-27.05378, dtype=float32))
Training epoch:  53%|█████▎    | 532/1000 [37:32<32:53,  4.22s/it]Iteration 532 Predicted energy: -92.44527180815741 Cost value: 54.395944627550385 Grad:  (Array(18.773293, dtype=float32), Array(-0.93874305, dtype=float32))
Training epoch:  53%|█████▎    | 533/1000 [37:36<32:51,  4.22s/it]Iteration 533 Predicted energy: -92.44867144865998 Cost value: 54.3458090355739 Grad:  (Array(0.55063295, dtype=float32), Array(-11.461768, dtype=float32))
Training epoch:  53%|█████▎    | 534/1000 [37:41<32:53,  4.23s/it]Iteration 534 Predicted energy: -92.45027270579246 Cost value: 54.32220278932423 Grad:  (Array(4.3119326, dtype=float32), Array(-0.23261721, dtype=float32))
Training epoch:  54%|█████▎    | 535/1000 [37:45<32:43,  4.22s/it]Iteration 535 Predicted energy: -92.45057179391107 Cost value: 54.31779410471797 Grad:  (Array(1.7187004, dtype=float32), Array(-0.11071861, dtype=float32))
Training epoch:  54%|█████▎    | 536/1000 [37:49<32:42,  4.23s/it]Iteration 536 Predicted energy: -92.44988159081728 Cost value: 54.32796825843351 Grad:  (Array(0.35300353, dtype=float32), Array(-7.514743, dtype=float32))
Training epoch:  54%|█████▎    | 537/1000 [37:53<32:27,  4.21s/it]Iteration 537 Predicted energy: -92.44836367237953 Cost value: 54.35034695977465 Grad:  (Array(12.697801, dtype=float32), Array(-0.61883926, dtype=float32))
Training epoch:  54%|█████▍    | 538/1000 [37:57<32:21,  4.20s/it]Iteration 538 Predicted energy: -92.446225621316 Cost value: 54.38187610524695 Grad:  (Array(0.85140616, dtype=float32), Array(-17.807392, dtype=float32))
Training epoch:  54%|█████▍    | 539/1000 [38:02<32:22,  4.21s/it]Iteration 539 Predicted energy: -92.44295145480409 Cost value: 54.43017689719418 Grad:  (Array(23.066357, dtype=float32), Array(-1.1041955, dtype=float32))
Training epoch:  54%|█████▍    | 540/1000 [38:06<32:18,  4.21s/it]Iteration 540 Predicted energy: -92.43927935118721 Cost value: 54.484373599687515 Grad:  (Array(1.3485687, dtype=float32), Array(-28.51056, dtype=float32))
Training epoch:  54%|█████▍    | 541/1000 [38:10<32:16,  4.22s/it]Iteration 541 Predicted energy: -92.4330019031878 Cost value: 54.577085126552845 Grad:  (Array(34.67256, dtype=float32), Array(-1.646954, dtype=float32))
Training epoch:  54%|█████▍    | 542/1000 [38:14<32:01,  4.20s/it]Iteration 542 Predicted energy: -92.4272346147794 Cost value: 54.66233158022858 Grad:  (Array(1.9499434, dtype=float32), Array(-41.07408, dtype=float32))
Training epoch:  54%|█████▍    | 543/1000 [38:18<31:58,  4.20s/it]Iteration 543 Predicted energy: -92.41604872506629 Cost value: 54.82786016998298 Grad:  (Array(48.06158, dtype=float32), Array(-2.2933285, dtype=float32))
Training epoch:  54%|█████▍    | 544/1000 [38:23<31:51,  4.19s/it]Iteration 544 Predicted energy: -92.40983814215609 Cost value: 54.919872303627024 Grad:  (Array(2.6116962, dtype=float32), Array(-54.39106, dtype=float32))
Training epoch:  55%|█████▍    | 545/1000 [38:27<31:35,  4.17s/it]Iteration 545 Predicted energy: -92.39574362762113 Cost value: 55.12897405519994 Grad:  (Array(59.72859, dtype=float32), Array(-2.8938339, dtype=float32))
Training epoch:  55%|█████▍    | 546/1000 [38:31<31:29,  4.16s/it]Iteration 546 Predicted energy: -92.39763997856264 Cost value: 55.10081726152123 Grad:  (Array(3.0485065, dtype=float32), Array(-61.90933, dtype=float32))
Training epoch:  55%|█████▍    | 547/1000 [38:35<31:31,  4.17s/it]Iteration 547 Predicted energy: -92.39260673269534 Cost value: 55.175566087465526 Grad:  (Array(60.92805, dtype=float32), Array(-2.988947, dtype=float32))
Training epoch:  55%|█████▍    | 548/1000 [38:39<31:31,  4.18s/it]Iteration 548 Predicted energy: -92.40794680303533 Cost value: 54.94790853117913 Grad:  (Array(2.805803, dtype=float32), Array(-55.270466, dtype=float32))
Training epoch:  55%|█████▍    | 549/1000 [38:43<31:33,  4.20s/it]Iteration 549 Predicted energy: -92.41731422373053 Cost value: 54.80912078983836 Grad:  (Array(46.285934, dtype=float32), Array(-2.282063, dtype=float32))
Training epoch:  55%|█████▌    | 550/1000 [38:48<31:31,  4.20s/it]Iteration 550 Predicted energy: -92.43272649822258 Cost value: 54.58115438266952 Grad:  (Array(1.825642, dtype=float32), Array(-35.439514, dtype=float32))
Training epoch:  55%|█████▌    | 551/1000 [38:52<31:33,  4.22s/it]Iteration 551 Predicted energy: -92.4422133269314 Cost value: 54.441068785986765 Grad:  (Array(23.107956, dtype=float32), Array(-1.1491984, dtype=float32))
Training epoch:  55%|█████▌    | 552/1000 [38:56<31:26,  4.21s/it]Iteration 552 Predicted energy: -92.44834703182264 Cost value: 54.35059231736768 Grad:  (Array(0.60238975, dtype=float32), Array(-12.170348, dtype=float32))
Training epoch:  55%|█████▌    | 553/1000 [39:00<31:15,  4.20s/it]Iteration 553 Predicted energy: -92.45047544491639 Cost value: 54.3192143098713 Grad:  (Array(1.1518335, dtype=float32), Array(-0.13913399, dtype=float32))
Training epoch:  55%|█████▌    | 554/1000 [39:04<31:06,  4.18s/it]Iteration 554 Predicted energy: -92.44962214695056 Cost value: 54.33179291795283 Grad:  (Array(8.100054, dtype=float32), Array(-0.4231409, dtype=float32))
Training epoch:  56%|█████▌    | 555/1000 [39:09<31:04,  4.19s/it]Iteration 555 Predicted energy: -92.44655026511944 Cost value: 54.377088099677295 Grad:  (Array(0.7982634, dtype=float32), Array(-16.977676, dtype=float32))
Training epoch:  56%|█████▌    | 556/1000 [39:13<31:09,  4.21s/it]Iteration 556 Predicted energy: -92.44120288949048 Cost value: 54.455980668848106 Grad:  (Array(25.463177, dtype=float32), Array(-1.260027, dtype=float32))
Training epoch:  56%|█████▌    | 557/1000 [39:17<31:06,  4.21s/it]Iteration 557 Predicted energy: -92.43466192944429 Cost value: 54.552560560871314 Grad:  (Array(1.5609281, dtype=float32), Array(-33.762123, dtype=float32))
Training epoch:  56%|█████▌    | 558/1000 [39:21<30:51,  4.19s/it]Iteration 558 Predicted energy: -92.42368807846573 Cost value: 54.71478606597093 Grad:  (Array(42.558266, dtype=float32), Array(-2.0566978, dtype=float32))
Training epoch:  56%|█████▌    | 559/1000 [39:25<30:49,  4.19s/it]Iteration 559 Predicted energy: -92.41463049182653 Cost value: 54.848865034904925 Grad:  (Array(2.3780332, dtype=float32), Array(-50.919212, dtype=float32))
Training epoch:  56%|█████▌    | 560/1000 [39:30<30:43,  4.19s/it]Iteration 560 Predicted energy: -92.39761146830922 Cost value: 55.101240525127096 Grad:  (Array(58.870575, dtype=float32), Array(-2.8078077, dtype=float32))
Training epoch:  56%|█████▌    | 561/1000 [39:34<30:38,  4.19s/it]Iteration 561 Predicted energy: -92.39426885994276 Cost value: 55.15087620224724 Grad:  (Array(3.0775826, dtype=float32), Array(-63.814922, dtype=float32))
Training epoch:  56%|█████▌    | 562/1000 [39:38<30:29,  4.18s/it]Iteration 562 Predicted energy: -92.38283445093927 Cost value: 55.32083910539809 Grad:  (Array(65.83804, dtype=float32), Array(-3.171043, dtype=float32))
Training epoch:  56%|█████▋    | 563/1000 [39:42<30:30,  4.19s/it]Iteration 563 Predicted energy: -92.39736898091792 Cost value: 55.104840561915125 Grad:  (Array(3.1023998, dtype=float32), Array(-61.893917, dtype=float32))
Training epoch:  56%|█████▋    | 564/1000 [39:46<30:34,  4.21s/it]Iteration 564 Predicted energy: -92.40535663198 Cost value: 54.98631548778595 Grad:  (Array(53.90349, dtype=float32), Array(-2.6407163, dtype=float32))
Training epoch:  56%|█████▋    | 565/1000 [39:51<30:16,  4.18s/it]Iteration 565 Predicted energy: -92.42537942122613 Cost value: 54.689767389980624 Grad:  (Array(2.1756268, dtype=float32), Array(-42.299778, dtype=float32))
Training epoch:  57%|█████▋    | 566/1000 [39:55<30:16,  4.19s/it]Iteration 566 Predicted energy: -92.4379605880099 Cost value: 54.50384385216012 Grad:  (Array(28.445738, dtype=float32), Array(-1.4197539, dtype=float32))
Training epoch:  57%|█████▋    | 567/1000 [39:59<30:17,  4.20s/it]Iteration 567 Predicted energy: -92.44689688416447 Cost value: 54.3719762251708 Grad:  (Array(0.7770144, dtype=float32), Array(-15.466539, dtype=float32))
Training epoch:  57%|█████▋    | 568/1000 [40:03<30:13,  4.20s/it]Iteration 568 Predicted energy: -92.45017037486024 Cost value: 54.32371123136315 Grad:  (Array(2.1420412, dtype=float32), Array(-0.20757353, dtype=float32))
Training epoch:  57%|█████▋    | 569/1000 [40:07<30:04,  4.19s/it]Iteration 569 Predicted energy: -92.44915024906803 Cost value: 54.33874986895067 Grad:  (Array(8.93313, dtype=float32), Array(-0.4779075, dtype=float32))
Training epoch:  57%|█████▋    | 570/1000 [40:12<30:06,  4.20s/it]Iteration 570 Predicted energy: -92.44507285841985 Cost value: 54.398879319260494 Grad:  (Array(0.940501, dtype=float32), Array(-19.619793, dtype=float32))
Training epoch:  57%|█████▋    | 571/1000 [40:16<29:59,  4.19s/it]Iteration 571 Predicted energy: -92.43822566482552 Cost value: 54.49992997212882 Grad:  (Array(28.94806, dtype=float32), Array(-1.4423712, dtype=float32))
Training epoch:  57%|█████▋    | 572/1000 [40:20<29:58,  4.20s/it]Iteration 572 Predicted energy: -92.43096088743633 Cost value: 54.60724583293075 Grad:  (Array(1.7837722, dtype=float32), Array(-37.56565, dtype=float32))
Training epoch:  57%|█████▋    | 573/1000 [40:24<29:45,  4.18s/it]Iteration 573 Predicted energy: -92.4195028646696 Cost value: 54.77671916926861 Grad:  (Array(45.587646, dtype=float32), Array(-2.2054095, dtype=float32))
Training epoch:  57%|█████▋    | 574/1000 [40:28<29:44,  4.19s/it]Iteration 574 Predicted energy: -92.41290461055553 Cost value: 54.87443177372338 Grad:  (Array(2.4728823, dtype=float32), Array(-52.147648, dtype=float32))
Training epoch:  57%|█████▊    | 575/1000 [40:33<29:41,  4.19s/it]Iteration 575 Predicted energy: -92.40013536593605 Cost value: 55.06377700509676 Grad:  (Array(57.45312, dtype=float32), Array(-2.7306817, dtype=float32))
Training epoch:  58%|█████▊    | 576/1000 [40:37<29:37,  4.19s/it]Iteration 576 Predicted energy: -92.40182331602466 Cost value: 55.038728996844185 Grad:  (Array(2.8570752, dtype=float32), Array(-59.314358, dtype=float32))
Training epoch:  58%|█████▊    | 577/1000 [40:41<29:41,  4.21s/it]Iteration 577 Predicted energy: -92.3974713738943 Cost value: 55.10332039231681 Grad:  (Array(58.744545, dtype=float32), Array(-2.7966962, dtype=float32))
Training epoch:  58%|█████▊    | 578/1000 [40:45<29:28,  4.19s/it]Iteration 578 Predicted energy: -92.41025668757094 Cost value: 54.91366897084974 Grad:  (Array(2.6657374, dtype=float32), Array(-53.885002, dtype=float32))
Training epoch:  58%|█████▊    | 579/1000 [40:49<29:12,  4.16s/it]Iteration 579 Predicted energy: -92.41740633862072 Cost value: 54.80775688663217 Grad:  (Array(46.684547, dtype=float32), Array(-2.2633615, dtype=float32))
Training epoch:  58%|█████▊    | 580/1000 [40:53<29:09,  4.17s/it]Iteration 580 Predicted energy: -92.43097626712124 Cost value: 54.60701853152677 Grad:  (Array(1.870625, dtype=float32), Array(-37.494637, dtype=float32))
Training epoch:  58%|█████▊    | 581/1000 [40:58<29:03,  4.16s/it]Iteration 581 Predicted energy: -92.439467988415 Cost value: 54.481588839298894 Grad:  (Array(27.110529, dtype=float32), Array(-1.3548986, dtype=float32))
Training epoch:  58%|█████▊    | 582/1000 [41:02<28:52,  4.14s/it]Iteration 582 Predicted energy: -92.44620142160578 Cost value: 54.38223302284935 Grad:  (Array(0.85528076, dtype=float32), Array(-17.413198, dtype=float32))
Training epoch:  58%|█████▊    | 583/1000 [41:06<28:51,  4.15s/it]Iteration 583 Predicted energy: -92.44954428507103 Cost value: 54.33294076544812 Grad:  (Array(7.624922, dtype=float32), Array(-0.39728275, dtype=float32))
Training epoch:  58%|█████▊    | 584/1000 [41:10<28:47,  4.15s/it]Iteration 584 Predicted energy: -92.45044881966507 Cost value: 54.31960677514541 Grad:  (Array(0.6991615, dtype=float32), Array(-0.14402992, dtype=float32))
Training epoch:  58%|█████▊    | 585/1000 [41:14<28:52,  4.17s/it]Iteration 585 Predicted energy: -92.44948312948186 Cost value: 54.333842335667406 Grad:  (Array(0.40053532, dtype=float32), Array(-8.711045, dtype=float32))
Training epoch:  59%|█████▊    | 586/1000 [41:18<28:45,  4.17s/it]Iteration 586 Predicted energy: -92.44705846976278 Cost value: 54.36959327233373 Grad:  (Array(15.623685, dtype=float32), Array(-0.7889512, dtype=float32))
Training epoch:  59%|█████▊    | 587/1000 [41:23<29:00,  4.22s/it]Iteration 587 Predicted energy: -92.44372648139769 Cost value: 54.41874169991645 Grad:  (Array(1.06157, dtype=float32), Array(-22.27094, dtype=float32))
Training epoch:  59%|█████▉    | 588/1000 [41:27<28:53,  4.21s/it]Iteration 588 Predicted energy: -92.43875756991699 Cost value: 54.49207677553708 Grad:  (Array(28.490189, dtype=float32), Array(-1.3726224, dtype=float32))
Training epoch:  59%|█████▉    | 589/1000 [41:31<28:49,  4.21s/it]Iteration 589 Predicted energy: -92.43406746826481 Cost value: 54.56134225975228 Grad:  (Array(1.6495515, dtype=float32), Array(-34.45683, dtype=float32))
Training epoch:  59%|█████▉    | 590/1000 [41:35<28:48,  4.22s/it]Iteration 590 Predicted energy: -92.4263035283077 Cost value: 54.676100232562895 Grad:  (Array(40.45693, dtype=float32), Array(-1.91918, dtype=float32))
Training epoch:  59%|█████▉    | 591/1000 [41:40<28:46,  4.22s/it]Iteration 591 Predicted energy: -92.42149374755206 Cost value: 54.74725356847037 Grad:  (Array(2.18559, dtype=float32), Array(-45.80064, dtype=float32))
Training epoch:  59%|█████▉    | 592/1000 [41:44<28:42,  4.22s/it]Iteration 592 Predicted energy: -92.41153237716361 Cost value: 54.89476391975257 Grad:  (Array(50.89698, dtype=float32), Array(-2.4199588, dtype=float32))
Training epoch:  59%|█████▉    | 593/1000 [41:48<28:16,  4.17s/it]Iteration 593 Predicted energy: -92.40988522601289 Cost value: 54.919174448287805 Grad:  (Array(2.616132, dtype=float32), Array(-54.268265, dtype=float32))
Training epoch:  59%|█████▉    | 594/1000 [41:52<28:10,  4.16s/it]Iteration 594 Predicted energy: -92.40202010157164 Cost value: 55.035809206741256 Grad:  (Array(56.33638, dtype=float32), Array(-2.7189224, dtype=float32))
Training epoch:  60%|█████▉    | 595/1000 [41:56<28:22,  4.20s/it]Iteration 595 Predicted energy: -92.40810631377177 Cost value: 54.945543750729094 Grad:  (Array(2.7161, dtype=float32), Array(-55.3811, dtype=float32))
Training epoch:  60%|█████▉    | 596/1000 [42:00<28:20,  4.21s/it]Iteration 596 Predicted energy: -92.40881096834607 Cost value: 54.93509770636614 Grad:  (Array(52.117676, dtype=float32), Array(-2.5550144, dtype=float32))
Training epoch:  60%|█████▉    | 597/1000 [42:05<28:20,  4.22s/it]Iteration 597 Predicted energy: -92.42093388764314 Cost value: 54.75553884415584 Grad:  (Array(2.310514, dtype=float32), Array(-46.046513, dtype=float32))
Training epoch:  60%|█████▉    | 598/1000 [42:09<28:13,  4.21s/it]Iteration 598 Predicted energy: -92.42846019592375 Cost value: 54.64421066431358 Grad:  (Array(38.014984, dtype=float32), Array(-1.8788228, dtype=float32))
Training epoch:  60%|█████▉    | 599/1000 [42:13<27:55,  4.18s/it]Iteration 599 Predicted energy: -92.43834741857064 Cost value: 54.4981323156041 Grad:  (Array(1.4814143, dtype=float32), Array(-29.350166, dtype=float32))
Training epoch:  60%|██████    | 600/1000 [42:17<27:43,  4.16s/it]Iteration 600 Predicted energy: -92.44450157770775 Cost value: 54.40730667549564 Grad:  (Array(19.820692, dtype=float32), Array(-0.98961747, dtype=float32))
Training epoch:  60%|██████    | 601/1000 [42:21<27:32,  4.14s/it]Iteration 601 Predicted energy: -92.44864244850888 Cost value: 54.34623661238094 Grad:  (Array(0.56821835, dtype=float32), Array(-11.52631, dtype=float32))
Training epoch:  60%|██████    | 602/1000 [42:25<27:34,  4.16s/it]Iteration 602 Predicted energy: -92.45041272662371 Cost value: 54.32013880113345 Grad:  (Array(3.2052574, dtype=float32), Array(-0.17707646, dtype=float32))
Training epoch:  60%|██████    | 603/1000 [42:30<27:37,  4.18s/it]Iteration 603 Predicted energy: -92.45043366188858 Cost value: 54.31983020656752 Grad:  (Array(3.779397, dtype=float32), Array(-0.19658522, dtype=float32))
Training epoch:  60%|██████    | 604/1000 [42:34<27:38,  4.19s/it]Iteration 604 Predicted energy: -92.44913135032228 Cost value: 54.33902849284375 Grad:  (Array(0.48797023, dtype=float32), Array(-10.438751, dtype=float32))
Training epoch:  60%|██████    | 605/1000 [42:38<27:32,  4.18s/it]Iteration 605 Predicted energy: -92.44663107940913 Cost value: 54.375896243780154 Grad:  (Array(16.748497, dtype=float32), Array(-0.8275639, dtype=float32))
Training epoch:  61%|██████    | 606/1000 [42:42<27:24,  4.17s/it]Iteration 606 Predicted energy: -92.44322961081984 Cost value: 54.42607268186157 Grad:  (Array(1.0582157, dtype=float32), Array(-22.922634, dtype=float32))
Training epoch:  61%|██████    | 607/1000 [42:46<27:21,  4.18s/it]Iteration 607 Predicted energy: -92.43776604542492 Cost value: 54.50671637814389 Grad:  (Array(29.669695, dtype=float32), Array(-1.4257263, dtype=float32))
Training epoch:  61%|██████    | 608/1000 [42:51<27:11,  4.16s/it]Iteration 608 Predicted energy: -92.43191326488368 Cost value: 54.59317122687065 Grad:  (Array(1.7006711, dtype=float32), Array(-36.568752, dtype=float32))
Training epoch:  61%|██████    | 609/1000 [42:55<27:04,  4.15s/it]Iteration 609 Predicted energy: -92.42144494680508 Cost value: 54.74797573784348 Grad:  (Array(44.238026, dtype=float32), Array(-2.101647, dtype=float32))
Training epoch:  61%|██████    | 610/1000 [42:59<26:58,  4.15s/it]Iteration 610 Predicted energy: -92.41393288190328 Cost value: 54.859198522482664 Grad:  (Array(2.4470716, dtype=float32), Array(-51.449516, dtype=float32))
Training epoch:  61%|██████    | 611/1000 [43:03<27:07,  4.18s/it]Iteration 611 Predicted energy: -92.39878766406714 Cost value: 55.08378005697948 Grad:  (Array(58.150246, dtype=float32), Array(-2.7889583, dtype=float32))
Training epoch:  61%|██████    | 612/1000 [43:07<27:00,  4.18s/it]Iteration 612 Predicted energy: -92.39745250366911 Cost value: 55.10360054611523 Grad:  (Array(3.0406942, dtype=float32), Array(-61.981464, dtype=float32))
Training epoch:  61%|██████▏   | 613/1000 [43:11<26:51,  4.16s/it]Iteration 613 Predicted energy: -92.38872418919752 Cost value: 55.233260427526275 Grad:  (Array(62.835667, dtype=float32), Array(-3.0744562, dtype=float32))
Training epoch:  61%|██████▏   | 614/1000 [43:15<26:46,  4.16s/it]Iteration 614 Predicted energy: -92.40260250787514 Cost value: 55.02716825274595 Grad:  (Array(2.9753036, dtype=float32), Array(-58.657246, dtype=float32))
Training epoch:  62%|██████▏   | 615/1000 [43:20<26:47,  4.18s/it]Iteration 615 Predicted energy: -92.41038346169779 Cost value: 54.91179009908701 Grad:  (Array(50.697956, dtype=float32), Array(-2.507554, dtype=float32))
Training epoch:  62%|██████▏   | 616/1000 [43:24<26:35,  4.15s/it]Iteration 616 Predicted energy: -92.42783573603361 Cost value: 54.653443284413555 Grad:  (Array(2.0665743, dtype=float32), Array(-40.007236, dtype=float32))
Training epoch:  62%|██████▏   | 617/1000 [43:28<26:21,  4.13s/it]Iteration 617 Predicted energy: -92.43884367179771 Cost value: 54.490805596329345 Grad:  (Array(27.30618, dtype=float32), Array(-1.3650211, dtype=float32))
Training epoch:  62%|██████▏   | 618/1000 [43:32<26:14,  4.12s/it]Iteration 618 Predicted energy: -92.44687053194023 Cost value: 54.37236485453157 Grad:  (Array(0.7801389, dtype=float32), Array(-15.648136, dtype=float32))
Training epoch:  62%|██████▏   | 619/1000 [43:36<26:21,  4.15s/it]Iteration 619 Predicted energy: -92.45017573637861 Cost value: 54.32363219765616 Grad:  (Array(3.6767216, dtype=float32), Array(-0.22267306, dtype=float32))
Training epoch:  62%|██████▏   | 620/1000 [43:40<26:20,  4.16s/it]Iteration 620 Predicted energy: -92.44993130814846 Cost value: 54.3272353527821 Grad:  (Array(6.2843523, dtype=float32), Array(-0.3344464, dtype=float32))
Training epoch:  62%|██████▏   | 621/1000 [43:45<26:20,  4.17s/it]Iteration 621 Predicted energy: -92.44702811704731 Cost value: 54.370040889241174 Grad:  (Array(0.7567786, dtype=float32), Array(-15.91947, dtype=float32))
Training epoch:  62%|██████▏   | 622/1000 [43:49<26:26,  4.20s/it]Iteration 622 Predicted energy: -92.4416617303775 Cost value: 54.44920891137068 Grad:  (Array(24.7995, dtype=float32), Array(-1.2252151, dtype=float32))
Training epoch:  62%|██████▏   | 623/1000 [43:53<26:22,  4.20s/it]Iteration 623 Predicted energy: -92.4349974492075 Cost value: 54.54760439528316 Grad:  (Array(1.5543189, dtype=float32), Array(-33.38659, dtype=float32))
Training epoch:  62%|██████▏   | 624/1000 [43:57<26:22,  4.21s/it]Iteration 624 Predicted energy: -92.42400952365891 Cost value: 54.71003074487172 Grad:  (Array(42.28356, dtype=float32), Array(-2.0344577, dtype=float32))
Training epoch:  62%|██████▎   | 625/1000 [44:01<26:16,  4.20s/it]Iteration 625 Predicted energy: -92.41500420579573 Cost value: 54.84332972179019 Grad:  (Array(2.3608453, dtype=float32), Array(-50.57515, dtype=float32))
Training epoch:  63%|██████▎   | 626/1000 [44:06<26:12,  4.21s/it]Iteration 626 Predicted energy: -92.39825573195809 Cost value: 55.091676175033555 Grad:  (Array(58.496597, dtype=float32), Array(-2.7758036, dtype=float32))
Training epoch:  63%|██████▎   | 627/1000 [44:10<26:18,  4.23s/it]Iteration 627 Predicted energy: -92.39488662293279 Cost value: 55.14170111872289 Grad:  (Array(3.0363696, dtype=float32), Array(-63.384644, dtype=float32))
Training epoch:  63%|██████▎   | 628/1000 [44:14<26:10,  4.22s/it]Iteration 628 Predicted energy: -92.38345135436913 Cost value: 55.31166267977297 Grad:  (Array(65.535446, dtype=float32), Array(-3.1441534, dtype=float32))
Training epoch:  63%|██████▎   | 629/1000 [44:18<26:06,  4.22s/it]Iteration 629 Predicted energy: -92.39741334671558 Cost value: 55.104181885873125 Grad:  (Array(3.0795064, dtype=float32), Array(-61.812992, dtype=float32))
Training epoch:  63%|██████▎   | 630/1000 [44:22<25:47,  4.18s/it]Iteration 630 Predicted energy: -92.40481441851547 Cost value: 54.994357106567044 Grad:  (Array(54.186264, dtype=float32), Array(-2.6520936, dtype=float32))
Training epoch:  63%|██████▎   | 631/1000 [44:27<25:43,  4.18s/it]Iteration 631 Predicted energy: -92.4246717953617 Cost value: 54.7002340353521 Grad:  (Array(2.1990035, dtype=float32), Array(-42.86557, dtype=float32))
Training epoch:  63%|██████▎   | 632/1000 [44:31<25:44,  4.20s/it]Iteration 632 Predicted energy: -92.43720827649591 Cost value: 54.51495255622742 Grad:  (Array(29.25988, dtype=float32), Array(-1.4636698, dtype=float32))
Training epoch:  63%|██████▎   | 633/1000 [44:35<25:45,  4.21s/it]Iteration 633 Predicted energy: -92.44644851256871 Cost value: 54.37858877337455 Grad:  (Array(0.8267517, dtype=float32), Array(-16.417196, dtype=float32))
Training epoch:  63%|██████▎   | 634/1000 [44:39<25:39,  4.21s/it]Iteration 634 Predicted energy: -92.45005576400985 Cost value: 54.325400714351645 Grad:  (Array(3.1426105, dtype=float32), Array(-0.24759597, dtype=float32))
Training epoch:  64%|██████▎   | 635/1000 [44:44<25:33,  4.20s/it]Iteration 635 Predicted energy: -92.44938397145205 Cost value: 54.335304162788276 Grad:  (Array(7.8582516, dtype=float32), Array(-0.42486235, dtype=float32))
Training epoch:  64%|██████▎   | 636/1000 [44:48<25:26,  4.19s/it]Iteration 636 Predicted energy: -92.44563007607404 Cost value: 54.3906600457218 Grad:  (Array(0.8904631, dtype=float32), Array(-18.529589, dtype=float32))
Training epoch:  64%|██████▎   | 637/1000 [44:52<25:16,  4.18s/it]Iteration 637 Predicted energy: -92.43919373020701 Cost value: 54.48563760439388 Grad:  (Array(27.755726, dtype=float32), Array(-1.3843244, dtype=float32))
Training epoch:  64%|██████▍   | 638/1000 [44:56<25:07,  4.16s/it]Iteration 638 Predicted energy: -92.43223532666978 Cost value: 54.58841208239751 Grad:  (Array(1.724196, dtype=float32), Array(-36.27054, dtype=float32))
Training epoch:  64%|██████▍   | 639/1000 [45:00<25:05,  4.17s/it]Iteration 639 Predicted energy: -92.42141647409532 Cost value: 54.74839708849074 Grad:  (Array(44.15033, dtype=float32), Array(-2.1332793, dtype=float32))
Training epoch:  64%|██████▍   | 640/1000 [45:04<25:03,  4.18s/it]Iteration 640 Predicted energy: -92.4149831449407 Cost value: 54.84364165995939 Grad:  (Array(2.3927693, dtype=float32), Array(-50.59732, dtype=float32))
Training epoch:  64%|██████▍   | 641/1000 [45:09<25:00,  4.18s/it]Iteration 641 Predicted energy: -92.40279139414044 Cost value: 55.02436596048001 Grad:  (Array(55.937252, dtype=float32), Array(-2.653289, dtype=float32))
Training epoch:  64%|██████▍   | 642/1000 [45:13<24:59,  4.19s/it]Iteration 642 Predicted energy: -92.40370102570225 Cost value: 55.01087178321604 Grad:  (Array(2.787972, dtype=float32), Array(-58.08744, dtype=float32))
Training epoch:  64%|██████▍   | 643/1000 [45:17<24:50,  4.17s/it]Iteration 643 Predicted energy: -92.39865009619781 Cost value: 55.08582209065237 Grad:  (Array(58.09308, dtype=float32), Array(-2.7621727, dtype=float32))
Training epoch:  64%|██████▍   | 644/1000 [45:21<24:46,  4.18s/it]Iteration 644 Predicted energy: -92.40996766184104 Cost value: 54.917952632913924 Grad:  (Array(2.6632118, dtype=float32), Array(-54.037514, dtype=float32))
Training epoch:  64%|██████▍   | 645/1000 [45:25<24:43,  4.18s/it]Iteration 645 Predicted energy: -92.41577530231552 Cost value: 54.83190940804481 Grad:  (Array(47.733353, dtype=float32), Array(-2.3174486, dtype=float32))
Training epoch:  65%|██████▍   | 646/1000 [45:29<24:39,  4.18s/it]Iteration 646 Predicted energy: -92.42899113657485 Cost value: 54.63636133671008 Grad:  (Array(1.960662, dtype=float32), Array(-39.30797, dtype=float32))
Training epoch:  65%|██████▍   | 647/1000 [45:34<24:44,  4.21s/it]Iteration 647 Predicted energy: -92.43730832415261 Cost value: 54.513475177662556 Grad:  (Array(29.576782, dtype=float32), Array(-1.4741004, dtype=float32))
Training epoch:  65%|██████▍   | 648/1000 [45:38<24:46,  4.22s/it]Iteration 648 Predicted energy: -92.44466472180216 Cost value: 54.40489995772828 Grad:  (Array(1.0034629, dtype=float32), Array(-20.27695, dtype=float32))
Training epoch:  65%|██████▍   | 649/1000 [45:42<24:39,  4.21s/it]Iteration 649 Predicted energy: -92.44867449813991 Cost value: 54.345764074288965 Grad:  (Array(10.751074, dtype=float32), Array(-0.5515629, dtype=float32))
Training epoch:  65%|██████▌   | 650/1000 [45:46<24:34,  4.21s/it]Iteration 650 Predicted energy: -92.45036624880692 Cost value: 54.32082390673792 Grad:  (Array(0.10648756, dtype=float32), Array(-2.6433258, dtype=float32))
Training epoch:  65%|██████▌   | 651/1000 [45:51<24:25,  4.20s/it]Iteration 651 Predicted energy: -92.45016531002906 Cost value: 54.32378589168095 Grad:  (Array(0.23409095, dtype=float32), Array(-5.257707, dtype=float32))
Training epoch:  65%|██████▌   | 652/1000 [45:55<24:22,  4.20s/it]Iteration 652 Predicted energy: -92.44852572620431 Cost value: 54.34795757732997 Grad:  (Array(11.985507, dtype=float32), Array(-0.6068005, dtype=float32))
Training epoch:  65%|██████▌   | 653/1000 [45:59<24:12,  4.19s/it]Iteration 653 Predicted energy: -92.44587479424446 Cost value: 54.38705051143218 Grad:  (Array(0.8819335, dtype=float32), Array(-18.477262, dtype=float32))
Training epoch:  65%|██████▌   | 654/1000 [46:03<24:06,  4.18s/it]Iteration 654 Predicted energy: -92.44186026638461 Cost value: 54.44627896801998 Grad:  (Array(24.55034, dtype=float32), Array(-1.1809604, dtype=float32))
Training epoch:  66%|██████▌   | 655/1000 [46:07<24:02,  4.18s/it]Iteration 655 Predicted energy: -92.43765369170305 Cost value: 54.508375375805024 Grad:  (Array(1.448549, dtype=float32), Array(-30.43386, dtype=float32))
Training epoch:  66%|██████▌   | 656/1000 [46:11<24:00,  4.19s/it]Iteration 656 Predicted energy: -92.43088241814328 Cost value: 54.60840556369518 Grad:  (Array(36.53146, dtype=float32), Array(-1.7299635, dtype=float32))
Training epoch:  66%|██████▌   | 657/1000 [46:16<23:54,  4.18s/it]Iteration 657 Predicted energy: -92.42570084305034 Cost value: 54.68501350185328 Grad:  (Array(2.0035949, dtype=float32), Array(-42.27832, dtype=float32))
Training epoch:  66%|██████▌   | 658/1000 [46:20<23:51,  4.18s/it]Iteration 658 Predicted energy: -92.4157288566232 Cost value: 54.832597257635705 Grad:  (Array(48.180305, dtype=float32), Array(-2.282088, dtype=float32))
Training epoch:  66%|██████▌   | 659/1000 [46:24<23:43,  4.17s/it]Iteration 659 Predicted energy: -92.41190337032059 Cost value: 54.8892666065342 Grad:  (Array(2.528646, dtype=float32), Array(-52.837624, dtype=float32))
Training epoch:  66%|██████▌   | 660/1000 [46:28<23:33,  4.16s/it]Iteration 660 Predicted energy: -92.40159023050829 Cost value: 55.0421874850897 Grad:  (Array(56.543438, dtype=float32), Array(-2.7224648, dtype=float32))
Training epoch:  66%|██████▌   | 661/1000 [46:32<23:30,  4.16s/it]Iteration 661 Predicted energy: -92.40499344962105 Cost value: 54.99170181441662 Grad:  (Array(2.8018453, dtype=float32), Array(-57.31538, dtype=float32))
Training epoch:  66%|██████▌   | 662/1000 [46:36<23:24,  4.16s/it]Iteration 662 Predicted energy: -92.40260087582283 Cost value: 55.02719246597454 Grad:  (Array(55.637165, dtype=float32), Array(-2.7241175, dtype=float32))
Training epoch:  66%|██████▋   | 663/1000 [46:41<23:28,  4.18s/it]Iteration 663 Predicted energy: -92.41498332246276 Cost value: 54.84363903062727 Grad:  (Array(2.5390189, dtype=float32), Array(-50.422935, dtype=float32))
Training epoch:  66%|██████▋   | 664/1000 [46:45<23:24,  4.18s/it]Iteration 664 Predicted energy: -92.4224173500993 Cost value: 54.73358669480243 Grad:  (Array(42.669067, dtype=float32), Array(-2.1097646, dtype=float32))
Training epoch:  66%|██████▋   | 665/1000 [46:49<23:20,  4.18s/it]Iteration 665 Predicted energy: -92.43450895680908 Cost value: 54.55482028702074 Grad:  (Array(1.7133359, dtype=float32), Array(-33.613228, dtype=float32))
Training epoch:  67%|██████▋   | 666/1000 [46:53<23:17,  4.18s/it]Iteration 666 Predicted energy: -92.44215921994014 Cost value: 54.441867237032525 Grad:  (Array(23.224106, dtype=float32), Array(-1.1584336, dtype=float32))
Training epoch:  67%|██████▋   | 667/1000 [46:57<23:12,  4.18s/it]Iteration 667 Predicted energy: -92.44769170634426 Cost value: 54.360255239758644 Grad:  (Array(0.6983091, dtype=float32), Array(-14.01323, dtype=float32))
Training epoch:  67%|██████▋   | 668/1000 [47:01<23:04,  4.17s/it]Iteration 668 Predicted energy: -92.45019725425979 Cost value: 54.32331500489548 Grad:  (Array(4.6186485, dtype=float32), Array(-0.23404019, dtype=float32))
Training epoch:  67%|██████▋   | 669/1000 [47:06<22:59,  4.17s/it]Iteration 669 Predicted energy: -92.45045908987933 Cost value: 54.31945538852079 Grad:  (Array(3.2405844, dtype=float32), Array(-0.17404377, dtype=float32))
Training epoch:  67%|██████▋   | 670/1000 [47:10<22:56,  4.17s/it]Iteration 670 Predicted energy: -92.44902392330476 Cost value: 54.34061230114019 Grad:  (Array(0.50072914, dtype=float32), Array(-10.737338, dtype=float32))
Training epoch:  67%|██████▋   | 671/1000 [47:14<22:54,  4.18s/it]Iteration 671 Predicted energy: -92.44609227592258 Cost value: 54.38384280938815 Grad:  (Array(17.77586, dtype=float32), Array(-0.88082963, dtype=float32))
Training epoch:  67%|██████▋   | 672/1000 [47:18<22:50,  4.18s/it]Iteration 672 Predicted energy: -92.44207070998289 Cost value: 54.44317338156725 Grad:  (Array(1.1291536, dtype=float32), Array(-24.609957, dtype=float32))
Training epoch:  67%|██████▋   | 673/1000 [47:22<22:43,  4.17s/it]Iteration 673 Predicted energy: -92.4355838782065 Cost value: 54.53894243809873 Grad:  (Array(31.994106, dtype=float32), Array(-1.5375755, dtype=float32))
Training epoch:  67%|██████▋   | 674/1000 [47:26<22:36,  4.16s/it]Iteration 674 Predicted energy: -92.42887251188642 Cost value: 54.63811501307791 Grad:  (Array(1.8228492, dtype=float32), Array(-39.38232, dtype=float32))
Training epoch:  68%|██████▊   | 675/1000 [47:31<22:32,  4.16s/it]Iteration 675 Predicted energy: -92.41688760123819 Cost value: 54.815437815993434 Grad:  (Array(47.391468, dtype=float32), Array(-2.2453868, dtype=float32))
Training epoch:  68%|██████▊   | 676/1000 [47:35<22:29,  4.17s/it]Iteration 676 Predicted energy: -92.4094658915456 Cost value: 54.92538978760979 Grad:  (Array(2.589176, dtype=float32), Array(-54.41815, dtype=float32))
Training epoch:  68%|██████▊   | 677/1000 [47:39<22:26,  4.17s/it]Iteration 677 Predicted energy: -92.39417802432638 Cost value: 55.152225367126995 Grad:  (Array(60.44027, dtype=float32), Array(-2.8967295, dtype=float32))
Training epoch:  68%|██████▊   | 678/1000 [47:43<22:28,  4.19s/it]Iteration 678 Predicted energy: -92.39597016904985 Cost value: 55.12561001667626 Grad:  (Array(3.0922966, dtype=float32), Array(-62.72728, dtype=float32))
Training epoch:  68%|██████▊   | 679/1000 [47:47<22:20,  4.18s/it]Iteration 679 Predicted energy: -92.39092830515916 Cost value: 55.20050371039813 Grad:  (Array(61.591084, dtype=float32), Array(-3.018661, dtype=float32))
Training epoch:  68%|██████▊   | 680/1000 [47:52<22:15,  4.17s/it]Iteration 680 Predicted energy: -92.40753780762797 Cost value: 54.953972207229604 Grad:  (Array(2.8295248, dtype=float32), Array(-55.41141, dtype=float32))
Training epoch:  68%|██████▊   | 681/1000 [47:56<22:09,  4.17s/it]Iteration 681 Predicted energy: -92.41791950445605 Cost value: 54.80015898454608 Grad:  (Array(45.67326, dtype=float32), Array(-2.2668757, dtype=float32))
Training epoch:  68%|██████▊   | 682/1000 [48:00<22:10,  4.19s/it]Iteration 682 Predicted energy: -92.43379447880689 Cost value: 54.56537524301725 Grad:  (Array(1.7634314, dtype=float32), Array(-34.187073, dtype=float32))
Training epoch:  68%|██████▊   | 683/1000 [48:04<22:07,  4.19s/it]Iteration 683 Predicted energy: -92.44337241619421 Cost value: 54.42396563670575 Grad:  (Array(21.123123, dtype=float32), Array(-1.0673364, dtype=float32))
Training epoch:  68%|██████▊   | 684/1000 [48:08<22:04,  4.19s/it]Iteration 684 Predicted energy: -92.44899854081983 Cost value: 54.34098652126932 Grad:  (Array(0.467175, dtype=float32), Array(-9.675881, dtype=float32))
Training epoch:  68%|██████▊   | 685/1000 [48:13<22:01,  4.20s/it]Iteration 685 Predicted energy: -92.45038072522122 Cost value: 54.32061051689326 Grad:  (Array(0.07368268, dtype=float32), Array(-1.9035358, dtype=float32))
Training epoch:  69%|██████▊   | 686/1000 [48:17<22:08,  4.23s/it]Iteration 686 Predicted energy: -92.4485673623087 Cost value: 54.34734368745319 Grad:  (Array(11.589118, dtype=float32), Array(-0.594252, dtype=float32))
Training epoch:  69%|██████▊   | 687/1000 [48:21<22:00,  4.22s/it]Iteration 687 Predicted energy: -92.44443672219975 Cost value: 54.408263445131745 Grad:  (Array(0.9927263, dtype=float32), Array(-20.913881, dtype=float32))
Training epoch:  69%|██████▉   | 688/1000 [48:25<21:57,  4.22s/it]Iteration 688 Predicted energy: -92.43762022752405 Cost value: 54.50886950757042 Grad:  (Array(29.770512, dtype=float32), Array(-1.4549043, dtype=float32))
Training epoch:  69%|██████▉   | 689/1000 [48:29<21:46,  4.20s/it]Iteration 689 Predicted energy: -92.43009622244965 Cost value: 54.620025761106255 Grad:  (Array(1.7795969, dtype=float32), Array(-38.26069, dtype=float32))
Training epoch:  69%|██████▉   | 690/1000 [48:34<21:39,  4.19s/it]Iteration 690 Predicted energy: -92.417448603606 Cost value: 54.807131093933044 Grad:  (Array(46.984947, dtype=float32), Array(-2.2376995, dtype=float32))
Training epoch:  69%|██████▉   | 691/1000 [48:38<21:35,  4.19s/it]Iteration 691 Predicted energy: -92.40914458614051 Cost value: 54.930152386594635 Grad:  (Array(2.5544524, dtype=float32), Array(-54.543137, dtype=float32))
Training epoch:  69%|██████▉   | 692/1000 [48:42<21:32,  4.20s/it]Iteration 692 Predicted energy: -92.39288285172539 Cost value: 55.17146412519365 Grad:  (Array(61.179962, dtype=float32), Array(-2.8951354, dtype=float32))
Training epoch:  69%|██████▉   | 693/1000 [48:46<21:29,  4.20s/it]Iteration 693 Predicted energy: -92.39391159551654 Cost value: 55.15618268094028 Grad:  (Array(3.082822, dtype=float32), Array(-63.851875, dtype=float32))
Training epoch:  69%|██████▉   | 694/1000 [48:50<21:24,  4.20s/it]Iteration 694 Predicted energy: -92.38766201767399 Cost value: 55.24904947837919 Grad:  (Array(63.389137, dtype=float32), Array(-3.0522108, dtype=float32))
Training epoch:  70%|██████▉   | 695/1000 [48:55<21:22,  4.20s/it]Iteration 695 Predicted energy: -92.40467384627895 Cost value: 54.99644204258077 Grad:  (Array(2.878716, dtype=float32), Array(-57.314552, dtype=float32))
Training epoch:  70%|██████▉   | 696/1000 [48:59<21:19,  4.21s/it]Iteration 696 Predicted energy: -92.41512031883686 Cost value: 54.84160995523812 Grad:  (Array(47.743774, dtype=float32), Array(-2.3519323, dtype=float32))
Training epoch:  70%|██████▉   | 697/1000 [49:03<21:14,  4.21s/it]Iteration 697 Predicted energy: -92.4322160551611 Cost value: 54.58869685388752 Grad:  (Array(1.8429079, dtype=float32), Array(-35.91304, dtype=float32))
Training epoch:  70%|██████▉   | 698/1000 [49:07<21:12,  4.21s/it]Iteration 698 Predicted energy: -92.44254131459752 Cost value: 54.43622883262559 Grad:  (Array(22.423286, dtype=float32), Array(-1.1338203, dtype=float32))
Training epoch:  70%|██████▉   | 699/1000 [49:11<21:06,  4.21s/it]Iteration 699 Predicted energy: -92.44871722813436 Cost value: 54.345134068669935 Grad:  (Array(0.50764096, dtype=float32), Array(-10.388647, dtype=float32))
Training epoch:  70%|███████   | 700/1000 [49:16<20:59,  4.20s/it]Iteration 700 Predicted energy: -92.45023986163724 Cost value: 54.32268693688195 Grad:  (Array(0.06855015, dtype=float32), Array(-1.8504553, dtype=float32))
Training epoch:  70%|███████   | 701/1000 [49:20<20:53,  4.19s/it]Iteration 701 Predicted energy: -92.44827069837235 Cost value: 54.35171782715963 Grad:  (Array(11.96549, dtype=float32), Array(-0.6241469, dtype=float32))
Training epoch:  70%|███████   | 702/1000 [49:24<20:47,  4.19s/it]Iteration 702 Predicted energy: -92.44391114811552 Cost value: 54.41601719599159 Grad:  (Array(1.0403501, dtype=float32), Array(-21.68593, dtype=float32))
Training epoch:  70%|███████   | 703/1000 [49:28<20:45,  4.19s/it]Iteration 703 Predicted energy: -92.4370095624002 Cost value: 54.51788697663118 Grad:  (Array(30.331345, dtype=float32), Array(-1.4941506, dtype=float32))
Training epoch:  70%|███████   | 704/1000 [49:32<20:39,  4.19s/it]Iteration 704 Predicted energy: -92.43011737494193 Cost value: 54.619713105032595 Grad:  (Array(1.8084335, dtype=float32), Array(-38.276886, dtype=float32))
Training epoch:  70%|███████   | 705/1000 [49:37<20:35,  4.19s/it]Iteration 705 Predicted energy: -92.41910269300772 Cost value: 54.78264277405952 Grad:  (Array(45.76542, dtype=float32), Array(-2.1895947, dtype=float32))
Training epoch:  71%|███████   | 706/1000 [49:41<20:27,  4.18s/it]Iteration 706 Predicted energy: -92.41328901034805 Cost value: 54.8687368633959 Grad:  (Array(2.4388177, dtype=float32), Array(-51.714367, dtype=float32))
Training epoch:  71%|███████   | 707/1000 [49:45<20:28,  4.19s/it]Iteration 707 Predicted energy: -92.40153548239772 Cost value: 55.04299984517481 Grad:  (Array(56.601418, dtype=float32), Array(-2.6714392, dtype=float32))
Training epoch:  71%|███████   | 708/1000 [49:49<20:27,  4.20s/it]Iteration 708 Predicted energy: -92.40347546735752 Cost value: 55.01421773564352 Grad:  (Array(2.7998006, dtype=float32), Array(-58.17479, dtype=float32))
Training epoch:  71%|███████   | 709/1000 [49:53<20:18,  4.19s/it]Iteration 709 Predicted energy: -92.3993542859983 Cost value: 55.075369617986865 Grad:  (Array(57.619926, dtype=float32), Array(-2.7524617, dtype=float32))
Training epoch:  71%|███████   | 710/1000 [49:58<20:20,  4.21s/it]Iteration 710 Predicted energy: -92.41125680386021 Cost value: 54.8988474960589 Grad:  (Array(2.6238787, dtype=float32), Array(-53.111168, dtype=float32))
Training epoch:  71%|███████   | 711/1000 [50:02<20:21,  4.23s/it]Iteration 711 Predicted energy: -92.41771176942642 Cost value: 54.80323463328699 Grad:  (Array(46.279533, dtype=float32), Array(-2.2640917, dtype=float32))
Training epoch:  71%|███████   | 712/1000 [50:06<20:14,  4.22s/it]Iteration 712 Predicted energy: -92.430712455645 Cost value: 54.610917553337444 Grad:  (Array(1.8848743, dtype=float32), Array(-37.57193, dtype=float32))
Training epoch:  71%|███████▏  | 713/1000 [50:10<20:06,  4.21s/it]Iteration 713 Predicted energy: -92.4389120346688 Cost value: 54.48979632045322 Grad:  (Array(27.565155, dtype=float32), Array(-1.3790478, dtype=float32))
Training epoch:  71%|███████▏  | 714/1000 [50:14<20:02,  4.20s/it]Iteration 714 Predicted energy: -92.44572337046482 Cost value: 54.389283961718306 Grad:  (Array(0.90121645, dtype=float32), Array(-18.196558, dtype=float32))
Training epoch:  72%|███████▏  | 715/1000 [50:19<19:53,  4.19s/it]Iteration 715 Predicted energy: -92.44927556810516 Cost value: 54.33690231055161 Grad:  (Array(8.557046, dtype=float32), Array(-0.4439325, dtype=float32))
Training epoch:  72%|███████▏  | 716/1000 [50:23<19:45,  4.17s/it]Iteration 716 Predicted energy: -92.45047444041822 Cost value: 54.31922911649081 Grad:  (Array(0.02883451, dtype=float32), Array(-0.4734974, dtype=float32))
Training epoch:  72%|███████▏  | 717/1000 [50:27<19:42,  4.18s/it]Iteration 717 Predicted energy: -92.449809544811 Cost value: 54.32903032994982 Grad:  (Array(0.34669057, dtype=float32), Array(-7.450073, dtype=float32))
Training epoch:  72%|███████▏  | 718/1000 [50:31<19:38,  4.18s/it]Iteration 718 Predicted energy: -92.44768283136321 Cost value: 54.3603861092562 Grad:  (Array(14.263295, dtype=float32), Array(-0.7066825, dtype=float32))
Training epoch:  72%|███████▏  | 719/1000 [50:35<19:37,  4.19s/it]Iteration 719 Predicted energy: -92.44456712661372 Cost value: 54.40633968517416 Grad:  (Array(0.99168074, dtype=float32), Array(-20.805338, dtype=float32))
Training epoch:  72%|███████▏  | 720/1000 [50:40<19:35,  4.20s/it]Iteration 720 Predicted energy: -92.43984335412351 Cost value: 54.4760477081413 Grad:  (Array(27.15466, dtype=float32), Array(-1.3012856, dtype=float32))
Training epoch:  72%|███████▏  | 721/1000 [50:44<19:29,  4.19s/it]Iteration 721 Predicted energy: -92.43506351042767 Cost value: 54.546628591527245 Grad:  (Array(1.5645363, dtype=float32), Array(-33.280632, dtype=float32))
Training epoch:  72%|███████▏  | 722/1000 [50:48<19:29,  4.21s/it]Iteration 722 Predicted energy: -92.42712012248504 Cost value: 54.66402456750005 Grad:  (Array(39.749596, dtype=float32), Array(-1.8742307, dtype=float32))
Training epoch:  72%|███████▏  | 723/1000 [50:52<19:21,  4.19s/it]Iteration 723 Predicted energy: -92.42148043147913 Cost value: 54.74745062358902 Grad:  (Array(2.1551237, dtype=float32), Array(-45.683952, dtype=float32))
Training epoch:  72%|███████▏  | 724/1000 [50:56<19:17,  4.20s/it]Iteration 724 Predicted energy: -92.4102368079651 Cost value: 54.91396360194344 Grad:  (Array(51.615772, dtype=float32), Array(-2.4466636, dtype=float32))
Training epoch:  72%|███████▎  | 725/1000 [51:00<19:11,  4.19s/it]Iteration 725 Predicted energy: -92.40747321816876 Cost value: 54.95492982694977 Grad:  (Array(2.6714551, dtype=float32), Array(-55.70595, dtype=float32))
Training epoch:  73%|███████▎  | 726/1000 [51:05<19:03,  4.17s/it]Iteration 726 Predicted energy: -92.3981185734378 Cost value: 55.093712278261926 Grad:  (Array(58.245827, dtype=float32), Array(-2.815029, dtype=float32))
Training epoch:  73%|███████▎  | 727/1000 [51:09<19:07,  4.20s/it]Iteration 727 Predicted energy: -92.40509634369812 Cost value: 54.99017577434167 Grad:  (Array(2.8237412, dtype=float32), Array(-57.11052, dtype=float32))
Training epoch:  73%|███████▎  | 728/1000 [51:13<19:03,  4.21s/it]Iteration 728 Predicted energy: -92.40663961802713 Cost value: 54.967289743013595 Grad:  (Array(53.103252, dtype=float32), Array(-2.6124802, dtype=float32))
Training epoch:  73%|███████▎  | 729/1000 [51:17<19:02,  4.21s/it]Iteration 729 Predicted energy: -92.42089649601955 Cost value: 54.75609221904082 Grad:  (Array(2.3370912, dtype=float32), Array(-45.869053, dtype=float32))
Training epoch:  73%|███████▎  | 730/1000 [51:21<18:51,  4.19s/it]Iteration 730 Predicted energy: -92.43010944481999 Cost value: 54.61983032046698 Grad:  (Array(36.259003, dtype=float32), Array(-1.801672, dtype=float32))
Training epoch:  73%|███████▎  | 731/1000 [51:26<18:42,  4.17s/it]Iteration 731 Predicted energy: -92.44052836393178 Cost value: 54.465936351530104 Grad:  (Array(1.3415074, dtype=float32), Array(-26.390652, dtype=float32))
Training epoch:  73%|███████▎  | 732/1000 [51:30<18:44,  4.19s/it]Iteration 732 Predicted energy: -92.4466670527121 Cost value: 54.37536571070326 Grad:  (Array(15.553246, dtype=float32), Array(-0.78167826, dtype=float32))
Training epoch:  73%|███████▎  | 733/1000 [51:34<18:36,  4.18s/it]Iteration 733 Predicted energy: -92.44991320253774 Cost value: 54.32750225520121 Grad:  (Array(0.3099186, dtype=float32), Array(-6.393116, dtype=float32))
Training epoch:  73%|███████▎  | 734/1000 [51:38<18:34,  4.19s/it]Iteration 734 Predicted energy: -92.45048686624772 Cost value: 54.31904595599159 Grad:  (Array(0.12396552, dtype=float32), Array(-2.6748753, dtype=float32))
Training epoch:  74%|███████▎  | 735/1000 [51:42<18:33,  4.20s/it]Iteration 735 Predicted energy: -92.44904871377375 Cost value: 54.34024681048957 Grad:  (Array(10.487083, dtype=float32), Array(-0.530135, dtype=float32))
Training epoch:  74%|███████▎  | 736/1000 [51:47<18:25,  4.19s/it]Iteration 736 Predicted energy: -92.44609044864437 Cost value: 54.383869760064655 Grad:  (Array(0.8292083, dtype=float32), Array(-17.929508, dtype=float32))
Training epoch:  74%|███████▎  | 737/1000 [51:51<18:18,  4.18s/it]Iteration 737 Predicted energy: -92.4412522007293 Cost value: 54.455252893652805 Grad:  (Array(25.355785, dtype=float32), Array(-1.2337193, dtype=float32))
Training epoch:  74%|███████▍  | 738/1000 [51:55<18:13,  4.18s/it]Iteration 738 Predicted energy: -92.43556314161309 Cost value: 54.539248720027956 Grad:  (Array(1.4983972, dtype=float32), Array(-32.653492, dtype=float32))
Training epoch:  74%|███████▍  | 739/1000 [51:59<18:09,  4.18s/it]Iteration 739 Predicted energy: -92.42601443298858 Cost value: 54.68037564789875 Grad:  (Array(40.642475, dtype=float32), Array(-1.9271791, dtype=float32))
Training epoch:  74%|███████▍  | 740/1000 [52:03<18:07,  4.18s/it]Iteration 740 Predicted energy: -92.41814639856815 Cost value: 54.79679977206422 Grad:  (Array(2.2479126, dtype=float32), Array(-48.17498, dtype=float32))
Training epoch:  74%|███████▍  | 741/1000 [52:07<18:05,  4.19s/it]Iteration 741 Predicted energy: -92.40332606134241 Cost value: 55.01643409370276 Grad:  (Array(55.628593, dtype=float32), Array(-2.634185, dtype=float32))
Training epoch:  74%|███████▍  | 742/1000 [52:12<18:08,  4.22s/it]Iteration 742 Predicted energy: -92.39964232872461 Cost value: 55.07109441056415 Grad:  (Array(2.9226222, dtype=float32), Array(-60.530907, dtype=float32))
Training epoch:  74%|███████▍  | 743/1000 [52:16<18:09,  4.24s/it]Iteration 743 Predicted energy: -92.38844662484294 Cost value: 55.23738617020874 Grad:  (Array(62.97444, dtype=float32), Array(-3.0478563, dtype=float32))
Training epoch:  74%|███████▍  | 744/1000 [52:20<18:02,  4.23s/it]Iteration 744 Predicted energy: -92.39972123900573 Cost value: 55.06992323195737 Grad:  (Array(3.0313823, dtype=float32), Array(-60.32114, dtype=float32))
Training epoch:  74%|███████▍  | 745/1000 [52:24<17:55,  4.22s/it]Iteration 745 Predicted energy: -92.40500420434296 Cost value: 54.99154230826173 Grad:  (Array(53.81497, dtype=float32), Array(-2.658838, dtype=float32))
Training epoch:  75%|███████▍  | 746/1000 [52:29<17:44,  4.19s/it]Iteration 746 Predicted energy: -92.42330929011084 Cost value: 54.72038996223257 Grad:  (Array(2.263034, dtype=float32), Array(-43.80443, dtype=float32))
Training epoch:  75%|███████▍  | 747/1000 [52:33<17:36,  4.18s/it]Iteration 747 Predicted energy: -92.43509342238531 Cost value: 54.54618675877132 Grad:  (Array(31.304794, dtype=float32), Array(-1.5687295, dtype=float32))
Training epoch:  75%|███████▍  | 748/1000 [52:37<17:29,  4.16s/it]Iteration 748 Predicted energy: -92.44492002571377 Cost value: 54.4011337960814 Grad:  (Array(0.9772015, dtype=float32), Array(-19.389427, dtype=float32))
Training epoch:  75%|███████▍  | 749/1000 [52:41<17:26,  4.17s/it]Iteration 749 Predicted energy: -92.44954257177602 Cost value: 54.332966023148145 Grad:  (Array(6.8212223, dtype=float32), Array(-0.36176425, dtype=float32))
Training epoch:  75%|███████▌  | 750/1000 [52:45<17:26,  4.19s/it]Iteration 750 Predicted energy: -92.45022288652606 Cost value: 54.32293716363743 Grad:  (Array(3.5791311, dtype=float32), Array(-0.24259675, dtype=float32))
Training epoch:  75%|███████▌  | 751/1000 [52:50<17:38,  4.25s/it]Iteration 751 Predicted energy: -92.44788581001944 Cost value: 54.35739304764356 Grad:  (Array(0.6561644, dtype=float32), Array(-13.742875, dtype=float32))
Training epoch:  75%|███████▌  | 752/1000 [52:54<17:31,  4.24s/it]Iteration 752 Predicted energy: -92.44300256906435 Cost value: 54.42942269039364 Grad:  (Array(22.787193, dtype=float32), Array(-1.1269761, dtype=float32))
Training epoch:  75%|███████▌  | 753/1000 [52:58<17:25,  4.23s/it]Iteration 753 Predicted energy: -92.43670193987164 Cost value: 54.5224298087494 Grad:  (Array(1.4682528, dtype=float32), Array(-31.42488, dtype=float32))
Training epoch:  75%|███████▌  | 754/1000 [53:02<17:20,  4.23s/it]Iteration 754 Predicted energy: -92.42659683347823 Cost value: 54.67176272877895 Grad:  (Array(40.148464, dtype=float32), Array(-1.9240421, dtype=float32))
Training epoch:  76%|███████▌  | 755/1000 [53:06<17:11,  4.21s/it]Iteration 755 Predicted energy: -92.41814612583879 Cost value: 54.79680380981495 Grad:  (Array(2.2363725, dtype=float32), Array(-48.142338, dtype=float32))
Training epoch:  76%|███████▌  | 756/1000 [53:11<17:07,  4.21s/it]Iteration 756 Predicted energy: -92.4028800563721 Cost value: 55.023050603656394 Grad:  (Array(55.88253, dtype=float32), Array(-2.6318278, dtype=float32))
Training epoch:  76%|███████▌  | 757/1000 [53:15<16:59,  4.20s/it]Iteration 757 Predicted energy: -92.39887290773827 Cost value: 55.0825147336535 Grad:  (Array(2.8918805, dtype=float32), Array(-60.907677, dtype=float32))
Training epoch:  76%|███████▌  | 758/1000 [53:19<16:58,  4.21s/it]Iteration 758 Predicted energy: -92.38718673601326 Cost value: 55.256115213336216 Grad:  (Array(63.72928, dtype=float32), Array(-3.036837, dtype=float32))
Training epoch:  76%|███████▌  | 759/1000 [53:23<16:52,  4.20s/it]Iteration 759 Predicted energy: -92.39822787930173 Cost value: 55.092089641625634 Grad:  (Array(3.0256248, dtype=float32), Array(-61.23368, dtype=float32))
Training epoch:  76%|███████▌  | 760/1000 [53:27<16:45,  4.19s/it]Iteration 760 Predicted energy: -92.40296798986088 Cost value: 55.021746073694494 Grad:  (Array(55.173313, dtype=float32), Array(-2.6929972, dtype=float32))
Training epoch:  76%|███████▌  | 761/1000 [53:32<16:37,  4.17s/it]Iteration 761 Predicted energy: -92.42166772506377 Cost value: 54.74467903125738 Grad:  (Array(2.3097987, dtype=float32), Array(-45.24376, dtype=float32))
Training epoch:  76%|███████▌  | 762/1000 [53:36<16:36,  4.19s/it]Iteration 762 Predicted energy: -92.43366291361696 Cost value: 54.56731896180854 Grad:  (Array(32.88694, dtype=float32), Array(-1.6460266, dtype=float32))
Training epoch:  76%|███████▋  | 763/1000 [53:40<16:37,  4.21s/it]Iteration 763 Predicted energy: -92.44411024841898 Cost value: 54.413079820732186 Grad:  (Array(1.0545492, dtype=float32), Array(-20.841198, dtype=float32))
Training epoch:  76%|███████▋  | 764/1000 [53:44<16:38,  4.23s/it]Iteration 764 Predicted energy: -92.44918334374806 Cost value: 54.33826195635615 Grad:  (Array(8.108269, dtype=float32), Array(-0.42702308, dtype=float32))
Training epoch:  76%|███████▋  | 765/1000 [53:49<16:31,  4.22s/it]Iteration 765 Predicted energy: -92.45020864377246 Cost value: 54.32314711369514 Grad:  (Array(2.4939775, dtype=float32), Array(-0.2367875, dtype=float32))
Training epoch:  77%|███████▋  | 766/1000 [53:53<16:25,  4.21s/it]Iteration 766 Predicted energy: -92.44810677720788 Cost value: 54.35413482627692 Grad:  (Array(0.61684525, dtype=float32), Array(-12.923111, dtype=float32))
Training epoch:  77%|███████▋  | 767/1000 [53:57<16:22,  4.22s/it]Iteration 767 Predicted energy: -92.44352228706818 Cost value: 54.42175438634889 Grad:  (Array(21.852455, dtype=float32), Array(-1.0907837, dtype=float32))
Training epoch:  77%|███████▋  | 768/1000 [54:01<16:15,  4.21s/it]Iteration 768 Predicted energy: -92.43772632586794 Cost value: 54.507302868087365 Grad:  (Array(1.4340992, dtype=float32), Array(-30.261229, dtype=float32))
Training epoch:  77%|███████▋  | 769/1000 [54:05<16:15,  4.22s/it]Iteration 769 Predicted energy: -92.4288438396694 Cost value: 54.63853889019044 Grad:  (Array(38.213406, dtype=float32), Array(-1.8416286, dtype=float32))
Training epoch:  77%|███████▋  | 770/1000 [54:10<16:06,  4.20s/it]Iteration 770 Predicted energy: -92.4219218836337 Cost value: 54.740918075265995 Grad:  (Array(2.120037, dtype=float32), Array(-45.247643, dtype=float32))
Training epoch:  77%|███████▋  | 771/1000 [54:14<16:03,  4.21s/it]Iteration 771 Predicted energy: -92.40979290447603 Cost value: 54.92054279995737 Grad:  (Array(51.812325, dtype=float32), Array(-2.4405546, dtype=float32))
Training epoch:  77%|███████▋  | 772/1000 [54:18<16:01,  4.22s/it]Iteration 772 Predicted energy: -92.40670462510728 Cost value: 54.966325823186686 Grad:  (Array(2.6593065, dtype=float32), Array(-56.063293, dtype=float32))
Training epoch:  77%|███████▋  | 773/1000 [54:22<15:57,  4.22s/it]Iteration 773 Predicted energy: -92.39723924447188 Cost value: 55.106766714388215 Grad:  (Array(58.795944, dtype=float32), Array(-2.7839994, dtype=float32))
Training epoch:  77%|███████▋  | 774/1000 [54:27<15:57,  4.24s/it]Iteration 774 Predicted energy: -92.40434997152389 Cost value: 55.001245831029706 Grad:  (Array(2.807162, dtype=float32), Array(-57.566616, dtype=float32))
Training epoch:  78%|███████▊  | 775/1000 [54:31<15:54,  4.24s/it]Iteration 775 Predicted energy: -92.40572000501044 Cost value: 54.98092659733335 Grad:  (Array(53.823284, dtype=float32), Array(-2.608285, dtype=float32))
Training epoch:  78%|███████▊  | 776/1000 [54:35<15:48,  4.23s/it]Iteration 776 Predicted energy: -92.41989123969842 Cost value: 54.77097049227017 Grad:  (Array(2.3399727, dtype=float32), Array(-46.75205, dtype=float32))
Training epoch:  78%|███████▊  | 777/1000 [54:39<15:44,  4.24s/it]Iteration 777 Predicted energy: -92.42877930582465 Cost value: 54.63949293543253 Grad:  (Array(37.611137, dtype=float32), Array(-1.8652539, dtype=float32))
Training epoch:  78%|███████▊  | 778/1000 [54:43<15:41,  4.24s/it]Iteration 778 Predicted energy: -92.43935338106219 Cost value: 54.48328072387345 Grad:  (Array(1.4088039, dtype=float32), Array(-27.959875, dtype=float32))
Training epoch:  78%|███████▊  | 779/1000 [54:48<15:34,  4.23s/it]Iteration 779 Predicted energy: -92.4456879728748 Cost value: 54.38980607098758 Grad:  (Array(17.470432, dtype=float32), Array(-0.88626736, dtype=float32))
Training epoch:  78%|███████▊  | 780/1000 [54:52<15:20,  4.19s/it]Iteration 780 Predicted energy: -92.4493987807715 Cost value: 54.33508583666056 Grad:  (Array(0.39830816, dtype=float32), Array(-8.413916, dtype=float32))
Training epoch:  78%|███████▊  | 781/1000 [54:56<15:16,  4.19s/it]Iteration 781 Predicted energy: -92.45047479508116 Cost value: 54.31922388864705 Grad:  (Array(0.02137361, dtype=float32), Array(-0.7163763, dtype=float32))
Training epoch:  78%|███████▊  | 782/1000 [55:00<15:13,  4.19s/it]Iteration 782 Predicted energy: -92.44956239180371 Cost value: 54.33267383312994 Grad:  (Array(8.335053, dtype=float32), Array(-0.4240097, dtype=float32))
Training epoch:  78%|███████▊  | 783/1000 [55:04<15:09,  4.19s/it]Iteration 783 Predicted energy: -92.44718251584253 Cost value: 54.36776396182869 Grad:  (Array(0.74734825, dtype=float32), Array(-15.665886, dtype=float32))
Training epoch:  78%|███████▊  | 784/1000 [55:09<15:05,  4.19s/it]Iteration 784 Predicted energy: -92.44329420607829 Cost value: 54.42511959554767 Grad:  (Array(22.44613, dtype=float32), Array(-1.0880016, dtype=float32))
Training epoch:  78%|███████▊  | 785/1000 [55:13<14:59,  4.18s/it]Iteration 785 Predicted energy: -92.4388114334811 Cost value: 54.49128155025629 Grad:  (Array(1.3556776, dtype=float32), Array(-28.949783, dtype=float32))
Training epoch:  79%|███████▊  | 786/1000 [55:17<14:56,  4.19s/it]Iteration 786 Predicted energy: -92.4317359685829 Cost value: 54.59579124346335 Grad:  (Array(35.690876, dtype=float32), Array(-1.6868039, dtype=float32))
Training epoch:  79%|███████▊  | 787/1000 [55:21<14:52,  4.19s/it]Iteration 787 Predicted energy: -92.42581592316627 Cost value: 54.68331149592295 Grad:  (Array(1.963722, dtype=float32), Array(-42.026024, dtype=float32))
Training epoch:  79%|███████▉  | 788/1000 [55:25<14:46,  4.18s/it]Iteration 788 Predicted energy: -92.41494054570033 Cost value: 54.844272611844 Grad:  (Array(48.61239, dtype=float32), Array(-2.2869506, dtype=float32))
Training epoch:  79%|███████▉  | 789/1000 [55:30<14:48,  4.21s/it]Iteration 789 Predicted energy: -92.41031540920484 Cost value: 54.91279867555249 Grad:  (Array(2.5509472, dtype=float32), Array(-53.74266, dtype=float32))
Training epoch:  79%|███████▉  | 790/1000 [55:34<14:46,  4.22s/it]Iteration 790 Predicted energy: -92.39902341248559 Cost value: 55.080280736215336 Grad:  (Array(57.805088, dtype=float32), Array(-2.7679834, dtype=float32))
Training epoch:  79%|███████▉  | 791/1000 [55:38<14:44,  4.23s/it]Iteration 791 Predicted energy: -92.40297390746196 Cost value: 55.02165828417116 Grad:  (Array(2.858619, dtype=float32), Array(-58.403885, dtype=float32))
Training epoch:  79%|███████▉  | 792/1000 [55:42<14:37,  4.22s/it]Iteration 792 Predicted energy: -92.40115682917282 Cost value: 55.04861851853988 Grad:  (Array(56.226402, dtype=float32), Array(-2.7520797, dtype=float32))
Training epoch:  79%|███████▉  | 793/1000 [55:46<14:32,  4.21s/it]Iteration 793 Predicted energy: -92.41507510813571 Cost value: 54.84227957407389 Grad:  (Array(2.546632, dtype=float32), Array(-50.191338, dtype=float32))
Training epoch:  79%|███████▉  | 794/1000 [55:51<14:28,  4.22s/it]Iteration 794 Predicted energy: -92.42380825155188 Cost value: 54.71300825314566 Grad:  (Array(41.377327, dtype=float32), Array(-2.055443, dtype=float32))
Training epoch:  80%|███████▉  | 795/1000 [55:55<14:23,  4.21s/it]Iteration 795 Predicted energy: -92.43630686194355 Cost value: 54.5282644207718 Grad:  (Array(1.609929, dtype=float32), Array(-31.497154, dtype=float32))
Training epoch:  80%|███████▉  | 796/1000 [55:59<14:20,  4.22s/it]Iteration 796 Predicted energy: -92.44402159280436 Cost value: 54.41438776881142 Grad:  (Array(20.213665, dtype=float32), Array(-1.0149795, dtype=float32))
Training epoch:  80%|███████▉  | 797/1000 [56:03<14:17,  4.22s/it]Iteration 797 Predicted energy: -92.44887293351596 Cost value: 54.34283839916795 Grad:  (Array(0.5138227, dtype=float32), Array(-10.430922, dtype=float32))
Training epoch:  80%|███████▉  | 798/1000 [56:08<14:14,  4.23s/it]Iteration 798 Predicted energy: -92.45050669963722 Cost value: 54.31875360644878 Grad:  (Array(0.5213375, dtype=float32), Array(-0.13043952, dtype=float32))
Training epoch:  80%|███████▉  | 799/1000 [56:12<14:05,  4.21s/it]Iteration 799 Predicted energy: -92.44971642053922 Cost value: 54.33040314365334 Grad:  (Array(7.8104753, dtype=float32), Array(-0.3986534, dtype=float32))
Training epoch:  80%|████████  | 800/1000 [56:16<14:05,  4.23s/it]Iteration 800 Predicted energy: -92.44710917576353 Cost value: 54.36884550600909 Grad:  (Array(0.7368385, dtype=float32), Array(-15.772375, dtype=float32))
Training epoch:  80%|████████  | 801/1000 [56:20<14:00,  4.23s/it]Iteration 801 Predicted energy: -92.44262459640622 Cost value: 54.4349999180121 Grad:  (Array(23.42762, dtype=float32), Array(-1.1440086, dtype=float32))
Training epoch:  80%|████████  | 802/1000 [56:24<13:55,  4.22s/it]Iteration 802 Predicted energy: -92.43713443075812 Cost value: 54.5160430304919 Grad:  (Array(1.413628, dtype=float32), Array(-30.857498, dtype=float32))
Training epoch:  80%|████████  | 803/1000 [56:29<13:45,  4.19s/it]Iteration 803 Predicted energy: -92.42812622646998 Cost value: 54.64914829531018 Grad:  (Array(38.87347, dtype=float32), Array(-1.8405819, dtype=float32))
Training epoch:  80%|████████  | 804/1000 [56:33<13:40,  4.19s/it]Iteration 804 Predicted energy: -92.4203288375936 Cost value: 54.764493586207415 Grad:  (Array(2.1506364, dtype=float32), Array(-46.430016, dtype=float32))
Training epoch:  80%|████████  | 805/1000 [56:37<13:40,  4.21s/it]Iteration 805 Predicted energy: -92.40598825517844 Cost value: 54.97694856627217 Grad:  (Array(54.076664, dtype=float32), Array(-2.548082, dtype=float32))
Training epoch:  81%|████████  | 806/1000 [56:41<13:36,  4.21s/it]Iteration 806 Predicted energy: -92.40136616857568 Cost value: 55.04551218517004 Grad:  (Array(2.8420968, dtype=float32), Array(-59.405735, dtype=float32))
Training epoch:  81%|████████  | 807/1000 [56:45<13:29,  4.20s/it]Iteration 807 Predicted energy: -92.38924918035798 Cost value: 55.22545733085528 Grad:  (Array(62.602028, dtype=float32), Array(-3.0097172, dtype=float32))
Training epoch:  81%|████████  | 808/1000 [56:49<13:21,  4.17s/it]Iteration 808 Predicted energy: -92.39882564794327 Cost value: 55.083216237556144 Grad:  (Array(3.0349681, dtype=float32), Array(-60.810978, dtype=float32))
Training epoch:  81%|████████  | 809/1000 [56:54<13:23,  4.21s/it]Iteration 809 Predicted energy: -92.40245985269544 Cost value: 55.02928471388588 Grad:  (Array(55.2301, dtype=float32), Array(-2.7221155, dtype=float32))
Training epoch:  81%|████████  | 810/1000 [56:58<13:16,  4.19s/it]Iteration 810 Predicted energy: -92.42078228991745 Cost value: 54.75778242208403 Grad:  (Array(2.361879, dtype=float32), Array(-45.78396, dtype=float32))
Training epoch:  81%|████████  | 811/1000 [57:02<13:18,  4.23s/it]Iteration 811 Predicted energy: -92.43268226984664 Cost value: 54.581807894789556 Grad:  (Array(33.639248, dtype=float32), Array(-1.684294, dtype=float32))
Training epoch:  81%|████████  | 812/1000 [57:06<13:14,  4.23s/it]Iteration 812 Predicted energy: -92.44351208126898 Cost value: 54.42190496506308 Grad:  (Array(1.1019441, dtype=float32), Array(-21.760157, dtype=float32))
Training epoch:  81%|████████▏ | 813/1000 [57:11<13:11,  4.23s/it]Iteration 813 Predicted energy: -92.44895727852169 Cost value: 54.34159486408435 Grad:  (Array(9.031207, dtype=float32), Array(-0.4724444, dtype=float32))
Training epoch:  81%|████████▏ | 814/1000 [57:15<13:04,  4.22s/it]Iteration 814 Predicted energy: -92.45034162527858 Cost value: 54.32118687126159 Grad:  (Array(1.5207891, dtype=float32), Array(-0.1926251, dtype=float32))
Training epoch:  82%|████████▏ | 815/1000 [57:19<13:04,  4.24s/it]Iteration 815 Predicted energy: -92.44852890274491 Cost value: 54.347910741747384 Grad:  (Array(0.56841266, dtype=float32), Array(-11.895611, dtype=float32))
Training epoch:  82%|████████▏ | 816/1000 [57:23<12:58,  4.23s/it]Iteration 816 Predicted energy: -92.4441338986199 Cost value: 54.412730908827164 Grad:  (Array(20.980383, dtype=float32), Array(-1.0406799, dtype=float32))
Training epoch:  82%|████████▏ | 817/1000 [57:28<12:52,  4.22s/it]Iteration 817 Predicted energy: -92.43818695270411 Cost value: 54.500501550883115 Grad:  (Array(1.3842753, dtype=float32), Array(-29.640217, dtype=float32))
Training epoch:  82%|████████▏ | 818/1000 [57:32<12:46,  4.21s/it]Iteration 818 Predicted energy: -92.4287513448321 Cost value: 54.63990630331591 Grad:  (Array(38.305107, dtype=float32), Array(-1.834747, dtype=float32))
Training epoch:  82%|████████▏ | 819/1000 [57:36<12:42,  4.21s/it]Iteration 819 Predicted energy: -92.42051018109156 Cost value: 54.7618096252061 Grad:  (Array(2.14238, dtype=float32), Array(-46.27841, dtype=float32))
Training epoch:  82%|████████▏ | 820/1000 [57:40<12:34,  4.19s/it]Iteration 820 Predicted energy: -92.40592025469999 Cost value: 54.97795696960208 Grad:  (Array(54.115353, dtype=float32), Array(-2.5403898, dtype=float32))
Training epoch:  82%|████████▏ | 821/1000 [57:44<12:32,  4.20s/it]Iteration 821 Predicted energy: -92.401117711775 Cost value: 55.04919898122915 Grad:  (Array(2.8076053, dtype=float32), Array(-59.485054, dtype=float32))
Training epoch:  82%|████████▏ | 822/1000 [57:49<12:27,  4.20s/it]Iteration 822 Predicted energy: -92.38879007029261 Cost value: 55.23228118735656 Grad:  (Array(62.93637, dtype=float32), Array(-2.9861624, dtype=float32))
Training epoch:  82%|████████▏ | 823/1000 [57:53<12:25,  4.21s/it]Iteration 823 Predicted energy: -92.39795646248301 Cost value: 55.096118846165496 Grad:  (Array(3.0153692, dtype=float32), Array(-61.331905, dtype=float32))
Training epoch:  82%|████████▏ | 824/1000 [57:57<12:21,  4.21s/it]Iteration 824 Predicted energy: -92.40091187716797 Cost value: 55.052253409398865 Grad:  (Array(56.27754, dtype=float32), Array(-2.7408178, dtype=float32))
Training epoch:  82%|████████▎ | 825/1000 [58:01<12:19,  4.22s/it]Iteration 825 Predicted energy: -92.41922389219351 Cost value: 54.78084866998784 Grad:  (Array(2.398624, dtype=float32), Array(-47.100468, dtype=float32))
Training epoch:  83%|████████▎ | 826/1000 [58:05<12:12,  4.21s/it]Iteration 826 Predicted energy: -92.43103077209776 Cost value: 54.60621298842389 Grad:  (Array(35.32435, dtype=float32), Array(-1.7642, dtype=float32))
Training epoch:  83%|████████▎ | 827/1000 [58:10<12:05,  4.20s/it]Iteration 827 Predicted energy: -92.44241248048272 Cost value: 54.43812994890509 Grad:  (Array(1.1941758, dtype=float32), Array(-23.516193, dtype=float32))
Training epoch:  83%|████████▎ | 828/1000 [58:14<12:03,  4.21s/it]Iteration 828 Predicted energy: -92.44836736914229 Cost value: 54.35029245273093 Grad:  (Array(10.856426, dtype=float32), Array(-0.5648641, dtype=float32))
Training epoch:  83%|████████▎ | 829/1000 [58:18<12:00,  4.21s/it]Iteration 829 Predicted energy: -92.45029588651177 Cost value: 54.32186108938059 Grad:  (Array(0.06737655, dtype=float32), Array(-0.27641582, dtype=float32))
Training epoch:  83%|████████▎ | 830/1000 [58:22<11:53,  4.20s/it]Iteration 830 Predicted energy: -92.44897432369052 Cost value: 54.34134356147907 Grad:  (Array(0.4860736, dtype=float32), Array(-10.223168, dtype=float32))
Training epoch:  83%|████████▎ | 831/1000 [58:26<11:48,  4.19s/it]Iteration 831 Predicted energy: -92.44513883627272 Cost value: 54.39790607644217 Grad:  (Array(19.15545, dtype=float32), Array(-0.9586216, dtype=float32))
Training epoch:  83%|████████▎ | 832/1000 [58:31<11:43,  4.19s/it]Iteration 832 Predicted energy: -92.43983833980543 Cost value: 54.47612172741484 Grad:  (Array(1.3062185, dtype=float32), Array(-27.618618, dtype=float32))
Training epoch:  83%|████████▎ | 833/1000 [58:35<11:39,  4.19s/it]Iteration 833 Predicted energy: -92.43171536612032 Cost value: 54.59609570281449 Grad:  (Array(35.63343, dtype=float32), Array(-1.7154967, dtype=float32))
Training epoch:  83%|████████▎ | 834/1000 [58:39<11:33,  4.18s/it]Iteration 834 Predicted energy: -92.42475170428634 Cost value: 54.699052035212134 Grad:  (Array(2.0001984, dtype=float32), Array(-42.87936, dtype=float32))
Training epoch:  84%|████████▎ | 835/1000 [58:43<11:27,  4.16s/it]Iteration 835 Predicted energy: -92.41286356566704 Cost value: 54.87503987413451 Grad:  (Array(49.86621, dtype=float32), Array(-2.3427153, dtype=float32))
Training epoch:  84%|████████▎ | 836/1000 [58:47<11:27,  4.19s/it]Iteration 836 Predicted energy: -92.40844201269785 Cost value: 54.94056710929455 Grad:  (Array(2.5858748, dtype=float32), Array(-54.865356, dtype=float32))
Training epoch:  84%|████████▎ | 837/1000 [58:52<11:25,  4.20s/it]Iteration 837 Predicted energy: -92.39756919963379 Cost value: 55.10186804944307 Grad:  (Array(58.603153, dtype=float32), Array(-2.763439, dtype=float32))
Training epoch:  84%|████████▍ | 838/1000 [58:56<11:22,  4.21s/it]Iteration 838 Predicted energy: -92.40276469801952 Cost value: 55.02476201635628 Grad:  (Array(2.8357575, dtype=float32), Array(-58.48459, dtype=float32))
Training epoch:  84%|████████▍ | 839/1000 [59:00<11:19,  4.22s/it]Iteration 839 Predicted energy: -92.4020890494297 Cost value: 55.034786216632256 Grad:  (Array(55.81693, dtype=float32), Array(-2.6992695, dtype=float32))
Training epoch:  84%|████████▍ | 840/1000 [59:04<11:16,  4.23s/it]Iteration 840 Predicted energy: -92.41627054323081 Cost value: 54.82457527684359 Grad:  (Array(2.4721808, dtype=float32), Array(-49.376534, dtype=float32))
Training epoch:  84%|████████▍ | 841/1000 [59:08<11:12,  4.23s/it]Iteration 841 Predicted energy: -92.42505086225029 Cost value: 54.69462705145536 Grad:  (Array(40.56812, dtype=float32), Array(-2.007642, dtype=float32))
Training epoch:  84%|████████▍ | 842/1000 [59:13<11:07,  4.22s/it]Iteration 842 Predicted energy: -92.43694514374114 Cost value: 54.51883826695213 Grad:  (Array(1.5578907, dtype=float32), Array(-30.80453, dtype=float32))
Training epoch:  84%|████████▍ | 843/1000 [59:17<11:03,  4.23s/it]Iteration 843 Predicted energy: -92.44422010745619 Cost value: 54.4114590775467 Grad:  (Array(19.916092, dtype=float32), Array(-1.0100124, dtype=float32))
Training epoch:  84%|████████▍ | 844/1000 [59:21<10:59,  4.23s/it]Iteration 844 Predicted energy: -92.44882335992611 Cost value: 54.34356929079116 Grad:  (Array(0.5035168, dtype=float32), Array(-10.425944, dtype=float32))
Training epoch:  84%|████████▍ | 845/1000 [59:25<10:53,  4.21s/it]Iteration 845 Predicted energy: -92.45043046334176 Cost value: 54.31987735442957 Grad:  (Array(0.7475796, dtype=float32), Array(-0.1542269, dtype=float32))
Training epoch:  85%|████████▍ | 846/1000 [59:30<10:51,  4.23s/it]Iteration 846 Predicted energy: -92.44977322968802 Cost value: 54.32956567594934 Grad:  (Array(7.2938213, dtype=float32), Array(-0.37422934, dtype=float32))
Training epoch:  85%|████████▍ | 847/1000 [59:34<10:53,  4.27s/it]Iteration 847 Predicted energy: -92.44743146610978 Cost value: 54.3640927791406 Grad:  (Array(0.7155249, dtype=float32), Array(-15.043229, dtype=float32))
Training epoch:  85%|████████▍ | 848/1000 [59:38<10:45,  4.25s/it]Iteration 848 Predicted energy: -92.44345784641405 Cost value: 54.4227051621107 Grad:  (Array(22.161568, dtype=float32), Array(-1.0753546, dtype=float32))
Training epoch:  85%|████████▍ | 849/1000 [59:42<10:38,  4.23s/it]Iteration 849 Predicted energy: -92.43875800667149 Cost value: 54.492070327403056 Grad:  (Array(1.3497351, dtype=float32), Array(-28.967041, dtype=float32))
Training epoch:  85%|████████▌ | 850/1000 [59:47<10:36,  4.24s/it]Iteration 850 Predicted energy: -92.43135801463235 Cost value: 54.601376711544766 Grad:  (Array(35.999878, dtype=float32), Array(-1.6997212, dtype=float32))
Training epoch:  85%|████████▌ | 851/1000 [59:51<10:30,  4.23s/it]Iteration 851 Predicted energy: -92.42510818315688 Cost value: 54.69377921185805 Grad:  (Array(1.9771129, dtype=float32), Array(-42.556396, dtype=float32))
Training epoch:  85%|████████▌ | 852/1000 [59:55<10:28,  4.24s/it]Iteration 852 Predicted energy: -92.41375459090752 Cost value: 54.861839649953694 Grad:  (Array(49.336098, dtype=float32), Array(-2.3118658, dtype=float32))
Training epoch:  85%|████████▌ | 853/1000 [59:59<10:23,  4.24s/it]Iteration 853 Predicted energy: -92.40909016471025 Cost value: 54.93095907709642 Grad:  (Array(2.577401, dtype=float32), Array(-54.472088, dtype=float32))
Training epoch:  85%|████████▌ | 854/1000 [1:00:04<10:18,  4.24s/it]Iteration 854 Predicted energy: -92.39772612553863 Cost value: 55.09953833223378 Grad:  (Array(58.417717, dtype=float32), Array(-2.7907524, dtype=float32))
Training epoch:  86%|████████▌ | 855/1000 [1:00:08<10:12,  4.22s/it]Iteration 855 Predicted energy: -92.40245893564003 Cost value: 55.02929831963745 Grad:  (Array(2.8725514, dtype=float32), Array(-58.632416, dtype=float32))
Training epoch:  86%|████████▌ | 856/1000 [1:00:12<10:06,  4.21s/it]Iteration 856 Predicted energy: -92.40150084397932 Cost value: 55.04351381794458 Grad:  (Array(55.936592, dtype=float32), Array(-2.7363796, dtype=float32))
Training epoch:  86%|████████▌ | 857/1000 [1:00:16<10:04,  4.23s/it]Iteration 857 Predicted energy: -92.41612137710888 Cost value: 54.82678425899672 Grad:  (Array(2.5091877, dtype=float32), Array(-49.352173, dtype=float32))
Training epoch:  86%|████████▌ | 858/1000 [1:00:20<09:57,  4.20s/it]Iteration 858 Predicted energy: -92.42546748350672 Cost value: 54.68846491204062 Grad:  (Array(39.97884, dtype=float32), Array(-1.9905417, dtype=float32))
Training epoch:  86%|████████▌ | 859/1000 [1:00:25<09:49,  4.18s/it]Iteration 859 Predicted energy: -92.43772487236366 Cost value: 54.50732433026082 Grad:  (Array(1.5216722, dtype=float32), Array(-29.787544, dtype=float32))
Training epoch:  86%|████████▌ | 860/1000 [1:00:29<09:46,  4.19s/it]Iteration 860 Predicted energy: -92.44513632582671 Cost value: 54.3979431080055 Grad:  (Array(18.253265, dtype=float32), Array(-0.91931814, dtype=float32))
Training epoch:  86%|████████▌ | 861/1000 [1:00:33<09:39,  4.17s/it]Iteration 861 Predicted energy: -92.44940878587477 Cost value: 54.334938336852545 Grad:  (Array(0.40645865, dtype=float32), Array(-8.371611, dtype=float32))
Training epoch:  86%|████████▌ | 862/1000 [1:00:37<09:36,  4.17s/it]Iteration 862 Predicted energy: -92.4504839067783 Cost value: 54.319089579441204 Grad:  (Array(0.06977067, dtype=float32), Array(-1.5945492, dtype=float32))
Training epoch:  86%|████████▋ | 863/1000 [1:00:41<09:32,  4.18s/it]Iteration 863 Predicted energy: -92.44914381392469 Cost value: 54.3388447420812 Grad:  (Array(10.007286, dtype=float32), Array(-0.5047679, dtype=float32))
Training epoch:  86%|████████▋ | 864/1000 [1:00:45<09:28,  4.18s/it]Iteration 864 Predicted energy: -92.44600319945073 Cost value: 54.385156613363606 Grad:  (Array(0.8410644, dtype=float32), Array(-18.039392, dtype=float32))
Training epoch:  86%|████████▋ | 865/1000 [1:00:50<09:25,  4.19s/it]Iteration 865 Predicted energy: -92.44081224926319 Cost value: 54.461746225531144 Grad:  (Array(25.856731, dtype=float32), Array(-1.2539014, dtype=float32))
Training epoch:  87%|████████▋ | 866/1000 [1:00:54<09:21,  4.19s/it]Iteration 866 Predicted energy: -92.43476909868451 Cost value: 54.55097747465812 Grad:  (Array(1.5294471, dtype=float32), Array(-33.420975, dtype=float32))
Training epoch:  87%|████████▋ | 867/1000 [1:00:58<09:15,  4.18s/it]Iteration 867 Predicted energy: -92.42477030282474 Cost value: 54.69877693041381 Grad:  (Array(41.55335, dtype=float32), Array(-1.9548935, dtype=float32))
Training epoch:  87%|████████▋ | 868/1000 [1:01:02<09:11,  4.18s/it]Iteration 868 Predicted energy: -92.41690567746849 Cost value: 54.815170152726104 Grad:  (Array(2.2667701, dtype=float32), Array(-48.955284, dtype=float32))
Training epoch:  87%|████████▋ | 869/1000 [1:01:06<09:05,  4.17s/it]Iteration 869 Predicted energy: -92.40219864252829 Cost value: 55.03316018632593 Grad:  (Array(56.15286, dtype=float32), Array(-2.6401575, dtype=float32))
Training epoch:  87%|████████▋ | 870/1000 [1:01:10<09:00,  4.16s/it]Iteration 870 Predicted energy: -92.39944367000511 Cost value: 55.07404293882005 Grad:  (Array(2.9013884, dtype=float32), Array(-60.470226, dtype=float32))
Training epoch:  87%|████████▋ | 871/1000 [1:01:15<09:03,  4.22s/it]Iteration 871 Predicted energy: -92.38959567181402 Cost value: 55.22030762929117 Grad:  (Array(62.286373, dtype=float32), Array(-3.0002377, dtype=float32))
Training epoch:  87%|████████▋ | 872/1000 [1:01:19<08:59,  4.22s/it]Iteration 872 Predicted energy: -92.40176066073676 Cost value: 55.03965865601454 Grad:  (Array(2.956377, dtype=float32), Array(-58.93758, dtype=float32))
Training epoch:  87%|████████▋ | 873/1000 [1:01:23<08:54,  4.21s/it]Iteration 873 Predicted energy: -92.40812388085958 Cost value: 54.94528331804258 Grad:  (Array(51.852, dtype=float32), Array(-2.5606637, dtype=float32))
Training epoch:  87%|████████▋ | 874/1000 [1:01:27<08:47,  4.19s/it]Iteration 874 Predicted energy: -92.42579107106847 Cost value: 54.683679049947685 Grad:  (Array(2.148955, dtype=float32), Array(-41.610737, dtype=float32))
Training epoch:  88%|████████▊ | 875/1000 [1:01:31<08:43,  4.19s/it]Iteration 875 Predicted energy: -92.43710354541678 Cost value: 54.516499115159235 Grad:  (Array(29.024635, dtype=float32), Array(-1.4609911, dtype=float32))
Training epoch:  88%|████████▊ | 876/1000 [1:01:36<08:39,  4.19s/it]Iteration 876 Predicted energy: -92.4459564951039 Cost value: 54.3858454700296 Grad:  (Array(0.86619437, dtype=float32), Array(-17.327972, dtype=float32))
Training epoch:  88%|████████▊ | 877/1000 [1:01:40<08:35,  4.19s/it]Iteration 877 Predicted energy: -92.44986997156902 Cost value: 54.32813954373689 Grad:  (Array(4.9958363, dtype=float32), Array(-0.2998166, dtype=float32))
Training epoch:  88%|████████▊ | 878/1000 [1:01:44<08:33,  4.21s/it]Iteration 878 Predicted energy: -92.45002117105884 Cost value: 54.325910655544895 Grad:  (Array(5.16415, dtype=float32), Array(-0.2933529, dtype=float32))
Training epoch:  88%|████████▊ | 879/1000 [1:01:48<08:25,  4.18s/it]Iteration 879 Predicted energy: -92.44733548717342 Cost value: 54.36550813232892 Grad:  (Array(0.7195249, dtype=float32), Array(-15.0634365, dtype=float32))
Training epoch:  88%|████████▊ | 880/1000 [1:01:52<08:21,  4.18s/it]Iteration 880 Predicted energy: -92.44215887690477 Cost value: 54.44187229918719 Grad:  (Array(23.953602, dtype=float32), Array(-1.1763521, dtype=float32))
Training epoch:  88%|████████▊ | 881/1000 [1:01:57<08:17,  4.18s/it]Iteration 881 Predicted energy: -92.43573501118215 Cost value: 54.5367102122074 Grad:  (Array(1.5018063, dtype=float32), Array(-32.398743, dtype=float32))
Training epoch:  88%|████████▊ | 882/1000 [1:02:01<08:12,  4.18s/it]Iteration 882 Predicted energy: -92.42546661773912 Cost value: 54.688477717029876 Grad:  (Array(40.952904, dtype=float32), Array(-1.9454557, dtype=float32))
Training epoch:  88%|████████▊ | 883/1000 [1:02:05<08:08,  4.18s/it]Iteration 883 Predicted energy: -92.41731013866968 Cost value: 54.809181275865974 Grad:  (Array(2.2476494, dtype=float32), Array(-48.62832, dtype=float32))
Training epoch:  88%|████████▊ | 884/1000 [1:02:09<08:07,  4.20s/it]Iteration 884 Predicted energy: -92.40252732619919 Cost value: 55.028283658245186 Grad:  (Array(55.989426, dtype=float32), Array(-2.6170154, dtype=float32))
Training epoch:  88%|████████▊ | 885/1000 [1:02:13<08:02,  4.20s/it]Iteration 885 Predicted energy: -92.39947906152358 Cost value: 55.07351764579297 Grad:  (Array(2.8603022, dtype=float32), Array(-60.4027, dtype=float32))
Training epoch:  89%|████████▊ | 886/1000 [1:02:18<07:58,  4.20s/it]Iteration 886 Predicted energy: -92.38925582774719 Cost value: 55.225358532305464 Grad:  (Array(62.57325, dtype=float32), Array(-2.9767532, dtype=float32))
Training epoch:  89%|████████▊ | 887/1000 [1:02:22<07:54,  4.20s/it]Iteration 887 Predicted energy: -92.400779037802 Cost value: 55.05422468899892 Grad:  (Array(2.948301, dtype=float32), Array(-59.555, dtype=float32))
Training epoch:  89%|████████▉ | 888/1000 [1:02:26<07:50,  4.20s/it]Iteration 888 Predicted energy: -92.4062942770426 Cost value: 54.9724105734431 Grad:  (Array(53.097748, dtype=float32), Array(-2.5979958, dtype=float32))
Training epoch:  89%|████████▉ | 889/1000 [1:02:30<07:47,  4.21s/it]Iteration 889 Predicted energy: -92.42400416394759 Cost value: 54.71011003242778 Grad:  (Array(2.2079659, dtype=float32), Array(-43.216476, dtype=float32))
Training epoch:  89%|████████▉ | 890/1000 [1:02:34<07:43,  4.21s/it]Iteration 890 Predicted energy: -92.43534195812525 Cost value: 54.542515679726115 Grad:  (Array(31.039898, dtype=float32), Array(-1.5585092, dtype=float32))
Training epoch:  89%|████████▉ | 891/1000 [1:02:39<07:41,  4.23s/it]Iteration 891 Predicted energy: -92.44485945036024 Cost value: 54.4020273725263 Grad:  (Array(0.9775572, dtype=float32), Array(-19.433353, dtype=float32))
Training epoch:  89%|████████▉ | 892/1000 [1:02:43<07:38,  4.24s/it]Iteration 892 Predicted energy: -92.44940690807628 Cost value: 54.33496602020129 Grad:  (Array(7.1543827, dtype=float32), Array(-0.3795766, dtype=float32))
Training epoch:  89%|████████▉ | 893/1000 [1:02:47<07:34,  4.25s/it]Iteration 893 Predicted energy: -92.45020671677551 Cost value: 54.32317551926717 Grad:  (Array(2.9801664, dtype=float32), Array(-0.24751478, dtype=float32))
Training epoch:  89%|████████▉ | 894/1000 [1:02:51<07:29,  4.24s/it]Iteration 894 Predicted energy: -92.44812562847359 Cost value: 54.353856863751425 Grad:  (Array(0.6192434, dtype=float32), Array(-12.945254, dtype=float32))
Training epoch:  90%|████████▉ | 895/1000 [1:02:56<07:25,  4.24s/it]Iteration 895 Predicted energy: -92.44369016638915 Cost value: 54.41927748604193 Grad:  (Array(21.605131, dtype=float32), Array(-1.0692486, dtype=float32))
Training epoch:  90%|████████▉ | 896/1000 [1:03:00<07:21,  4.24s/it]Iteration 896 Predicted energy: -92.43804470926614 Cost value: 54.50260177997333 Grad:  (Array(1.3969462, dtype=float32), Array(-29.7938, dtype=float32))
Training epoch:  90%|████████▉ | 897/1000 [1:03:04<07:18,  4.26s/it]Iteration 897 Predicted energy: -92.42932517349846 Cost value: 54.63142328603993 Grad:  (Array(37.735233, dtype=float32), Array(-1.7994976, dtype=float32))
Training epoch:  90%|████████▉ | 898/1000 [1:03:08<07:13,  4.25s/it]Iteration 898 Predicted energy: -92.42227868197448 Cost value: 54.73563850726168 Grad:  (Array(2.081613, dtype=float32), Array(-44.830143, dtype=float32))
Training epoch:  90%|████████▉ | 899/1000 [1:03:13<07:09,  4.25s/it]Iteration 899 Predicted energy: -92.40990856210938 Cost value: 54.918828573007715 Grad:  (Array(51.676083, dtype=float32), Array(-2.4139633, dtype=float32))
Training epoch:  90%|█████████ | 900/1000 [1:03:17<07:06,  4.26s/it]Iteration 900 Predicted energy: -92.40619444183768 Cost value: 54.97389100735228 Grad:  (Array(2.6515648, dtype=float32), Array(-56.25397, dtype=float32))
Training epoch:  90%|█████████ | 901/1000 [1:03:21<07:00,  4.24s/it]Iteration 901 Predicted energy: -92.39593186427345 Cost value: 55.12617881820065 Grad:  (Array(59.347103, dtype=float32), Array(-2.8039837, dtype=float32))
Training epoch:  90%|█████████ | 902/1000 [1:03:25<06:55,  4.24s/it]Iteration 902 Predicted energy: -92.40294618653766 Cost value: 55.02206953364151 Grad:  (Array(2.8395672, dtype=float32), Array(-58.281143, dtype=float32))
Training epoch:  90%|█████████ | 903/1000 [1:03:30<06:49,  4.22s/it]Iteration 903 Predicted energy: -92.4042536681439 Cost value: 55.00267426644373 Grad:  (Array(54.444904, dtype=float32), Array(-2.6451197, dtype=float32))
Training epoch:  90%|█████████ | 904/1000 [1:03:34<06:44,  4.22s/it]Iteration 904 Predicted energy: -92.41927788209252 Cost value: 54.78004947030152 Grad:  (Array(2.3711948, dtype=float32), Array(-47.024162, dtype=float32))
Training epoch:  90%|█████████ | 905/1000 [1:03:38<06:39,  4.20s/it]Iteration 905 Predicted energy: -92.42885693982437 Cost value: 54.63834522320935 Grad:  (Array(37.285114, dtype=float32), Array(-1.8541592, dtype=float32))
Training epoch:  91%|█████████ | 906/1000 [1:03:42<06:33,  4.19s/it]Iteration 906 Predicted energy: -92.43986600704665 Cost value: 54.47571331575823 Grad:  (Array(1.3698989, dtype=float32), Array(-27.128185, dtype=float32))
Training epoch:  91%|█████████ | 907/1000 [1:03:46<06:30,  4.20s/it]Iteration 907 Predicted energy: -92.44634062093128 Cost value: 54.380180010574996 Grad:  (Array(15.9547615, dtype=float32), Array(-0.81479186, dtype=float32))
Training epoch:  91%|█████████ | 908/1000 [1:03:51<06:28,  4.22s/it]Iteration 908 Predicted energy: -92.44978052050911 Cost value: 54.32945819677078 Grad:  (Array(0.30444047, dtype=float32), Array(-6.477229, dtype=float32))
Training epoch:  91%|█████████ | 909/1000 [1:03:55<06:22,  4.20s/it]Iteration 909 Predicted energy: -92.45036148237274 Cost value: 54.32089416653804 Grad:  (Array(0.14189394, dtype=float32), Array(-3.0777225, dtype=float32))
Training epoch:  91%|█████████ | 910/1000 [1:03:59<06:18,  4.20s/it]Iteration 910 Predicted energy: -92.44877386280523 Cost value: 54.344299059892656 Grad:  (Array(11.117965, dtype=float32), Array(-0.55797917, dtype=float32))
Training epoch:  91%|█████████ | 911/1000 [1:04:03<06:14,  4.21s/it]Iteration 911 Predicted energy: -92.44561176148584 Cost value: 54.390930186320254 Grad:  (Array(0.88672537, dtype=float32), Array(-18.812214, dtype=float32))
Training epoch:  91%|█████████ | 912/1000 [1:04:07<06:10,  4.21s/it]Iteration 912 Predicted energy: -92.4405908956617 Cost value: 54.465013374089025 Grad:  (Array(26.113838, dtype=float32), Array(-1.2561972, dtype=float32))
Training epoch:  91%|█████████▏| 913/1000 [1:04:12<06:06,  4.21s/it]Iteration 913 Predicted energy: -92.43510173221061 Cost value: 54.54606401376214 Grad:  (Array(1.5290601, dtype=float32), Array(-33.07728, dtype=float32))
Training epoch:  91%|█████████▏| 914/1000 [1:04:16<06:02,  4.22s/it]Iteration 914 Predicted energy: -92.42620035908334 Cost value: 54.67762597756624 Grad:  (Array(40.375847, dtype=float32), Array(-1.8921074, dtype=float32))
Training epoch:  92%|█████████▏| 915/1000 [1:04:20<05:55,  4.18s/it]Iteration 915 Predicted energy: -92.41959826108805 Cost value: 54.775307095858714 Grad:  (Array(2.176471, dtype=float32), Array(-46.912117, dtype=float32))
Training epoch:  92%|█████████▏| 916/1000 [1:04:24<05:52,  4.19s/it]Iteration 916 Predicted energy: -92.40709148609899 Cost value: 54.96058965390491 Grad:  (Array(53.35492, dtype=float32), Array(-2.4990888, dtype=float32))
Training epoch:  92%|█████████▏| 917/1000 [1:04:28<05:49,  4.21s/it]Iteration 917 Predicted energy: -92.40446294695234 Cost value: 54.999570128411655 Grad:  (Array(2.7313828, dtype=float32), Array(-57.365395, dtype=float32))
Training epoch:  92%|█████████▏| 918/1000 [1:04:33<05:44,  4.21s/it]Iteration 918 Predicted energy: -92.39529008163507 Cost value: 55.13570931795046 Grad:  (Array(59.48519, dtype=float32), Array(-2.856086, dtype=float32))
Training epoch:  92%|█████████▏| 919/1000 [1:04:37<05:41,  4.22s/it]Iteration 919 Predicted energy: -92.40441103544211 Cost value: 55.000340100224676 Grad:  (Array(2.8419206, dtype=float32), Array(-57.27794, dtype=float32))
Training epoch:  92%|█████████▏| 920/1000 [1:04:41<05:38,  4.23s/it]Iteration 920 Predicted energy: -92.40816660403407 Cost value: 54.94464994807368 Grad:  (Array(51.899593, dtype=float32), Array(-2.5540218, dtype=float32))
Training epoch:  92%|█████████▏| 921/1000 [1:04:45<05:34,  4.24s/it]Iteration 921 Predicted energy: -92.42370732519667 Cost value: 54.714501332345044 Grad:  (Array(2.221506, dtype=float32), Array(-43.389153, dtype=float32))
Training epoch:  92%|█████████▏| 922/1000 [1:04:50<05:29,  4.23s/it]Iteration 922 Predicted energy: -92.4338563130335 Cost value: 54.56446172801433 Grad:  (Array(32.47892, dtype=float32), Array(-1.6262338, dtype=float32))
Training epoch:  92%|█████████▏| 923/1000 [1:04:54<05:24,  4.21s/it]Iteration 923 Predicted energy: -92.44345532230889 Cost value: 54.42274240364599 Grad:  (Array(1.106661, dtype=float32), Array(-21.905735, dtype=float32))
Training epoch:  92%|█████████▏| 924/1000 [1:04:58<05:21,  4.23s/it]Iteration 924 Predicted energy: -92.44860360038453 Cost value: 54.34680938985881 Grad:  (Array(10.466969, dtype=float32), Array(-0.531678, dtype=float32))
Training epoch:  92%|█████████▎| 925/1000 [1:05:02<05:15,  4.21s/it]Iteration 925 Predicted energy: -92.45044629065804 Cost value: 54.319644053644296 Grad:  (Array(0.0333373, dtype=float32), Array(-0.9747648, dtype=float32))
Training epoch:  93%|█████████▎| 926/1000 [1:05:06<05:10,  4.19s/it]Iteration 926 Predicted energy: -92.44959709335082 Cost value: 54.33216225926428 Grad:  (Array(0.3966364, dtype=float32), Array(-8.347773, dtype=float32))
Training epoch:  93%|█████████▎| 927/1000 [1:05:11<05:05,  4.19s/it]Iteration 927 Predicted energy: -92.44662767304233 Cost value: 54.37594648089869 Grad:  (Array(16.533157, dtype=float32), Array(-0.8180776, dtype=float32))
Training epoch:  93%|█████████▎| 928/1000 [1:05:15<05:08,  4.29s/it]Iteration 928 Predicted energy: -92.44216335752773 Cost value: 54.441806178891014 Grad:  (Array(1.1225793, dtype=float32), Array(-24.351707, dtype=float32))
Training epoch:  93%|█████████▎| 929/1000 [1:05:19<05:02,  4.25s/it]Iteration 929 Predicted energy: -92.43509851298168 Cost value: 54.54611156520082 Grad:  (Array(32.345764, dtype=float32), Array(-1.5414305, dtype=float32))
Training epoch:  93%|█████████▎| 930/1000 [1:05:23<04:55,  4.22s/it]Iteration 930 Predicted energy: -92.42794228307565 Cost value: 54.65186793452088 Grad:  (Array(1.8281803, dtype=float32), Array(-39.985394, dtype=float32))
Training epoch:  93%|█████████▎| 931/1000 [1:05:28<04:50,  4.22s/it]Iteration 931 Predicted energy: -92.41563035011333 Cost value: 54.834056129757485 Grad:  (Array(48.06405, dtype=float32), Array(-2.243693, dtype=float32))
Training epoch:  93%|█████████▎| 932/1000 [1:05:32<04:44,  4.19s/it]Iteration 932 Predicted energy: -92.40862582014668 Cost value: 54.937842311449856 Grad:  (Array(2.5510445, dtype=float32), Array(-54.650608, dtype=float32))
Training epoch:  93%|█████████▎| 933/1000 [1:05:36<04:41,  4.20s/it]Iteration 933 Predicted energy: -92.3943286355571 Cost value: 55.149988374928206 Grad:  (Array(60.16344, dtype=float32), Array(-2.8404338, dtype=float32))
Training epoch:  93%|█████████▎| 934/1000 [1:05:40<04:39,  4.23s/it]Iteration 934 Predicted energy: -92.39741610914406 Cost value: 55.104140873657016 Grad:  (Array(2.9996357, dtype=float32), Array(-61.54366, dtype=float32))
Training epoch:  94%|█████████▎| 935/1000 [1:05:44<04:34,  4.23s/it]Iteration 935 Predicted energy: -92.39431270116776 Cost value: 55.15022504241483 Grad:  (Array(59.642075, dtype=float32), Array(-2.9018238, dtype=float32))
Training epoch:  94%|█████████▎| 936/1000 [1:05:49<04:29,  4.21s/it]Iteration 936 Predicted energy: -92.41099628558123 Cost value: 54.90270811951301 Grad:  (Array(2.6914005, dtype=float32), Array(-52.850014, dtype=float32))
Training epoch:  94%|█████████▎| 937/1000 [1:05:53<04:24,  4.20s/it]Iteration 937 Predicted energy: -92.42170728474898 Cost value: 54.74409363139144 Grad:  (Array(42.713234, dtype=float32), Array(-2.124929, dtype=float32))
Training epoch:  94%|█████████▍| 938/1000 [1:05:57<04:20,  4.20s/it]Iteration 938 Predicted energy: -92.43628000374291 Cost value: 54.52866108088976 Grad:  (Array(1.6087229, dtype=float32), Array(-31.304714, dtype=float32))
Training epoch:  94%|█████████▍| 939/1000 [1:06:01<04:15,  4.20s/it]Iteration 939 Predicted energy: -92.44491014247306 Cost value: 54.40127958806168 Grad:  (Array(18.350042, dtype=float32), Array(-0.93615353, dtype=float32))
Training epoch:  94%|█████████▍| 940/1000 [1:06:05<04:12,  4.21s/it]Iteration 940 Predicted energy: -92.4495280183589 Cost value: 54.33318057245122 Grad:  (Array(0.3427749, dtype=float32), Array(-7.272373, dtype=float32))
Training epoch:  94%|█████████▍| 941/1000 [1:06:10<04:09,  4.22s/it]Iteration 941 Predicted energy: -92.45020005143807 Cost value: 54.323273772060766 Grad:  (Array(0.18107344, dtype=float32), Array(-3.968711, dtype=float32))
Training epoch:  94%|█████████▍| 942/1000 [1:06:14<04:06,  4.24s/it]Iteration 942 Predicted energy: -92.44788552106193 Cost value: 54.35739730846465 Grad:  (Array(13.376583, dtype=float32), Array(-0.676464, dtype=float32))
Training epoch:  94%|█████████▍| 943/1000 [1:06:18<04:00,  4.22s/it]Iteration 943 Predicted energy: -92.44344676247397 Cost value: 54.422868698556144 Grad:  (Array(1.0535122, dtype=float32), Array(-22.389462, dtype=float32))
Training epoch:  94%|█████████▍| 944/1000 [1:06:22<03:55,  4.21s/it]Iteration 944 Predicted energy: -92.43631951904048 Cost value: 54.52807749268246 Grad:  (Array(31.02333, dtype=float32), Array(-1.4956702, dtype=float32))
Training epoch:  94%|█████████▍| 945/1000 [1:06:27<03:51,  4.21s/it]Iteration 945 Predicted energy: -92.4288695891159 Cost value: 54.63815822192254 Grad:  (Array(1.798639, dtype=float32), Array(-39.15271, dtype=float32))
Training epoch:  95%|█████████▍| 946/1000 [1:06:31<03:46,  4.20s/it]Iteration 946 Predicted energy: -92.41648184651145 Cost value: 54.82144618956796 Grad:  (Array(47.45282, dtype=float32), Array(-2.2221026, dtype=float32))
Training epoch:  95%|█████████▍| 947/1000 [1:06:35<03:43,  4.23s/it]Iteration 947 Predicted energy: -92.40923248526714 Cost value: 54.92884946770006 Grad:  (Array(2.5151315, dtype=float32), Array(-54.209118, dtype=float32))
Training epoch:  95%|█████████▍| 948/1000 [1:06:39<03:39,  4.23s/it]Iteration 948 Predicted energy: -92.39482015734235 Cost value: 55.14268823630248 Grad:  (Array(59.978397, dtype=float32), Array(-2.8059137, dtype=float32))
Training epoch:  95%|█████████▍| 949/1000 [1:06:43<03:35,  4.23s/it]Iteration 949 Predicted energy: -92.39721120056015 Cost value: 55.107183077142324 Grad:  (Array(2.9654381, dtype=float32), Array(-61.649338, dtype=float32))
Training epoch:  95%|█████████▌| 950/1000 [1:06:48<03:31,  4.23s/it]Iteration 950 Predicted energy: -92.39320688359452 Cost value: 55.1666505750175 Grad:  (Array(60.33873, dtype=float32), Array(-2.9032032, dtype=float32))
Training epoch:  95%|█████████▌| 951/1000 [1:06:52<03:25,  4.19s/it]Iteration 951 Predicted energy: -92.40931772964777 Cost value: 54.92758591456715 Grad:  (Array(2.7208672, dtype=float32), Array(-54.026268, dtype=float32))
Training epoch:  95%|█████████▌| 952/1000 [1:06:56<03:21,  4.20s/it]Iteration 952 Predicted energy: -92.41937836171066 Cost value: 54.778562109835846 Grad:  (Array(44.52906, dtype=float32), Array(-2.2031996, dtype=float32))
Training epoch:  95%|█████████▌| 953/1000 [1:07:00<03:17,  4.21s/it]Iteration 953 Predicted energy: -92.43442888512527 Cost value: 54.55600313212242 Grad:  (Array(1.707763, dtype=float32), Array(-33.401527, dtype=float32))
Training epoch:  95%|█████████▌| 954/1000 [1:07:04<03:13,  4.20s/it]Iteration 954 Predicted energy: -92.44352008747506 Cost value: 54.42178683963514 Grad:  (Array(20.698578, dtype=float32), Array(-1.0535154, dtype=float32))
Training epoch:  96%|█████████▌| 955/1000 [1:07:09<03:08,  4.19s/it]Iteration 955 Predicted energy: -92.44891763419825 Cost value: 54.34217935580572 Grad:  (Array(0.46542352, dtype=float32), Array(-9.642354, dtype=float32))
Training epoch:  96%|█████████▌| 956/1000 [1:07:13<03:05,  4.21s/it]Iteration 956 Predicted energy: -92.45030547762464 Cost value: 54.321719710012786 Grad:  (Array(0.06407826, dtype=float32), Array(-1.6625633, dtype=float32))
Training epoch:  96%|█████████▌| 957/1000 [1:07:17<03:01,  4.22s/it]Iteration 957 Predicted energy: -92.44867099199077 Cost value: 54.34581576866936 Grad:  (Array(11.0037985, dtype=float32), Array(-0.56610996, dtype=float32))
Training epoch:  96%|█████████▌| 958/1000 [1:07:21<02:57,  4.21s/it]Iteration 958 Predicted energy: -92.44487213527776 Cost value: 54.40184025054283 Grad:  (Array(0.94971335, dtype=float32), Array(-20.004322, dtype=float32))
Training epoch:  96%|█████████▌| 959/1000 [1:07:26<02:53,  4.23s/it]Iteration 959 Predicted energy: -92.4387231629074 Cost value: 54.492584753200696 Grad:  (Array(28.30061, dtype=float32), Array(-1.3716817, dtype=float32))
Training epoch:  96%|█████████▌| 960/1000 [1:07:30<02:49,  4.24s/it]Iteration 960 Predicted energy: -92.43215624153547 Cost value: 54.589580713410065 Grad:  (Array(1.6703192, dtype=float32), Array(-36.073074, dtype=float32))
Training epoch:  96%|█████████▌| 961/1000 [1:07:34<02:44,  4.22s/it]Iteration 961 Predicted energy: -92.42161392358352 Cost value: 54.74547518466121 Grad:  (Array(43.832893, dtype=float32), Array(-2.057006, dtype=float32))
Training epoch:  96%|█████████▌| 962/1000 [1:07:38<02:40,  4.22s/it]Iteration 962 Predicted energy: -92.41490280162576 Cost value: 54.844831655243794 Grad:  (Array(2.334054, dtype=float32), Array(-50.31627, dtype=float32))
Training epoch:  96%|█████████▋| 963/1000 [1:07:42<02:36,  4.22s/it]Iteration 963 Predicted energy: -92.4019921133554 Cost value: 55.0362244749778 Grad:  (Array(56.19841, dtype=float32), Array(-2.6192825, dtype=float32))
Training epoch:  96%|█████████▋| 964/1000 [1:07:47<02:32,  4.22s/it]Iteration 964 Predicted energy: -92.4018721283847 Cost value: 55.03800474006168 Grad:  (Array(2.8035698, dtype=float32), Array(-58.87975, dtype=float32))
Training epoch:  96%|█████████▋| 965/1000 [1:07:51<02:27,  4.20s/it]Iteration 965 Predicted energy: -92.39546914170407 Cost value: 55.13305018537855 Grad:  (Array(59.338787, dtype=float32), Array(-2.8338814, dtype=float32))
Training epoch:  97%|█████████▋| 966/1000 [1:07:55<02:23,  4.21s/it]Iteration 966 Predicted energy: -92.40746406767785 Cost value: 54.955065495125886 Grad:  (Array(2.7404037, dtype=float32), Array(-55.286694, dtype=float32))
Training epoch:  97%|█████████▋| 967/1000 [1:07:59<02:19,  4.22s/it]Iteration 967 Predicted energy: -92.41396926324828 Cost value: 54.85865959242155 Grad:  (Array(48.313583, dtype=float32), Array(-2.373697, dtype=float32))
Training epoch:  97%|█████████▋| 968/1000 [1:08:03<02:14,  4.21s/it]Iteration 968 Predicted energy: -92.42882502894729 Cost value: 54.63881698030726 Grad:  (Array(1.9819505, dtype=float32), Array(-38.958847, dtype=float32))
Training epoch:  97%|█████████▋| 969/1000 [1:08:08<02:10,  4.21s/it]Iteration 969 Predicted energy: -92.4383149455492 Cost value: 54.49861176685907 Grad:  (Array(27.756868, dtype=float32), Array(-1.3967913, dtype=float32))
Training epoch:  97%|█████████▋| 970/1000 [1:08:12<02:05,  4.20s/it]Iteration 970 Predicted energy: -92.44595153104508 Cost value: 54.38591868670466 Grad:  (Array(0.8654164, dtype=float32), Array(-17.428368, dtype=float32))
Training epoch:  97%|█████████▋| 971/1000 [1:08:16<02:02,  4.22s/it]Iteration 971 Predicted energy: -92.44964538006826 Cost value: 54.33145041539261 Grad:  (Array(6.5260715, dtype=float32), Array(-0.33997384, dtype=float32))
Training epoch:  97%|█████████▋| 972/1000 [1:08:20<01:58,  4.23s/it]Iteration 972 Predicted energy: -92.45036735776709 Cost value: 54.32080756007572 Grad:  (Array(2.4574652, dtype=float32), Array(-0.2037546, dtype=float32))
Training epoch:  97%|█████████▋| 973/1000 [1:08:25<01:53,  4.21s/it]Iteration 973 Predicted energy: -92.44878876025417 Cost value: 54.3440794163406 Grad:  (Array(0.53681004, dtype=float32), Array(-11.240241, dtype=float32))
Training epoch:  97%|█████████▋| 974/1000 [1:08:29<01:49,  4.21s/it]Iteration 974 Predicted energy: -92.44530701492904 Cost value: 54.39542530351417 Grad:  (Array(19.024242, dtype=float32), Array(-0.931927, dtype=float32))
Training epoch:  98%|█████████▊| 975/1000 [1:08:33<01:45,  4.20s/it]Iteration 975 Predicted energy: -92.44066481037751 Cost value: 54.46392239220375 Grad:  (Array(1.2259108, dtype=float32), Array(-26.443655, dtype=float32))
Training epoch:  98%|█████████▊| 976/1000 [1:08:37<01:40,  4.20s/it]Iteration 976 Predicted energy: -92.43346500814347 Cost value: 54.57024284438336 Grad:  (Array(33.93735, dtype=float32), Array(-1.6032408, dtype=float32))
Training epoch:  98%|█████████▊| 977/1000 [1:08:41<01:37,  4.22s/it]Iteration 977 Predicted energy: -92.42684608426335 Cost value: 54.668076852538675 Grad:  (Array(1.8817205, dtype=float32), Array(-40.93848, dtype=float32))
Training epoch:  98%|█████████▊| 978/1000 [1:08:46<01:32,  4.22s/it]Iteration 978 Predicted energy: -92.41535245132191 Cost value: 54.83817188925447 Grad:  (Array(48.20968, dtype=float32), Array(-2.241876, dtype=float32))
Training epoch:  98%|█████████▊| 979/1000 [1:08:50<01:27,  4.18s/it]Iteration 979 Predicted energy: -92.4097537640268 Cost value: 54.921122928667494 Grad:  (Array(2.5182734, dtype=float32), Array(-53.86419, dtype=float32))
Training epoch:  98%|█████████▊| 980/1000 [1:08:54<01:23,  4.20s/it]Iteration 980 Predicted energy: -92.39749473323543 Cost value: 55.10297359255872 Grad:  (Array(58.47876, dtype=float32), Array(-2.761326, dtype=float32))
Training epoch:  98%|█████████▊| 981/1000 [1:08:58<01:19,  4.20s/it]Iteration 981 Predicted energy: -92.40116276136622 Cost value: 55.04853049104638 Grad:  (Array(2.879798, dtype=float32), Array(-59.2632, dtype=float32))
Training epoch:  98%|█████████▊| 982/1000 [1:09:02<01:15,  4.20s/it]Iteration 982 Predicted energy: -92.39907041048639 Cost value: 55.079583136849024 Grad:  (Array(57.1474, dtype=float32), Array(-2.7805326, dtype=float32))
Training epoch:  98%|█████████▊| 983/1000 [1:09:07<01:11,  4.19s/it]Iteration 983 Predicted energy: -92.41391359970363 Cost value: 54.85948415777411 Grad:  (Array(2.575025, dtype=float32), Array(-50.79751, dtype=float32))
Training epoch:  98%|█████████▊| 984/1000 [1:09:11<01:06,  4.17s/it]Iteration 984 Predicted energy: -92.42337003615964 Cost value: 54.71949124961504 Grad:  (Array(41.47085, dtype=float32), Array(-2.06284, dtype=float32))
Training epoch:  98%|█████████▊| 985/1000 [1:09:15<01:02,  4.19s/it]Iteration 985 Predicted energy: -92.43652159830434 Cost value: 54.525093100475296 Grad:  (Array(1.5877706, dtype=float32), Array(-31.06346, dtype=float32))
Training epoch:  99%|█████████▊| 986/1000 [1:09:19<00:58,  4.21s/it]Iteration 986 Predicted energy: -92.4445175249851 Cost value: 54.40707141734035 Grad:  (Array(19.139225, dtype=float32), Array(-0.9678368, dtype=float32))
Training epoch:  99%|█████████▊| 987/1000 [1:09:23<00:54,  4.23s/it]Iteration 987 Predicted energy: -92.4492150204152 Cost value: 54.337794951480156 Grad:  (Array(0.43145907, dtype=float32), Array(-8.904234, dtype=float32))
Training epoch:  99%|█████████▉| 988/1000 [1:09:28<00:50,  4.24s/it]Iteration 988 Predicted energy: -92.45044037129074 Cost value: 54.31973130735721 Grad:  (Array(0.06570006, dtype=float32), Array(-1.5075722, dtype=float32))
Training epoch:  99%|█████████▉| 989/1000 [1:09:32<00:46,  4.23s/it]Iteration 989 Predicted energy: -92.44903798005355 Cost value: 54.340405059639366 Grad:  (Array(10.227166, dtype=float32), Array(-0.516334, dtype=float32))
Training epoch:  99%|█████████▉| 990/1000 [1:09:36<00:42,  4.24s/it]Iteration 990 Predicted energy: -92.44568896753512 Cost value: 54.38979139985922 Grad:  (Array(0.8667589, dtype=float32), Array(-18.567865, dtype=float32))
Training epoch:  99%|█████████▉| 991/1000 [1:09:40<00:38,  4.22s/it]Iteration 991 Predicted energy: -92.44015673080747 Cost value: 54.47142187192118 Grad:  (Array(26.600437, dtype=float32), Array(-1.2815974, dtype=float32))
Training epoch:  99%|█████████▉| 992/1000 [1:09:45<00:33,  4.23s/it]Iteration 992 Predicted energy: -92.4338141390495 Cost value: 54.56508478935036 Grad:  (Array(1.5638752, dtype=float32), Array(-34.305195, dtype=float32))
Training epoch:  99%|█████████▉| 993/1000 [1:09:49<00:29,  4.26s/it]Iteration 993 Predicted energy: -92.42341081133154 Cost value: 54.71888800198451 Grad:  (Array(42.502125, dtype=float32), Array(-1.9857862, dtype=float32))
Training epoch:  99%|█████████▉| 994/1000 [1:09:53<00:25,  4.25s/it]Iteration 994 Predicted energy: -92.41562176574416 Cost value: 54.83418326437466 Grad:  (Array(2.289964, dtype=float32), Array(-49.763947, dtype=float32))
Training epoch: 100%|█████████▉| 995/1000 [1:09:57<00:21,  4.24s/it]Iteration 995 Predicted energy: -92.40109516389876 Cost value: 55.04953357033782 Grad:  (Array(56.67485, dtype=float32), Array(-2.6444168, dtype=float32))
Training epoch: 100%|█████████▉| 996/1000 [1:10:01<00:16,  4.21s/it]Iteration 996 Predicted energy: -92.39930743462251 Cost value: 55.07606501436624 Grad:  (Array(2.8827145, dtype=float32), Array(-60.38493, dtype=float32))
Training epoch: 100%|█████████▉| 997/1000 [1:10:06<00:12,  4.19s/it]Iteration 997 Predicted energy: -92.390854343808 Cost value: 55.201602737783304 Grad:  (Array(61.51394, dtype=float32), Array(-2.951987, dtype=float32))
Training epoch: 100%|█████████▉| 998/1000 [1:10:10<00:08,  4.17s/it]Iteration 998 Predicted energy: -92.4038004182022 Cost value: 55.0093974183821 Grad:  (Array(2.8835545, dtype=float32), Array(-57.499786, dtype=float32))
Training epoch: 100%|█████████▉| 999/1000 [1:10:14<00:04,  4.16s/it]Iteration 999 Predicted energy: -92.41109961401102 Cost value: 54.901176878049014 Grad:  (Array(49.88981, dtype=float32), Array(-2.4644942, dtype=float32))






Training epoch: 100%|██████████| 1000/1000 [1:10:18<00:00,  4.18s/it]Training epoch: 100%|██████████| 1000/1000 [1:10:18<00:00,  4.22s/it]
